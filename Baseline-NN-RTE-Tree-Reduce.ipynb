{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6915e5d5-f526-4fd8-a23e-1530d82dc744",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import arff\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score, auc, roc_curve, balanced_accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from sklearn.ensemble import RandomTreesEmbedding\n",
    "from sklearn.decomposition import PCA\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "95467a3e-7e51-4155-9f95-bfa27ec8f808",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_directory=\"MDP/\"\n",
    "files = [arff for arff in os.listdir(path_to_directory) if arff.endswith(\".arff\")]\n",
    "\n",
    "def toCsv(content): \n",
    "    data = False\n",
    "    header = \"\"\n",
    "    newContent = []\n",
    "    for line in content:\n",
    "        if not data:\n",
    "            if \"@attribute\" in line:\n",
    "                attri = line.split()\n",
    "                columnName = attri[attri.index(\"@attribute\")+1]\n",
    "                header = header + columnName + \",\"\n",
    "            elif \"@data\" in line:\n",
    "                data = True\n",
    "                header = header[:-1]\n",
    "                header += '\\n'\n",
    "                newContent.append(header)\n",
    "        else:\n",
    "            newContent.append(line)\n",
    "    return newContent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9fdc2d03-00e8-42ce-9b59-cfa043c9247a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Main loop for reading and writing files\n",
    "for zzzz,file in enumerate(files):\n",
    "    with open(path_to_directory+file , \"r\") as inFile:\n",
    "        content = inFile.readlines()\n",
    "        name,ext = os.path.splitext(inFile.name)\n",
    "        new = toCsv(content)\n",
    "        with open(name+\".csv\", \"w\") as outFile:\n",
    "            outFile.writelines(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "98a2ffda-90f7-4979-bda2-065d9ef077df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm1 = pd.read_csv('MDP/CM1.csv')\n",
    "kc3 = pd.read_csv('MDP/KC3.csv')\n",
    "#kc4 = pd.read_csv('MDP/KC4.csv')\n",
    "mc2 = pd.read_csv('MDP/MC2.csv')\n",
    "mw1 = pd.read_csv('MDP/MW1.csv')\n",
    "pc1 = pd.read_csv('MDP/PC1.csv')\n",
    "pc2 = pd.read_csv('MDP/PC2.csv')\n",
    "pc3 = pd.read_csv('MDP/PC3.csv')\n",
    "pc4 = pd.read_csv('MDP/PC4.csv')\n",
    "jm1 = pd.read_csv('MDP/JM1.csv')\n",
    "jm1.rename(columns={\"label\": \"Defective\"}, errors=\"raise\", inplace=True)\n",
    "kc1 = pd.read_csv('MDP/KC1.csv')\n",
    "mc1 = pd.read_csv('MDP/MC1.csv')\n",
    "pc5 = pd.read_csv('MDP/PC5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "49cd79c0-40c8-4910-b7f9-73b9edf5262a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC_BLANK</th>\n",
       "      <th>BRANCH_COUNT</th>\n",
       "      <th>LOC_CODE_AND_COMMENT</th>\n",
       "      <th>LOC_COMMENTS</th>\n",
       "      <th>CYCLOMATIC_COMPLEXITY</th>\n",
       "      <th>DESIGN_COMPLEXITY</th>\n",
       "      <th>ESSENTIAL_COMPLEXITY</th>\n",
       "      <th>LOC_EXECUTABLE</th>\n",
       "      <th>HALSTEAD_CONTENT</th>\n",
       "      <th>HALSTEAD_DIFFICULTY</th>\n",
       "      <th>...</th>\n",
       "      <th>PARAMETER_COUNT</th>\n",
       "      <th>MAINTENANCE_SEVERITY</th>\n",
       "      <th>MODIFIED_CONDITION_COUNT</th>\n",
       "      <th>MULTIPLE_CONDITION_COUNT</th>\n",
       "      <th>NODE_COUNT</th>\n",
       "      <th>NORMALIZED_CYLOMATIC_COMPLEXITY</th>\n",
       "      <th>NUMBER_OF_LINES</th>\n",
       "      <th>PERCENT_COMMENTS</th>\n",
       "      <th>GLOBAL_DATA_COMPLEXITY</th>\n",
       "      <th>GLOBAL_DATA_DENSITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>23.87</td>\n",
       "      <td>27.06</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>69.72</td>\n",
       "      <td>22.29</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>95</td>\n",
       "      <td>59.66</td>\n",
       "      <td>33.33</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>89.39</td>\n",
       "      <td>2.50</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16.84</td>\n",
       "      <td>1.50</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>9.0</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>41</td>\n",
       "      <td>42.25</td>\n",
       "      <td>28.27</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>68.0</td>\n",
       "      <td>25.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>10.82</td>\n",
       "      <td>9.75</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>69.69</td>\n",
       "      <td>27.79</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.21</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>9.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>19.50</td>\n",
       "      <td>40.24</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>68.0</td>\n",
       "      <td>58.93</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>17.24</td>\n",
       "      <td>7.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.67</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2008 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LOC_BLANK  BRANCH_COUNT  LOC_CODE_AND_COMMENT  LOC_COMMENTS  \\\n",
       "0          6.0            15                     1             3   \n",
       "1          5.0            17                     0             7   \n",
       "2         12.0            31                     0             0   \n",
       "3          1.0             1                     0             0   \n",
       "4          0.0             1                     0             0   \n",
       "..         ...           ...                   ...           ...   \n",
       "119        9.0            23                     5             9   \n",
       "120        1.0             3                     0             0   \n",
       "121        8.0             3                     5             8   \n",
       "122        9.0            11                     0            33   \n",
       "123        1.0             3                     1             0   \n",
       "\n",
       "     CYCLOMATIC_COMPLEXITY  DESIGN_COMPLEXITY  ESSENTIAL_COMPLEXITY  \\\n",
       "0                        8                  8                     1   \n",
       "1                        9                  8                     1   \n",
       "2                       16                 13                    10   \n",
       "3                        1                  1                     1   \n",
       "4                        1                  1                     1   \n",
       "..                     ...                ...                   ...   \n",
       "119                     12                  4                     8   \n",
       "120                      2                  1                     1   \n",
       "121                      2                  1                     1   \n",
       "122                      6                  2                     1   \n",
       "123                      2                  1                     1   \n",
       "\n",
       "     LOC_EXECUTABLE  HALSTEAD_CONTENT  HALSTEAD_DIFFICULTY  ...  \\\n",
       "0                45             23.87                27.06  ...   \n",
       "1                82             69.72                22.29  ...   \n",
       "2                95             59.66                33.33  ...   \n",
       "3                12             89.39                 2.50  ...   \n",
       "4                 3             16.84                 1.50  ...   \n",
       "..              ...               ...                  ...  ...   \n",
       "119              41             42.25                28.27  ...   \n",
       "120               9             10.82                 9.75  ...   \n",
       "121              43             69.69                27.79  ...   \n",
       "122              23             19.50                40.24  ...   \n",
       "123              14             17.24                 7.50  ...   \n",
       "\n",
       "     PARAMETER_COUNT  MAINTENANCE_SEVERITY  MODIFIED_CONDITION_COUNT  \\\n",
       "0                NaN                   NaN                       NaN   \n",
       "1                NaN                   NaN                       NaN   \n",
       "2                NaN                   NaN                       NaN   \n",
       "3                NaN                   NaN                       NaN   \n",
       "4                NaN                   NaN                       NaN   \n",
       "..               ...                   ...                       ...   \n",
       "119              3.0                  0.67                      11.0   \n",
       "120              2.0                  0.50                       1.0   \n",
       "121              0.0                  0.50                       1.0   \n",
       "122              2.0                  0.17                       5.0   \n",
       "123              0.0                  0.50                       1.0   \n",
       "\n",
       "     MULTIPLE_CONDITION_COUNT  NODE_COUNT  NORMALIZED_CYLOMATIC_COMPLEXITY  \\\n",
       "0                         NaN         NaN                              NaN   \n",
       "1                         NaN         NaN                              NaN   \n",
       "2                         NaN         NaN                              NaN   \n",
       "3                         NaN         NaN                              NaN   \n",
       "4                         NaN         NaN                              NaN   \n",
       "..                        ...         ...                              ...   \n",
       "119                      19.0        32.0                             0.18   \n",
       "120                       2.0         6.0                             0.17   \n",
       "121                       2.0        21.0                             0.03   \n",
       "122                      10.0        24.0                             0.09   \n",
       "123                       2.0         7.0                             0.11   \n",
       "\n",
       "     NUMBER_OF_LINES  PERCENT_COMMENTS  GLOBAL_DATA_COMPLEXITY  \\\n",
       "0                NaN               NaN                     NaN   \n",
       "1                NaN               NaN                     NaN   \n",
       "2                NaN               NaN                     NaN   \n",
       "3                NaN               NaN                     NaN   \n",
       "4                NaN               NaN                     NaN   \n",
       "..               ...               ...                     ...   \n",
       "119             68.0             25.45                     5.0   \n",
       "120             12.0              0.00                     2.0   \n",
       "121             66.0             23.21                     2.0   \n",
       "122             68.0             58.93                     5.0   \n",
       "123             18.0              6.67                     2.0   \n",
       "\n",
       "     GLOBAL_DATA_DENSITY  \n",
       "0                    NaN  \n",
       "1                    NaN  \n",
       "2                    NaN  \n",
       "3                    NaN  \n",
       "4                    NaN  \n",
       "..                   ...  \n",
       "119                 0.42  \n",
       "120                 1.00  \n",
       "121                 1.00  \n",
       "122                 0.83  \n",
       "123                 1.00  \n",
       "\n",
       "[2008 rows x 40 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dataset = [kc1,pc2,mc2]\n",
    "label_dataset = ['kc1']\n",
    "\n",
    "list_test = [cm1,kc3,mc2,mw1,pc1,pc2,pc3,pc4,pc5,jm1,kc1,mc1] \n",
    "label_test = ['cm1','kc3','mc2','mw1','pc1','pc2','pc3','pc4','pc5','jm1','kc1','mc1']\n",
    "\n",
    "my_index = range(0,len(list_test))\n",
    "my_dataset = dict(zip(label_test,list_test))\n",
    "\n",
    "df = list_dataset\n",
    "df = pd.concat(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a3f48403-eca4-44c9-8827-03fc69a93458",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def adjustdataset_list(list_df):\n",
    "    dt_result = list_df.pop()\n",
    "    \n",
    "    for dt in list_df:\n",
    "        if len(dt.columns) > len(dt_result.columns):\n",
    "            dt_result = adjustdataset(dt,dt_result)\n",
    "        else:\n",
    "            dt_result = adjustdataset(dt_result,dt)    \n",
    "    return dt_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dea32944-e73e-48a1-98e5-4bd0383adeb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def adjustdataset(dt,dataframe):\n",
    "    dt_copy = dt.copy()\n",
    "    counter = 0\n",
    "    \n",
    "    for col in dataframe.columns:\n",
    "        if not col in dt.columns:\n",
    "            #print(\"Not Exist \",col)\n",
    "            dt_copy.insert(counter,col,-1)\n",
    "        counter += 1\n",
    "\n",
    "    return pd.concat([dt_copy[dataframe.columns], dataframe])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "971ad588-0428-41ee-a03e-ac5d97b73ab8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_distribution(df, columns):\n",
    "    \n",
    "    counter = 0\n",
    "    # Create a figure and a grid of subplots with 4 rows and 10 columns\n",
    "    fig, axes = plt.subplots(5, 8, figsize=(20, 8))\n",
    "    \n",
    "    # Loop through each subplot and add content (optional)\n",
    "    for i in range(5):\n",
    "        for j in range(8):\n",
    "            try:\n",
    "                ax = axes[i, j]\n",
    "                ax.set_title(columns[counter])\n",
    "                ax.plot(df[columns[counter]].sort_values(), norm.pdf(df[columns[counter]].sort_values(), df[columns[counter]].mean(), df[columns[counter]].std())) \n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                counter += 1\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "# Adjust layout to prevent overlapping titles/labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d7975d15-c9bc-4fd7-8f65-c71b1588958e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessing(dataframe, imputer = None, pt = None, scaler = None, show = True):\n",
    "    \n",
    "    df = dataframe.copy()\n",
    "    \n",
    "    df.loc[(df['Defective'] == 'N'),'Defective']=0\n",
    "    df.loc[(df['Defective'] == 'Y'),'Defective']=1\n",
    "    \n",
    "    change_dtypes = ['Defective']\n",
    "    dict_dtypes = {d:'int64' for d in change_dtypes }\n",
    "    df = df.astype(dict_dtypes)\n",
    "    \n",
    "    try:\n",
    "        df.loc[(df['DECISION_DENSITY'] == '?'),'DECISION_DENSITY']= -1\n",
    "        \n",
    "        change_dtypes = ['DECISION_DENSITY']\n",
    "        dict_dtypes = {d:'float64' for d in change_dtypes }\n",
    "        df = df.astype(dict_dtypes)\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    columns = df.columns\n",
    "    \n",
    "    if show:\n",
    "        show_distribution(df,df.columns)\n",
    "    \n",
    "    if imputer :\n",
    "        df = imputer.transform(df)\n",
    "    else:\n",
    "        imputer = KNNImputer(n_neighbors=2)\n",
    "        df = imputer.fit_transform(df)\n",
    "    \n",
    "    df = pd.DataFrame(df)\n",
    "    df.columns = columns\n",
    "    \n",
    "    if show:\n",
    "        show_distribution(df,df.columns)\n",
    "    \n",
    "    y = df['Defective']\n",
    "    X = df.drop('Defective',axis=1)\n",
    "    \n",
    "    if pt:\n",
    "        X_norm = pt.transform(X)\n",
    "    else:\n",
    "        pt = PowerTransformer()\n",
    "        X_norm = pt.fit_transform(X)\n",
    "    \n",
    "    X_norm = pd.DataFrame(X)\n",
    "    X_norm.columns = X.columns\n",
    "    \n",
    "    if show:\n",
    "        show_distribution(X_norm,X_norm.columns)\n",
    "\n",
    "    if scaler:\n",
    "        X_norm_scale = scaler.transform(X_norm)\n",
    "    else:\n",
    "        scaler = StandardScaler()\n",
    "        X_norm_scale = scaler.fit_transform(X_norm)\n",
    "        \n",
    "    return pt, scaler, imputer, X_norm_scale, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6c48181d-c863-463f-8cef-34c3e87d260c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def heat_map(y,result,title):\n",
    "    import seaborn as sns\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    sns.set\n",
    "    _, ax = plt.subplots(figsize=(10,10))\n",
    "    ax = sns.heatmap(confusion_matrix(y, result), annot=True, fmt='d', cmap= ['#09acec','#089dd9','#078fc5','#0681b1','#05668d','#05368d'], annot_kws={\"size\": 40, \"weight\": \"bold\"})  \n",
    "    labels = ['No Defect','Defect']\n",
    "    ax.set_xticklabels(labels, fontsize=30);\n",
    "    ax.set_yticklabels(labels, fontsize=30,rotation=0);\n",
    "    ax.set_ylabel('Prediction', fontsize=30,rotation=0);\n",
    "    ax.set_xlabel('Ground Truth', fontsize=30) #0,1\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2b292f4e-58d5-48e4-8011-acc2a7edb8c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def score(y,result):\n",
    "    accuracy = accuracy_score(y, result)\n",
    "    f1 = f1_score(y, result, average='weighted')\n",
    "    precision = precision_score(y, result, average='weighted')\n",
    "    recall = recall_score(y, result, average='weighted')\n",
    "    print(\"Accuracy = \" , accuracy, \" Precision = \",precision, \" Recall = \",recall, \" F1-Score = \",f1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "57f6d8de-6436-454d-99dc-063236a341f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "scorers = {\n",
    "            'f1_score': make_scorer(f1_score, average='micro'),\n",
    "            'precision_score': make_scorer(precision_score, average='micro'),\n",
    "            'recall_score': make_scorer(recall_score, average='micro'),\n",
    "            'accuracy_score': make_scorer(accuracy_score)\n",
    "          }\n",
    "search_space={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c8a69d5d-6055-4398-a83a-73923943d061",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pt, scaler, imputer, X_norm_scale, y = preprocessing(df, show=False)\n",
    "#X_norm_scale_smote, y_smote = X_norm_scale, y\n",
    "smote = SMOTE(random_state=42)\n",
    "X_norm_scale_smote, y_smote = smote.fit_resample(X_norm_scale, y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f94ee09a-ef5d-4c73-8f10-5447a071aced",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/manifold/_isomap.py:383: UserWarning: The number of connected components of the neighbors graph is 2 > 1. Completing the graph to fit Isomap might be slow. Increase the number of neighbors to avoid this issue.\n",
      "  self._fit_transform(X)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/scipy/sparse/_index.py:100: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/opt/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 219, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"model_21\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 100) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 39) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 74\u001b[0m\n\u001b[1;32m     70\u001b[0m checkpointer\u001b[38;5;241m=\u001b[39mModelCheckpoint(filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msdp-tree-\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.weights.best.keras\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(counter),verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     72\u001b[0m sdp_classifier\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m] )\n\u001b[0;32m---> 74\u001b[0m hist \u001b[38;5;241m=\u001b[39m sdp_classifier\u001b[38;5;241m.\u001b[39mfit([x_sparse_manifold_train,x_train_fold], y_train_fold, \n\u001b[1;32m     75\u001b[0m                 batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[checkpointer], \n\u001b[1;32m     76\u001b[0m                 verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msdp-classifier-tree-\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(counter), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m     79\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(sdp_classifier, handle, protocol\u001b[38;5;241m=\u001b[39mpickle\u001b[38;5;241m.\u001b[39mHIGHEST_PROTOCOL)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/pw/v332jpv14_v0w0p5xsgfb3v80000gn/T/__autograph_generated_file29k6jse_.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 219, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"model_21\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 100) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 39) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "histories = []\n",
    "\n",
    "lst_accu_stratified = []\n",
    "lst_f1_stratified = []\n",
    "lst_precision_stratified = []\n",
    "lst_recall_stratified = []\n",
    "lst_auc_stratified = []\n",
    "lst_bauc_stratified = []\n",
    "lst_gmean_stratified = []\n",
    "\n",
    "lst_accu_stratified_val = []\n",
    "lst_f1_stratified_val = []\n",
    "lst_precision_stratified_val = []\n",
    "lst_recall_stratified_val = []\n",
    "lst_auc_stratified_val = []\n",
    "lst_bauc_stratified_val = []\n",
    "lst_gmean_stratified_val = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=19)\n",
    "\n",
    "for train_index, test_index in skf.split(X_norm_scale_smote, y_smote):\n",
    "\n",
    "    x_train_fold, x_test_fold = X_norm_scale_smote[train_index], X_norm_scale_smote[test_index]\n",
    "    y_train_fold, y_test_fold = y_smote[train_index], y_smote[test_index]\n",
    " \n",
    "    rte = RandomTreesEmbedding(n_estimators=1000, random_state=0, max_depth=10).fit(x_train_fold)\n",
    "    x_sparse_embedding_train = rte.transform(x_train_fold)\n",
    "    x_sparse_embedding_test = rte.transform(x_test_fold)\n",
    "    \n",
    "    with open('rte-tree-{0}.pickle'.format(counter), 'wb') as handle:\n",
    "        pickle.dump(rte, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    from sklearn.manifold import Isomap\n",
    "    manifold = Isomap(n_components=100)\n",
    "    x_sparse_manifold_train = manifold.fit_transform(x_sparse_embedding_train)\n",
    "    x_sparse_manifold_test = manifold.transform(x_sparse_embedding_test)\n",
    "    \n",
    "    with open('manifold-tree-{0}.pickle'.format(counter), 'wb') as handle:\n",
    "        pickle.dump(manifold, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    scaler2 = StandardScaler()\n",
    "    x_sparse_manifold_train = scaler2.fit_transform(x_sparse_manifold_train)\n",
    "    x_sparse_manifold_test = scaler2.transform(x_sparse_manifold_test)\n",
    "    \n",
    "    with open('scaler-tree-{0}.pickle'.format(counter), 'wb') as handle:\n",
    "        pickle.dump(scaler2, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    input_X_train1 = layers.Input(\n",
    "    shape=(x_sparse_manifold_train.shape[1],), name=\"X_train1\")  \n",
    "    \n",
    "    input_X_train2 = layers.Input(shape=(x_train_fold.shape[1],), name=\"X_train2\")\n",
    "\n",
    "    layer_X_train1 = layers.Dense(64,activation='relu',name=\"X_train1_layer\")(input_X_train1)\n",
    "    layer_X_train1 = layers.BatchNormalization()(layer_X_train1)\n",
    "    layer_X_train1 = layers.Dropout(0.3)(layer_X_train1)\n",
    "    \n",
    "    layer_X_train2 = layers.Dense(64,activation='relu',name=\"X_train2_layer\")(input_X_train2)\n",
    "    layer_X_train2 = layers.BatchNormalization()(layer_X_train2)\n",
    "    layer_X_train2 = layers.Dropout(0.3)(layer_X_train2)\n",
    "    \n",
    "    # Merge all available features into a single large vector via concatenation\n",
    "    concat = layers.concatenate([layer_X_train1, layer_X_train2])\n",
    "\n",
    "    layer_final = layers.Dense(1, activation='sigmoid', name=\"classifier\")(layer_X_train1)\n",
    "    #sdp_classifier = Model(inputs=[input_X_train1, input_X_train2], outputs=layer_final)\n",
    "    sdp_classifier = Model(inputs=input_X_train1, outputs=layer_final)\n",
    "\n",
    "\n",
    "    checkpointer=ModelCheckpoint(filepath='sdp-tree-{0}.weights.best.keras'.format(counter),verbose=1,save_best_only=True)\n",
    "\n",
    "    sdp_classifier.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'] )\n",
    "    \n",
    "    hist = sdp_classifier.fit([x_sparse_manifold_train,x_train_fold], y_train_fold, \n",
    "                    batch_size=32, epochs=100, validation_split= 0.1, callbacks=[checkpointer], \n",
    "                    verbose=2, shuffle=True)\n",
    "    \n",
    "    with open('sdp-classifier-tree-{0}.pickle'.format(counter), 'wb') as handle:\n",
    "        pickle.dump(sdp_classifier, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "\n",
    "    sdp_classifier.load_weights('sdp-tree-{0}.weights.best.keras'.format(counter))\n",
    "\n",
    "    histories.append(hist)\n",
    "\n",
    "    results = sdp_classifier.predict([x_sparse_manifold_train,x_train_fold])\n",
    "    results = np.round(results)\n",
    "    \n",
    "    lst_accu_stratified.append(accuracy_score(y_train_fold, results))\n",
    "    lst_f1_stratified.append(f1_score(y_train_fold, results, average='weighted') )\n",
    "    lst_precision_stratified.append(precision_score(results, y_train_fold, average='weighted') )\n",
    "    lst_recall_stratified.append(recall_score(results, y_train_fold, average='weighted') )\n",
    "    fpr, tpr, thresholds = roc_curve(y_train_fold, results)\n",
    "    lst_auc_stratified.append(auc(fpr, tpr))\n",
    "    lst_bauc_stratified.append(balanced_accuracy_score(y_train_fold, results))\n",
    "    \n",
    "    results = sdp_classifier.predict([x_sparse_manifold_test,x_test_fold])\n",
    "    results = np.round(results)\n",
    "    \n",
    "    lst_accu_stratified_val.append(accuracy_score(y_test_fold, results))\n",
    "    lst_f1_stratified_val.append(f1_score(results, y_test_fold, average='weighted') )\n",
    "    lst_precision_stratified_val.append(precision_score(results, y_test_fold, average='weighted') )\n",
    "    lst_recall_stratified_val.append(recall_score(results, y_test_fold, average='weighted') )\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_fold, results)\n",
    "    lst_auc_stratified_val.append(auc(fpr, tpr))\n",
    "    lst_bauc_stratified_val.append(balanced_accuracy_score(y_test_fold, results))\n",
    "    \n",
    "    print(\"Evaluate on training data\")\n",
    "    results = sdp_classifier.evaluate([x_sparse_manifold_train, x_train_fold], y_train_fold)\n",
    "    print(\"test loss, test acc:\", results)\n",
    "\n",
    "    print(\"Evaluate on test data\")\n",
    "    results = sdp_classifier.evaluate([x_sparse_manifold_test , x_test_fold], y_test_fold)\n",
    "    print(\"test loss, test acc:\", results)\n",
    "    counter += 1\n",
    "    \n",
    "\n",
    "dict_test = {  \"train_accu\":lst_accu_stratified, \n",
    "               \"train_precision\":lst_precision_stratified, \"train_recall\":lst_recall_stratified,\n",
    "               \"train_auc\":lst_auc_stratified, \"train_f1\":lst_f1_stratified, \"train_bauc\":lst_bauc_stratified,\n",
    "             \n",
    "               \"test_accu\":lst_accu_stratified_val, \n",
    "               \"test_precision\":lst_precision_stratified_val, \"test_recall\":lst_recall_stratified_val, \n",
    "               \"test_auc\":lst_auc_stratified_val, \"test_f1\":lst_f1_stratified_val,\"test_bauc\":lst_bauc_stratified_val, \n",
    "               \"Input\": x_train_fold.shape[1], \"RTE\": x_sparse_manifold_train.shape[1]}\n",
    "\n",
    "dict_test_result = pd.DataFrame.from_dict(dict_test)\n",
    "dict_test_result.to_csv(\"hasil.csv\")\n",
    "\n",
    "with open('histories-tree-manifold.pickle'.format(counter), 'wb') as handle:\n",
    "        pickle.dump(histories, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cbdbde-167a-4748-8d7a-16f3adb6a187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict_test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176f6dcd-5e0b-45bd-a73b-225010c96ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best = np.argmax(dict_test_result['test_f1'])\n",
    "\n",
    "dbfile = open('rte-tree-{0}.pickle'.format(best), 'rb')    \n",
    "rte = pickle.load(dbfile)\n",
    "dbfile.close()\n",
    "\n",
    "dbfile = open('manifold-tree-{0}.pickle'.format(best), 'rb')    \n",
    "manifold = pickle.load(dbfile)\n",
    "dbfile.close()\n",
    "\n",
    "dbfile = open('scaler-tree-{0}.pickle'.format(best), 'rb')    \n",
    "scaler2 = pickle.load(dbfile)\n",
    "dbfile.close()\n",
    "\n",
    "dbfile = open('sdp-classifier-tree-{0}.pickle'.format(best), 'rb')    \n",
    "sdp_classifier = pickle.load(dbfile)\n",
    "dbfile.close()\n",
    "sdp_classifier.load_weights('sdp-tree-{0}.weights.best.keras'.format(best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c91b00-4914-4288-b111-f558d6c11e3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_sparse_embedding = rte.transform(X_norm_scale)\n",
    "X_sparse_manifold = manifold.transform(X_sparse_embedding)\n",
    "X_sparse_manifold = scaler2.transform(X_sparse_manifold)\n",
    "X_sparse_embedding.shape, X_sparse_manifold.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "34557d77-c1cb-4dcb-a3da-5ed736dd2b7e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "tsne = TSNE(n_jobs=4, n_components=2, verbose = 1)\n",
    "Y  = tsne.fit_transform(X_sparse_manifold)\n",
    "\n",
    "#tsne = TSNE(n_jobs=4, n_components=2, verbose = 1)\n",
    "#Y  = tsne.fit_transform(encoded_train_tcga)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0af136be-9fe3-406f-a700-d50ef3135c23",
   "metadata": {
    "tags": []
   },
   "source": [
    "tsne_ori = pd.DataFrame(Y, columns = [\"tsne1\", \"tsne2\"])\n",
    "defect = pd.DataFrame(df, columns = [\"Defective\"])\n",
    "tsne_ori = pd.concat([tsne_ori,defect.reset_index(drop=True)], axis = 1, sort = False)\n",
    "tsne_ori = tsne_ori.sort_values(by = \"Defective\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "345f745b-aa3f-4cd0-a617-b3238504d734",
   "metadata": {
    "tags": []
   },
   "source": [
    "import plotly_express as px\n",
    "\n",
    "figx = px.scatter(\n",
    "    tsne_ori,\n",
    "    x=\"tsne1\",\n",
    "    y=\"tsne2\",\n",
    "    color=\"Defective\",\n",
    "    hover_name=\"Defective\",\n",
    "    width=970,\n",
    "    height=800,\n",
    "    template=\"ggplot2\",\n",
    "    color_discrete_sequence= px.colors.qualitative.Alphabet,\n",
    "    #facet_col=\"group_label\",\n",
    "    size_max=0.1,\n",
    ")\n",
    "\n",
    "figx.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ad6c81-4e4b-4d4c-ac81-c65bae16db19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Evaluate on training data\")\n",
    "results = sdp_classifier.evaluate([X_sparse_manifold, X_norm_scale], y, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2534dc17-636b-4a74-85ee-168e8584e4ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "results = sdp_classifier.predict([X_sparse_manifold,X_norm_scale])\n",
    "results=np.round(results)\n",
    "print(classification_report(y,results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d644bd-ad4c-4677-b0cd-9cc007d050b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_result = []\n",
    "\n",
    "for label in my_dataset:\n",
    "    dt = adjustdataset(my_dataset[label], df)\n",
    "    pt, scaler_dt, imputer, X_norm_scale_dt, y_dt = preprocessing(dt,imputer,pt, scaler, show=False)\n",
    "    x_sparse_embedding_dt = rte.transform(X_norm_scale_dt)\n",
    "    x_sparse_manifold_dt = manifold.transform(x_sparse_embedding_dt)\n",
    "    x_sparse_manifold_dt = scaler2.transform(x_sparse_manifold_dt)\n",
    "    results = sdp_classifier.predict([x_sparse_manifold_dt,X_norm_scale_dt])\n",
    "    result  = np.round(results)\n",
    "    fpr, tpr, thresholds = roc_curve(y_dt, result)\n",
    "    list_result.append({'label':label, 'accuracy' : accuracy_score(y_dt, result),'precision':precision_score(y_dt, result, average='weighted'),\n",
    "                  'recall': recall_score(y_dt, result, average='weighted'), 'auc':auc(fpr, tpr), 'gmean': balanced_accuracy_score(y_dt, result), 'bauc': balanced_accuracy_score(y_dt, result),\n",
    "                        'f1-score':f1_score(y_dt, result, average='weighted')})\n",
    "    #heat_map(y_dt,result,label)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaf8265-fb9a-423b-9d7f-e5d794f2a1ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(list_result)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b541f30-57c1-465b-9d4a-bfdbd6d516f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_result[['accuracy','precision','recall','auc','f1-score']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc25061-7a0c-4f90-9702-621f5b804f72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sdp_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e07fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_result = []\n",
    "\n",
    "for label in my_dataset:\n",
    "    dt = my_dataset[label]\n",
    "    list_result.append({'Dataset':label, 'Instances':dt.shape[0], 'Features':dt.shape[1],\n",
    "                        'Defective Instances': dt[dt['Defective'] == 'Y'].shape[0],\n",
    "                        'Non-Defective Instances': dt[dt['Defective'] == 'N'].shape[0],})\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42fb2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(list_result)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d497dfdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "dot_img_file = 'model_1.png'\n",
    "keras.utils.plot_model(sdp_classifier, to_file=dot_img_file, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18db3dbc-37d8-4e7c-9355-b7b6203dde7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sdp_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89a0eb6-026c-404e-b5bd-271ca3bf2fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the first dense layer by name\n",
    "meta_model_1 = sdp_classifier.get_layer('X_train1_layer')\n",
    "meta_model_2 = sdp_classifier.get_layer('X_train2_layer')\n",
    "concatenate = sdp_classifier.get_layer('concatenate_3')\n",
    "final_layer = sdp_classifier.get_layer('classifier')\n",
    "\n",
    "# Retrieve the weights and biases of the dense layer\n",
    "meta_model_1_weights, meta_model_1_biases = meta_model_1.get_weights()\n",
    "meta_model_2_weights, meta_model_2_biases = meta_model_2.get_weights()\n",
    "concatenate_weights = concatenate.get_weights()\n",
    "final_layer_weights, final_layer_biases = final_layer.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033d39e9-e7e3-4c3d-a087-cee20fa78829",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "tsne = TSNE(n_jobs=4, n_components=2, verbose = 1)\n",
    "Y  = tsne.fit_transform(meta_model_1_weights)\n",
    "tsne_ori = pd.DataFrame(Y, columns = [\"tsne1\", \"tsne2\"])\n",
    "\n",
    "import plotly_express as px\n",
    "\n",
    "figx = px.scatter(\n",
    "    tsne_ori,\n",
    "    x=\"tsne1\",\n",
    "    y=\"tsne2\",\n",
    "    #color=\"Defective\",\n",
    "    #hover_name=\"Defective\",\n",
    "    width=970,\n",
    "    height=800,\n",
    "    template=\"ggplot2\",\n",
    "    color_discrete_sequence= px.colors.qualitative.Alphabet,\n",
    "    #facet_col=\"group_label\",\n",
    "    size_max=0.1,\n",
    ")\n",
    "\n",
    "figx.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e90905-c1c6-43a1-86b9-3d3db9dfba79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "tsne = TSNE(n_jobs=4, n_components=2, verbose = 1)\n",
    "Y  = tsne.fit_transform(meta_model_2_weights)\n",
    "tsne_ori = pd.DataFrame(Y, columns = [\"tsne1\", \"tsne2\"])\n",
    "\n",
    "import plotly_express as px\n",
    "\n",
    "figx = px.scatter(\n",
    "    tsne_ori,\n",
    "    x=\"tsne1\",\n",
    "    y=\"tsne2\",\n",
    "    #color=\"Defective\",\n",
    "    #hover_name=\"Defective\",\n",
    "    width=970,\n",
    "    height=800,\n",
    "    template=\"ggplot2\",\n",
    "    color_discrete_sequence= px.colors.qualitative.Alphabet,\n",
    "    #facet_col=\"group_label\",\n",
    "    size_max=0.1,\n",
    ")\n",
    "\n",
    "figx.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a76c465-3633-466e-8f88-02c2e755a77c",
   "metadata": {
    "tags": []
   },
   "source": [
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "tsne = TSNE(n_jobs=4, n_components=2, verbose = 1)\n",
    "Y  = tsne.fit_transform(concatenate_weights)\n",
    "tsne_ori = pd.DataFrame(Y, columns = [\"tsne1\", \"tsne2\"])\n",
    "\n",
    "import plotly_express as px\n",
    "\n",
    "figx = px.scatter(\n",
    "    tsne_ori,\n",
    "    x=\"tsne1\",\n",
    "    y=\"tsne2\",\n",
    "    #color=\"Defective\",\n",
    "    #hover_name=\"Defective\",\n",
    "    width=970,\n",
    "    height=800,\n",
    "    template=\"ggplot2\",\n",
    "    color_discrete_sequence= px.colors.qualitative.Alphabet,\n",
    "    #facet_col=\"group_label\",\n",
    "    size_max=0.1,\n",
    ")\n",
    "\n",
    "figx.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a630d101-8121-43d7-a294-a86c501da914",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "tsne = TSNE(n_jobs=4, n_components=2, verbose = 1)\n",
    "Y  = tsne.fit_transform(final_layer_weights)\n",
    "tsne_ori = pd.DataFrame(Y, columns = [\"tsne1\", \"tsne2\"])\n",
    "\n",
    "import plotly_express as px\n",
    "\n",
    "figx = px.scatter(\n",
    "    tsne_ori,\n",
    "    x=\"tsne1\",\n",
    "    y=\"tsne2\",\n",
    "    #color=\"Defective\",\n",
    "    #hover_name=\"Defective\",\n",
    "    width=970,\n",
    "    height=800,\n",
    "    template=\"ggplot2\",\n",
    "    color_discrete_sequence= px.colors.qualitative.Alphabet,\n",
    "    #facet_col=\"group_label\",\n",
    "    size_max=0.1,\n",
    ")\n",
    "\n",
    "figx.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cbc5b1-2416-4479-86c0-418985623f35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
