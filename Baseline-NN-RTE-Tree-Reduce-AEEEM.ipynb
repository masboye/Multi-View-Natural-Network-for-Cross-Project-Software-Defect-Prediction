{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "6915e5d5-f526-4fd8-a23e-1530d82dc744",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import arff\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score, auc, roc_curve\n",
    "from sklearn.metrics import make_scorer\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from sklearn.ensemble import RandomTreesEmbedding\n",
    "from sklearn.decomposition import PCA\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "95467a3e-7e51-4155-9f95-bfa27ec8f808",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_directory=\"AEEEM/\"\n",
    "files = [arff for arff in os.listdir(path_to_directory) if arff.endswith(\".arff\")]\n",
    "\n",
    "def toCsv(content): \n",
    "    data = False\n",
    "    header = \"\"\n",
    "    newContent = []\n",
    "    for line in content:\n",
    "        if not data:\n",
    "            if \"@attribute\" in line:\n",
    "                attri = line.split()\n",
    "                columnName = attri[attri.index(\"@attribute\")+1]\n",
    "                header = header + columnName + \",\"\n",
    "            elif \"@data\" in line:\n",
    "                data = True\n",
    "                header = header[:-1]\n",
    "                header += '\\n'\n",
    "                newContent.append(header)\n",
    "        else:\n",
    "            newContent.append(line)\n",
    "    return newContent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "9fdc2d03-00e8-42ce-9b59-cfa043c9247a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Main loop for reading and writing files\n",
    "for zzzz,file in enumerate(files):\n",
    "    with open(path_to_directory+file , \"r\") as inFile:\n",
    "        content = inFile.readlines()\n",
    "        name,ext = os.path.splitext(inFile.name)\n",
    "        new = toCsv(content)\n",
    "        with open(name+\".csv\", \"w\") as outFile:\n",
    "            outFile.writelines(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "98a2ffda-90f7-4979-bda2-065d9ef077df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eq = pd.read_csv('AEEEM/EQ.csv')\n",
    "jdt = pd.read_csv('AEEEM/JDT.csv')\n",
    "lc = pd.read_csv('AEEEM/LC.csv')\n",
    "ml = pd.read_csv('AEEEM/ML.csv')\n",
    "pde = pd.read_csv('AEEEM/PDE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "46d03aa5-c545-45db-8435-59d489d40fea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_relink = ['eq','jdt','lc','ml','pde']\n",
    "list_data_relink = [eq,jdt,lc,ml,pde]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "3ed279a9-6748-4714-bb29-d4d1d6b50205",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ck_oo_numberOfPrivateMethods</th>\n",
       "      <th>LDHH_lcom</th>\n",
       "      <th>LDHH_fanIn</th>\n",
       "      <th>numberOfNonTrivialBugsFoundUntil:</th>\n",
       "      <th>WCHU_numberOfPublicAttributes</th>\n",
       "      <th>WCHU_numberOfAttributes</th>\n",
       "      <th>CvsWEntropy</th>\n",
       "      <th>LDHH_numberOfPublicMethods</th>\n",
       "      <th>WCHU_fanIn</th>\n",
       "      <th>LDHH_numberOfPrivateAttributes</th>\n",
       "      <th>...</th>\n",
       "      <th>LDHH_fanOut</th>\n",
       "      <th>LDHH_numberOfMethodsInherited</th>\n",
       "      <th>LDHH_rfc</th>\n",
       "      <th>ck_oo_numberOfMethodsInherited</th>\n",
       "      <th>ck_oo_numberOfPublicMethods</th>\n",
       "      <th>LDHH_cbo</th>\n",
       "      <th>WCHU_numberOfLinesOfCode</th>\n",
       "      <th>CvsExpEntropy</th>\n",
       "      <th>LDHH_numberOfMethods</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>### ckooPrivateMethod LDHHlcom LDHHfanIn NNTBF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.002547</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.393707</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.004091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004406</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.008431</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.103594</td>\n",
       "      <td>0.003611</td>\n",
       "      <td>buggy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>0.008643</td>\n",
       "      <td>0.004756</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.37</td>\n",
       "      <td>2.093750</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.015332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018761</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.060301</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.021602</td>\n",
       "      <td>43.12</td>\n",
       "      <td>0.328692</td>\n",
       "      <td>0.009906</td>\n",
       "      <td>buggy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.009143</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.01</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.484675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.17</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003117</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.011859</td>\n",
       "      <td>4.68</td>\n",
       "      <td>0.125841</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>clean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.005642</td>\n",
       "      <td>0.005395</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.811584</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>6.07</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020376</td>\n",
       "      <td>0.002338</td>\n",
       "      <td>0.030608</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.020478</td>\n",
       "      <td>24.06</td>\n",
       "      <td>0.170416</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>buggy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.052387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004539</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.041507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>clean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>clean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>2</td>\n",
       "      <td>0.004633</td>\n",
       "      <td>0.018031</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.02</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.727254</td>\n",
       "      <td>0.003060</td>\n",
       "      <td>11.14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011596</td>\n",
       "      <td>0.004215</td>\n",
       "      <td>0.018394</td>\n",
       "      <td>30.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.025180</td>\n",
       "      <td>23.19</td>\n",
       "      <td>0.267032</td>\n",
       "      <td>0.004671</td>\n",
       "      <td>buggy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>clean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>clean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>325 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          ck_oo_numberOfPrivateMethods  LDHH_lcom  LDHH_fanIn  \\\n",
       "0    ### ckooPrivateMethod LDHHlcom LDHHfanIn NNTBF...        NaN         NaN   \n",
       "1                                                    3   0.002547    0.002555   \n",
       "2                                                   37   0.008643    0.004756   \n",
       "3                                                    3   0.001479    0.009143   \n",
       "4                                                   10   0.005642    0.005395   \n",
       "..                                                 ...        ...         ...   \n",
       "320                                                  1   0.000000    0.000000   \n",
       "321                                                  1   0.000000    0.000000   \n",
       "322                                                  2   0.004633    0.018031   \n",
       "323                                                  0   0.000000    0.000000   \n",
       "324                                                  0   0.000000    0.000000   \n",
       "\n",
       "     numberOfNonTrivialBugsFoundUntil:  WCHU_numberOfPublicAttributes  \\\n",
       "0                                  NaN                            NaN   \n",
       "1                                  4.0                           0.00   \n",
       "2                                 71.0                           0.00   \n",
       "3                                  5.0                           1.01   \n",
       "4                                 38.0                           0.00   \n",
       "..                                 ...                            ...   \n",
       "320                                1.0                           0.00   \n",
       "321                                0.0                           0.00   \n",
       "322                               27.0                           2.02   \n",
       "323                                1.0                           0.00   \n",
       "324                                1.0                           0.00   \n",
       "\n",
       "     WCHU_numberOfAttributes  CvsWEntropy  LDHH_numberOfPublicMethods  \\\n",
       "0                        NaN          NaN                         NaN   \n",
       "1                       3.04     0.393707                    0.003049   \n",
       "2                      14.37     2.093750                    0.001481   \n",
       "3                       3.08     0.484675                    0.000000   \n",
       "4                       1.06     0.811584                    0.000876   \n",
       "..                       ...          ...                         ...   \n",
       "320                     0.00     0.052387                    0.000000   \n",
       "321                     0.00     0.000000                    0.000000   \n",
       "322                     2.02     0.727254                    0.003060   \n",
       "323                     0.00     0.000000                    0.000000   \n",
       "324                     0.00     0.000000                    0.000000   \n",
       "\n",
       "     WCHU_fanIn  LDHH_numberOfPrivateAttributes  ...  LDHH_fanOut  \\\n",
       "0           NaN                             NaN  ...          NaN   \n",
       "1          1.01                        0.004091  ...     0.005627   \n",
       "2          2.02                        0.015332  ...     0.018761   \n",
       "3          6.17                        0.001953  ...     0.003117   \n",
       "4          6.07                        0.000739  ...     0.020376   \n",
       "..          ...                             ...  ...          ...   \n",
       "320        0.00                        0.000000  ...     0.004607   \n",
       "321        0.00                        0.000000  ...     0.000000   \n",
       "322       11.14                        0.000000  ...     0.011596   \n",
       "323        0.00                        0.000000  ...     0.000000   \n",
       "324        0.00                        0.000000  ...     0.000000   \n",
       "\n",
       "     LDHH_numberOfMethodsInherited  LDHH_rfc  ck_oo_numberOfMethodsInherited  \\\n",
       "0                              NaN       NaN                             NaN   \n",
       "1                         0.000000  0.004406                             8.0   \n",
       "2                         0.001486  0.060301                             7.0   \n",
       "3                         0.001486  0.002325                             7.0   \n",
       "4                         0.002338  0.030608                            17.0   \n",
       "..                             ...       ...                             ...   \n",
       "320                       0.000000  0.000000                            16.0   \n",
       "321                       0.000000  0.000000                             7.0   \n",
       "322                       0.004215  0.018394                            30.0   \n",
       "323                       0.000000  0.000000                             9.0   \n",
       "324                       0.000000  0.000000                             9.0   \n",
       "\n",
       "     ck_oo_numberOfPublicMethods  LDHH_cbo  WCHU_numberOfLinesOfCode  \\\n",
       "0                            NaN       NaN                       NaN   \n",
       "1                            8.0  0.008431                      3.50   \n",
       "2                            7.0  0.021602                     43.12   \n",
       "3                            2.0  0.011859                      4.68   \n",
       "4                           10.0  0.020478                     24.06   \n",
       "..                           ...       ...                       ...   \n",
       "320                          1.0  0.004539                      1.04   \n",
       "321                          1.0  0.000000                      0.00   \n",
       "322                         27.0  0.025180                     23.19   \n",
       "323                          2.0  0.000000                      0.00   \n",
       "324                          2.0  0.000000                      0.00   \n",
       "\n",
       "     CvsExpEntropy  LDHH_numberOfMethods  class  \n",
       "0              NaN                   NaN    NaN  \n",
       "1         0.103594              0.003611  buggy  \n",
       "2         0.328692              0.009906  buggy  \n",
       "3         0.125841              0.001655  clean  \n",
       "4         0.170416              0.007000  buggy  \n",
       "..             ...                   ...    ...  \n",
       "320       0.041507              0.000000  clean  \n",
       "321       0.000000              0.000000  clean  \n",
       "322       0.267032              0.004671  buggy  \n",
       "323       0.000000              0.000000  clean  \n",
       "324       0.000000              0.000000  clean  \n",
       "\n",
       "[325 rows x 62 columns]"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "e4638b45-65f9-4bb0-9dc3-333b188744cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for dt in list_data_relink:\n",
    "    dt.drop(index=dt.index[0], axis=0, inplace=True)\n",
    "    dt['Defective'] = dt['class']\n",
    "    dt.loc[dt['Defective'] == 'clean', 'Defective'] = 'N'\n",
    "    dt.loc[dt['Defective'] == 'buggy', 'Defective'] = 'Y'\n",
    "    dt.drop('class',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "49cd79c0-40c8-4910-b7f9-73b9edf5262a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ck_oo_numberOfPrivateMethods</th>\n",
       "      <th>LDHH_lcom</th>\n",
       "      <th>LDHH_fanIn</th>\n",
       "      <th>numberOfNonTrivialBugsFoundUntil:</th>\n",
       "      <th>WCHU_numberOfPublicAttributes</th>\n",
       "      <th>WCHU_numberOfAttributes</th>\n",
       "      <th>CvsWEntropy</th>\n",
       "      <th>LDHH_numberOfPublicMethods</th>\n",
       "      <th>WCHU_fanIn</th>\n",
       "      <th>LDHH_numberOfPrivateAttributes</th>\n",
       "      <th>...</th>\n",
       "      <th>LDHH_fanOut</th>\n",
       "      <th>LDHH_numberOfMethodsInherited</th>\n",
       "      <th>LDHH_rfc</th>\n",
       "      <th>ck_oo_numberOfMethodsInherited</th>\n",
       "      <th>ck_oo_numberOfPublicMethods</th>\n",
       "      <th>LDHH_cbo</th>\n",
       "      <th>WCHU_numberOfLinesOfCode</th>\n",
       "      <th>CvsExpEntropy</th>\n",
       "      <th>LDHH_numberOfMethods</th>\n",
       "      <th>Defective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.003976</td>\n",
       "      <td>0.005189</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.105389</td>\n",
       "      <td>0.004203</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.004297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010649</td>\n",
       "      <td>0.002227</td>\n",
       "      <td>0.027707</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>4.28</td>\n",
       "      <td>0.209245</td>\n",
       "      <td>0.004770</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0.002264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.032927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.004680</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>5.44</td>\n",
       "      <td>0.054240</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001689</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.061022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.003134</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0.046823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.005692</td>\n",
       "      <td>0.007865</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.14</td>\n",
       "      <td>0.109004</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>5.09</td>\n",
       "      <td>0.004365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.007727</td>\n",
       "      <td>8.66</td>\n",
       "      <td>0.051960</td>\n",
       "      <td>0.006210</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>16</td>\n",
       "      <td>0.007664</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.056587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>10.37</td>\n",
       "      <td>0.121457</td>\n",
       "      <td>0.007955</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>0</td>\n",
       "      <td>0.004142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.027205</td>\n",
       "      <td>0.004887</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.002642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002647</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.007854</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.003189</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.190859</td>\n",
       "      <td>0.004892</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002679</td>\n",
       "      <td>0.004295</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.036016</td>\n",
       "      <td>0.002367</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003134</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.004879</td>\n",
       "      <td>3.41</td>\n",
       "      <td>0.065036</td>\n",
       "      <td>0.002969</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>0</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>0.011023</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.065500</td>\n",
       "      <td>0.003137</td>\n",
       "      <td>6.06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004833</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>55.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.011873</td>\n",
       "      <td>3.93</td>\n",
       "      <td>0.050098</td>\n",
       "      <td>0.003455</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.058844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.002331</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.036310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1497 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ck_oo_numberOfPrivateMethods  LDHH_lcom  LDHH_fanIn  \\\n",
       "1                               0   0.003976    0.005189   \n",
       "2                               0   0.000000    0.000000   \n",
       "3                               8   0.002264    0.000000   \n",
       "4                               2   0.000000    0.001689   \n",
       "5                               1   0.005692    0.007865   \n",
       "...                           ...        ...         ...   \n",
       "1493                           16   0.007664    0.001443   \n",
       "1494                            0   0.004142    0.000000   \n",
       "1495                            0   0.002679    0.004295   \n",
       "1496                            0   0.003033    0.011023   \n",
       "1497                           13   0.000000    0.000000   \n",
       "\n",
       "      numberOfNonTrivialBugsFoundUntil:  WCHU_numberOfPublicAttributes  \\\n",
       "1                                   2.0                           0.00   \n",
       "2                                   0.0                           0.00   \n",
       "3                                   7.0                           0.00   \n",
       "4                                   3.0                           0.00   \n",
       "5                                   3.0                           0.00   \n",
       "...                                 ...                            ...   \n",
       "1493                                8.0                           0.00   \n",
       "1494                                4.0                           1.01   \n",
       "1495                                5.0                           0.00   \n",
       "1496                                1.0                           0.00   \n",
       "1497                                3.0                           0.00   \n",
       "\n",
       "      WCHU_numberOfAttributes  CvsWEntropy  LDHH_numberOfPublicMethods  \\\n",
       "1                        3.03     0.105389                    0.004203   \n",
       "2                        0.00     0.000000                    0.000000   \n",
       "3                        0.00     0.032927                    0.000000   \n",
       "4                        0.00     0.061022                    0.000000   \n",
       "5                        6.14     0.109004                    0.001720   \n",
       "...                       ...          ...                         ...   \n",
       "1493                     0.00     0.056587                    0.000000   \n",
       "1494                     2.02     0.027205                    0.004887   \n",
       "1495                     1.01     0.036016                    0.002367   \n",
       "1496                     0.00     0.065500                    0.003137   \n",
       "1497                     0.00     0.058844                    0.000000   \n",
       "\n",
       "      WCHU_fanIn  LDHH_numberOfPrivateAttributes  ...  LDHH_fanOut  \\\n",
       "1           2.04                        0.004297  ...     0.010649   \n",
       "2           0.00                        0.000000  ...     0.000000   \n",
       "3           0.00                        0.000000  ...     0.002006   \n",
       "4           2.06                        0.000000  ...     0.001873   \n",
       "5           5.09                        0.004365  ...     0.002715   \n",
       "...          ...                             ...  ...          ...   \n",
       "1493        1.01                        0.000000  ...     0.010813   \n",
       "1494        0.00                        0.002642  ...     0.002647   \n",
       "1495        3.05                        0.001510  ...     0.001815   \n",
       "1496        6.06                        0.000000  ...     0.000000   \n",
       "1497        0.00                        0.000000  ...     0.002075   \n",
       "\n",
       "      LDHH_numberOfMethodsInherited  LDHH_rfc  ck_oo_numberOfMethodsInherited  \\\n",
       "1                          0.002227  0.027707                            14.0   \n",
       "2                          0.000000  0.000000                            51.0   \n",
       "3                          0.000713  0.004680                            14.0   \n",
       "4                          0.000000  0.005933                             0.0   \n",
       "5                          0.000000  0.007782                             0.0   \n",
       "...                             ...       ...                             ...   \n",
       "1493                       0.000000  0.019267                             0.0   \n",
       "1494                       0.001324  0.007854                             6.0   \n",
       "1495                       0.000000  0.003134                             6.0   \n",
       "1496                       0.004833  0.003419                            55.0   \n",
       "1497                       0.000000  0.001140                             0.0   \n",
       "\n",
       "      ck_oo_numberOfPublicMethods  LDHH_cbo  WCHU_numberOfLinesOfCode  \\\n",
       "1                             6.0  0.008929                      4.28   \n",
       "2                             3.0  0.000000                      0.00   \n",
       "3                             2.0  0.001619                      5.44   \n",
       "4                             6.0  0.003134                      6.39   \n",
       "5                            18.0  0.007727                      8.66   \n",
       "...                           ...       ...                       ...   \n",
       "1493                          2.0  0.013420                     10.37   \n",
       "1494                         11.0  0.003189                      3.13   \n",
       "1495                          5.0  0.004879                      3.41   \n",
       "1496                         10.0  0.011873                      3.93   \n",
       "1497                         11.0  0.002331                      1.10   \n",
       "\n",
       "      CvsExpEntropy  LDHH_numberOfMethods  Defective  \n",
       "1          0.209245              0.004770          N  \n",
       "2          0.000000              0.000000          N  \n",
       "3          0.054240              0.002453          N  \n",
       "4          0.046823              0.000000          Y  \n",
       "5          0.051960              0.006210          N  \n",
       "...             ...                   ...        ...  \n",
       "1493       0.121457              0.007955          Y  \n",
       "1494       0.190859              0.004892          N  \n",
       "1495       0.065036              0.002969          N  \n",
       "1496       0.050098              0.003455          N  \n",
       "1497       0.036310              0.000000          Y  \n",
       "\n",
       "[1497 rows x 62 columns]"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dataset = [pde]\n",
    "label_dataset = ['pde']\n",
    "\n",
    "list_test = [eq,jdt,lc,ml,pde]  \n",
    "label_test = ['eq','jdt','lc','ml','pde'] \n",
    "\n",
    "my_index = range(0,len(list_test))\n",
    "my_dataset = dict(zip(label_test,list_test))\n",
    "\n",
    "df = list_dataset\n",
    "df = pd.concat(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "a3f48403-eca4-44c9-8827-03fc69a93458",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def adjustdataset_list(list_df):\n",
    "    dt_result = list_df.pop()\n",
    "    \n",
    "    for dt in list_df:\n",
    "        if len(dt.columns) > len(dt_result.columns):\n",
    "            dt_result = adjustdataset(dt,dt_result)\n",
    "        else:\n",
    "            dt_result = adjustdataset(dt_result,dt)    \n",
    "    return dt_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "dea32944-e73e-48a1-98e5-4bd0383adeb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def adjustdataset(dt,dataframe):\n",
    "    dt_copy = dt.copy()\n",
    "    counter = 0\n",
    "    \n",
    "    for col in dataframe.columns:\n",
    "        if not col in dt.columns:\n",
    "            #print(\"Not Exist \",col)\n",
    "            dt_copy.insert(counter,col,-1)\n",
    "        counter += 1\n",
    "\n",
    "    return pd.concat([dt_copy[dataframe.columns], dataframe])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "971ad588-0428-41ee-a03e-ac5d97b73ab8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_distribution(df, columns):\n",
    "    \n",
    "    counter = 0\n",
    "    # Create a figure and a grid of subplots with 4 rows and 10 columns\n",
    "    fig, axes = plt.subplots(5, 8, figsize=(20, 8))\n",
    "    \n",
    "    # Loop through each subplot and add content (optional)\n",
    "    for i in range(5):\n",
    "        for j in range(8):\n",
    "            try:\n",
    "                ax = axes[i, j]\n",
    "                ax.set_title(columns[counter])\n",
    "                ax.plot(df[columns[counter]].sort_values(), norm.pdf(df[columns[counter]].sort_values(), df[columns[counter]].mean(), df[columns[counter]].std())) \n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                counter += 1\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "# Adjust layout to prevent overlapping titles/labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "d7975d15-c9bc-4fd7-8f65-c71b1588958e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessing(dataframe, imputer = None, pt = None, scaler = None, show = True):\n",
    "    \n",
    "    df = dataframe.copy()\n",
    "    \n",
    "    df.loc[(df['Defective'] == 'N'),'Defective']=0\n",
    "    df.loc[(df['Defective'] == 'Y'),'Defective']=1\n",
    "    \n",
    "    change_dtypes = ['Defective']\n",
    "    dict_dtypes = {d:'int64' for d in change_dtypes }\n",
    "    df = df.astype(dict_dtypes)\n",
    "    \n",
    "    columns = df.columns\n",
    "    \n",
    "    if show:\n",
    "        show_distribution(df,df.columns)\n",
    "    \n",
    "    if imputer :\n",
    "        df = imputer.transform(df)\n",
    "    else:\n",
    "        imputer = KNNImputer(n_neighbors=2)\n",
    "        df = imputer.fit_transform(df)\n",
    "    \n",
    "    df = pd.DataFrame(df)\n",
    "    df.columns = columns\n",
    "    \n",
    "    if show:\n",
    "        show_distribution(df,df.columns)\n",
    "    \n",
    "    y = df['Defective']\n",
    "    X = df.drop('Defective',axis=1)\n",
    "    \n",
    "    if pt:\n",
    "        X_norm = pt.transform(X)\n",
    "    else:\n",
    "        pt = PowerTransformer()\n",
    "        X_norm = pt.fit_transform(X)\n",
    "    \n",
    "    X_norm = pd.DataFrame(X)\n",
    "    X_norm.columns = X.columns\n",
    "    \n",
    "    if show:\n",
    "        show_distribution(X_norm,X_norm.columns)\n",
    "\n",
    "    if scaler:\n",
    "        X_norm_scale = scaler.transform(X_norm)\n",
    "    else:\n",
    "        scaler = StandardScaler()\n",
    "        X_norm_scale = scaler.fit_transform(X_norm)\n",
    "        \n",
    "    return pt, scaler, imputer, X_norm_scale, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "6c48181d-c863-463f-8cef-34c3e87d260c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def heat_map(y,result,title):\n",
    "    import seaborn as sns\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    sns.set\n",
    "    _, ax = plt.subplots(figsize=(10,10))\n",
    "    ax = sns.heatmap(confusion_matrix(y, result), annot=True, fmt='d', cmap= ['#09acec','#089dd9','#078fc5','#0681b1','#05668d','#05368d'], annot_kws={\"size\": 40, \"weight\": \"bold\"})  \n",
    "    labels = ['No Defect','Defect']\n",
    "    ax.set_xticklabels(labels, fontsize=30);\n",
    "    ax.set_yticklabels(labels, fontsize=30,rotation=0);\n",
    "    ax.set_ylabel('Prediction', fontsize=30,rotation=0);\n",
    "    ax.set_xlabel('Ground Truth', fontsize=30) #0,1\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "2b292f4e-58d5-48e4-8011-acc2a7edb8c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def score(y,result):\n",
    "    accuracy = accuracy_score(y, result)\n",
    "    f1 = f1_score(y, result, average='weighted')\n",
    "    precision = precision_score(y, result, average='weighted')\n",
    "    recall = recall_score(y, result, average='weighted')\n",
    "    print(\"Accuracy = \" , accuracy, \" Precision = \",precision, \" Recall = \",recall, \" F1-Score = \",f1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "57f6d8de-6436-454d-99dc-063236a341f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "scorers = {\n",
    "            'f1_score': make_scorer(f1_score, average='micro'),\n",
    "            'precision_score': make_scorer(precision_score, average='micro'),\n",
    "            'recall_score': make_scorer(recall_score, average='micro'),\n",
    "            'accuracy_score': make_scorer(accuracy_score)\n",
    "          }\n",
    "search_space={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "c8a69d5d-6055-4398-a83a-73923943d061",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pt, scaler, imputer, X_norm_scale, y = preprocessing(df, show=False)\n",
    "#X_norm_scale_smote, y_smote = X_norm_scale, y\n",
    "smote = SMOTE(random_state=42)\n",
    "X_norm_scale_smote, y_smote = smote.fit_resample(X_norm_scale, y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "f94ee09a-ef5d-4c73-8f10-5447a071aced",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.63219, saving model to sdp-tree-aeeem-0.weights.best.keras\n",
      "66/66 - 2s - loss: 0.6759 - accuracy: 0.6611 - val_loss: 0.6322 - val_accuracy: 0.5948 - 2s/epoch - 24ms/step\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: val_loss improved from 0.63219 to 0.52709, saving model to sdp-tree-aeeem-0.weights.best.keras\n",
      "66/66 - 0s - loss: 0.5269 - accuracy: 0.7589 - val_loss: 0.5271 - val_accuracy: 0.7069 - 194ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: val_loss improved from 0.52709 to 0.45484, saving model to sdp-tree-aeeem-0.weights.best.keras\n",
      "66/66 - 0s - loss: 0.4340 - accuracy: 0.7996 - val_loss: 0.4548 - val_accuracy: 0.7716 - 188ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: val_loss improved from 0.45484 to 0.42981, saving model to sdp-tree-aeeem-0.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3919 - accuracy: 0.8289 - val_loss: 0.4298 - val_accuracy: 0.7974 - 191ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: val_loss improved from 0.42981 to 0.41468, saving model to sdp-tree-aeeem-0.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3560 - accuracy: 0.8476 - val_loss: 0.4147 - val_accuracy: 0.8103 - 167ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: val_loss improved from 0.41468 to 0.38588, saving model to sdp-tree-aeeem-0.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3290 - accuracy: 0.8648 - val_loss: 0.3859 - val_accuracy: 0.8362 - 168ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: val_loss improved from 0.38588 to 0.38100, saving model to sdp-tree-aeeem-0.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3104 - accuracy: 0.8682 - val_loss: 0.3810 - val_accuracy: 0.8147 - 170ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: val_loss improved from 0.38100 to 0.34371, saving model to sdp-tree-aeeem-0.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2755 - accuracy: 0.8883 - val_loss: 0.3437 - val_accuracy: 0.8448 - 182ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.34371\n",
      "66/66 - 0s - loss: 0.2710 - accuracy: 0.8902 - val_loss: 0.3446 - val_accuracy: 0.8362 - 186ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.34371\n",
      "66/66 - 0s - loss: 0.2466 - accuracy: 0.9070 - val_loss: 0.3539 - val_accuracy: 0.8276 - 135ms/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.34371\n",
      "66/66 - 0s - loss: 0.2373 - accuracy: 0.9151 - val_loss: 0.3442 - val_accuracy: 0.8405 - 138ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: val_loss improved from 0.34371 to 0.32411, saving model to sdp-tree-aeeem-0.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2158 - accuracy: 0.9166 - val_loss: 0.3241 - val_accuracy: 0.8534 - 167ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: val_loss improved from 0.32411 to 0.30660, saving model to sdp-tree-aeeem-0.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2132 - accuracy: 0.9223 - val_loss: 0.3066 - val_accuracy: 0.8491 - 176ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: val_loss improved from 0.30660 to 0.28867, saving model to sdp-tree-aeeem-0.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2005 - accuracy: 0.9204 - val_loss: 0.2887 - val_accuracy: 0.8750 - 178ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.28867\n",
      "66/66 - 0s - loss: 0.2016 - accuracy: 0.9214 - val_loss: 0.2989 - val_accuracy: 0.8707 - 143ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.28867\n",
      "66/66 - 0s - loss: 0.1806 - accuracy: 0.9319 - val_loss: 0.2910 - val_accuracy: 0.8707 - 122ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: val_loss improved from 0.28867 to 0.25612, saving model to sdp-tree-aeeem-0.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1733 - accuracy: 0.9338 - val_loss: 0.2561 - val_accuracy: 0.8922 - 161ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: val_loss improved from 0.25612 to 0.25113, saving model to sdp-tree-aeeem-0.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1686 - accuracy: 0.9396 - val_loss: 0.2511 - val_accuracy: 0.8836 - 192ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.25113\n",
      "66/66 - 0s - loss: 0.1565 - accuracy: 0.9410 - val_loss: 0.2723 - val_accuracy: 0.8793 - 121ms/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: val_loss improved from 0.25113 to 0.22794, saving model to sdp-tree-aeeem-0.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1546 - accuracy: 0.9410 - val_loss: 0.2279 - val_accuracy: 0.9009 - 171ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.22794\n",
      "66/66 - 0s - loss: 0.1572 - accuracy: 0.9377 - val_loss: 0.2375 - val_accuracy: 0.9095 - 121ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.22794\n",
      "66/66 - 0s - loss: 0.1575 - accuracy: 0.9410 - val_loss: 0.2559 - val_accuracy: 0.8879 - 116ms/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.22794\n",
      "66/66 - 0s - loss: 0.1456 - accuracy: 0.9468 - val_loss: 0.2389 - val_accuracy: 0.9052 - 115ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.22794\n",
      "66/66 - 0s - loss: 0.1291 - accuracy: 0.9525 - val_loss: 0.2399 - val_accuracy: 0.9138 - 151ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.22794\n",
      "66/66 - 0s - loss: 0.1254 - accuracy: 0.9573 - val_loss: 0.2292 - val_accuracy: 0.9138 - 124ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.22794\n",
      "66/66 - 0s - loss: 0.1156 - accuracy: 0.9593 - val_loss: 0.2469 - val_accuracy: 0.9009 - 115ms/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.22794\n",
      "66/66 - 0s - loss: 0.1383 - accuracy: 0.9535 - val_loss: 0.2391 - val_accuracy: 0.9052 - 120ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: val_loss improved from 0.22794 to 0.21187, saving model to sdp-tree-aeeem-0.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1207 - accuracy: 0.9583 - val_loss: 0.2119 - val_accuracy: 0.9095 - 175ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.21187\n",
      "66/66 - 0s - loss: 0.1286 - accuracy: 0.9564 - val_loss: 0.2397 - val_accuracy: 0.9009 - 151ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.21187\n",
      "66/66 - 0s - loss: 0.1185 - accuracy: 0.9535 - val_loss: 0.2165 - val_accuracy: 0.9138 - 150ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.21187\n",
      "66/66 - 0s - loss: 0.1007 - accuracy: 0.9631 - val_loss: 0.2276 - val_accuracy: 0.9052 - 126ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.21187\n",
      "66/66 - 0s - loss: 0.1113 - accuracy: 0.9607 - val_loss: 0.2153 - val_accuracy: 0.9095 - 125ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: val_loss improved from 0.21187 to 0.20867, saving model to sdp-tree-aeeem-0.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1186 - accuracy: 0.9521 - val_loss: 0.2087 - val_accuracy: 0.9181 - 194ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.20867\n",
      "66/66 - 0s - loss: 0.1111 - accuracy: 0.9616 - val_loss: 0.2210 - val_accuracy: 0.9052 - 133ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.20867\n",
      "66/66 - 0s - loss: 0.1026 - accuracy: 0.9621 - val_loss: 0.2249 - val_accuracy: 0.9009 - 121ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 36: val_loss improved from 0.20867 to 0.20233, saving model to sdp-tree-aeeem-0.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0902 - accuracy: 0.9693 - val_loss: 0.2023 - val_accuracy: 0.9138 - 168ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.20233\n",
      "66/66 - 0s - loss: 0.0929 - accuracy: 0.9679 - val_loss: 0.2078 - val_accuracy: 0.9095 - 120ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.20233\n",
      "66/66 - 0s - loss: 0.0955 - accuracy: 0.9669 - val_loss: 0.2083 - val_accuracy: 0.9138 - 139ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.20233\n",
      "66/66 - 0s - loss: 0.0890 - accuracy: 0.9708 - val_loss: 0.2160 - val_accuracy: 0.9181 - 147ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.20233\n",
      "66/66 - 0s - loss: 0.0827 - accuracy: 0.9693 - val_loss: 0.2353 - val_accuracy: 0.9138 - 119ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.20233\n",
      "66/66 - 0s - loss: 0.0911 - accuracy: 0.9640 - val_loss: 0.2226 - val_accuracy: 0.9052 - 132ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 42: val_loss improved from 0.20233 to 0.18330, saving model to sdp-tree-aeeem-0.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0833 - accuracy: 0.9679 - val_loss: 0.1833 - val_accuracy: 0.9224 - 193ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.18330\n",
      "66/66 - 0s - loss: 0.1087 - accuracy: 0.9559 - val_loss: 0.2084 - val_accuracy: 0.9138 - 135ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.18330\n",
      "66/66 - 0s - loss: 0.0817 - accuracy: 0.9688 - val_loss: 0.2171 - val_accuracy: 0.9009 - 166ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.18330\n",
      "66/66 - 0s - loss: 0.1054 - accuracy: 0.9626 - val_loss: 0.2313 - val_accuracy: 0.9181 - 125ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.18330\n",
      "66/66 - 0s - loss: 0.0940 - accuracy: 0.9684 - val_loss: 0.2217 - val_accuracy: 0.9181 - 125ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.18330\n",
      "66/66 - 0s - loss: 0.0779 - accuracy: 0.9712 - val_loss: 0.2271 - val_accuracy: 0.9181 - 124ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.18330\n",
      "66/66 - 0s - loss: 0.0941 - accuracy: 0.9664 - val_loss: 0.1915 - val_accuracy: 0.9224 - 126ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.18330\n",
      "66/66 - 0s - loss: 0.0847 - accuracy: 0.9674 - val_loss: 0.2175 - val_accuracy: 0.9181 - 123ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.18330\n",
      "66/66 - 0s - loss: 0.0737 - accuracy: 0.9717 - val_loss: 0.2237 - val_accuracy: 0.9095 - 118ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.18330\n",
      "66/66 - 0s - loss: 0.0745 - accuracy: 0.9722 - val_loss: 0.2133 - val_accuracy: 0.9224 - 120ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.18330\n",
      "66/66 - 0s - loss: 0.0741 - accuracy: 0.9746 - val_loss: 0.2290 - val_accuracy: 0.9095 - 134ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.18330\n",
      "66/66 - 0s - loss: 0.0939 - accuracy: 0.9636 - val_loss: 0.2066 - val_accuracy: 0.9138 - 133ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.18330\n",
      "66/66 - 0s - loss: 0.0596 - accuracy: 0.9818 - val_loss: 0.2191 - val_accuracy: 0.9181 - 123ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.18330\n",
      "66/66 - 0s - loss: 0.0702 - accuracy: 0.9736 - val_loss: 0.2172 - val_accuracy: 0.9181 - 123ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.18330\n",
      "66/66 - 0s - loss: 0.0769 - accuracy: 0.9746 - val_loss: 0.1864 - val_accuracy: 0.9310 - 118ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.18330\n",
      "66/66 - 0s - loss: 0.0682 - accuracy: 0.9770 - val_loss: 0.2104 - val_accuracy: 0.9138 - 119ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.18330\n",
      "66/66 - 0s - loss: 0.0784 - accuracy: 0.9693 - val_loss: 0.2016 - val_accuracy: 0.9267 - 118ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: val_loss improved from 0.18330 to 0.18303, saving model to sdp-tree-aeeem-0.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0575 - accuracy: 0.9818 - val_loss: 0.1830 - val_accuracy: 0.9267 - 166ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.18303\n",
      "66/66 - 0s - loss: 0.0633 - accuracy: 0.9760 - val_loss: 0.1964 - val_accuracy: 0.9224 - 118ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.18303\n",
      "66/66 - 0s - loss: 0.0661 - accuracy: 0.9751 - val_loss: 0.2023 - val_accuracy: 0.9095 - 126ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.18303\n",
      "66/66 - 0s - loss: 0.0648 - accuracy: 0.9751 - val_loss: 0.1922 - val_accuracy: 0.9138 - 130ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.18303\n",
      "66/66 - 0s - loss: 0.0587 - accuracy: 0.9789 - val_loss: 0.2015 - val_accuracy: 0.9267 - 146ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.18303\n",
      "66/66 - 0s - loss: 0.0768 - accuracy: 0.9703 - val_loss: 0.2297 - val_accuracy: 0.9181 - 133ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.18303\n",
      "66/66 - 0s - loss: 0.0637 - accuracy: 0.9765 - val_loss: 0.2170 - val_accuracy: 0.9095 - 141ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.18303\n",
      "66/66 - 0s - loss: 0.0622 - accuracy: 0.9779 - val_loss: 0.2192 - val_accuracy: 0.9095 - 117ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.18303\n",
      "66/66 - 0s - loss: 0.0630 - accuracy: 0.9779 - val_loss: 0.1906 - val_accuracy: 0.9224 - 120ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.18303\n",
      "66/66 - 0s - loss: 0.0627 - accuracy: 0.9756 - val_loss: 0.2131 - val_accuracy: 0.9224 - 117ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.18303\n",
      "66/66 - 0s - loss: 0.0635 - accuracy: 0.9760 - val_loss: 0.2196 - val_accuracy: 0.9267 - 120ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.18303\n",
      "66/66 - 0s - loss: 0.0592 - accuracy: 0.9827 - val_loss: 0.2181 - val_accuracy: 0.9224 - 127ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.18303\n",
      "66/66 - 0s - loss: 0.0756 - accuracy: 0.9712 - val_loss: 0.2053 - val_accuracy: 0.9267 - 119ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.18303\n",
      "66/66 - 0s - loss: 0.0701 - accuracy: 0.9765 - val_loss: 0.1999 - val_accuracy: 0.9267 - 137ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.18303\n",
      "66/66 - 0s - loss: 0.0469 - accuracy: 0.9851 - val_loss: 0.2031 - val_accuracy: 0.9267 - 117ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: val_loss improved from 0.18303 to 0.17660, saving model to sdp-tree-aeeem-0.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0562 - accuracy: 0.9794 - val_loss: 0.1766 - val_accuracy: 0.9397 - 184ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.17660\n",
      "66/66 - 0s - loss: 0.0676 - accuracy: 0.9751 - val_loss: 0.2032 - val_accuracy: 0.9224 - 145ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.17660\n",
      "66/66 - 0s - loss: 0.0656 - accuracy: 0.9784 - val_loss: 0.2181 - val_accuracy: 0.9181 - 127ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.17660\n",
      "66/66 - 0s - loss: 0.0692 - accuracy: 0.9717 - val_loss: 0.2153 - val_accuracy: 0.9181 - 128ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.17660\n",
      "66/66 - 0s - loss: 0.0389 - accuracy: 0.9856 - val_loss: 0.2215 - val_accuracy: 0.9095 - 133ms/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.17660\n",
      "66/66 - 0s - loss: 0.0570 - accuracy: 0.9832 - val_loss: 0.2528 - val_accuracy: 0.9138 - 125ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.17660\n",
      "66/66 - 0s - loss: 0.0528 - accuracy: 0.9784 - val_loss: 0.2083 - val_accuracy: 0.9267 - 117ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.17660\n",
      "66/66 - 0s - loss: 0.0567 - accuracy: 0.9808 - val_loss: 0.2041 - val_accuracy: 0.9310 - 116ms/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.17660\n",
      "66/66 - 0s - loss: 0.0576 - accuracy: 0.9770 - val_loss: 0.2474 - val_accuracy: 0.9181 - 117ms/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.17660\n",
      "66/66 - 0s - loss: 0.0575 - accuracy: 0.9799 - val_loss: 0.2304 - val_accuracy: 0.9224 - 214ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.17660\n",
      "66/66 - 0s - loss: 0.0538 - accuracy: 0.9813 - val_loss: 0.2385 - val_accuracy: 0.9181 - 122ms/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.17660\n",
      "66/66 - 0s - loss: 0.0547 - accuracy: 0.9784 - val_loss: 0.2399 - val_accuracy: 0.9224 - 119ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.17660\n",
      "66/66 - 0s - loss: 0.0504 - accuracy: 0.9823 - val_loss: 0.2372 - val_accuracy: 0.9224 - 138ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.17660\n",
      "66/66 - 0s - loss: 0.0582 - accuracy: 0.9789 - val_loss: 0.2729 - val_accuracy: 0.9181 - 124ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.17660\n",
      "66/66 - 0s - loss: 0.0554 - accuracy: 0.9789 - val_loss: 0.2645 - val_accuracy: 0.9224 - 116ms/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.17660\n",
      "66/66 - 0s - loss: 0.0454 - accuracy: 0.9827 - val_loss: 0.2291 - val_accuracy: 0.9310 - 118ms/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.17660\n",
      "66/66 - 0s - loss: 0.0418 - accuracy: 0.9866 - val_loss: 0.2240 - val_accuracy: 0.9224 - 118ms/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.17660\n",
      "66/66 - 0s - loss: 0.0391 - accuracy: 0.9871 - val_loss: 0.2593 - val_accuracy: 0.9224 - 117ms/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.17660\n",
      "66/66 - 0s - loss: 0.0469 - accuracy: 0.9837 - val_loss: 0.2369 - val_accuracy: 0.9224 - 134ms/epoch - 2ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.17660\n",
      "66/66 - 0s - loss: 0.0466 - accuracy: 0.9851 - val_loss: 0.2319 - val_accuracy: 0.9181 - 138ms/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.17660\n",
      "66/66 - 0s - loss: 0.0472 - accuracy: 0.9861 - val_loss: 0.2247 - val_accuracy: 0.9181 - 129ms/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.17660\n",
      "66/66 - 0s - loss: 0.0510 - accuracy: 0.9803 - val_loss: 0.2456 - val_accuracy: 0.9267 - 126ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.17660\n",
      "66/66 - 0s - loss: 0.0465 - accuracy: 0.9827 - val_loss: 0.2717 - val_accuracy: 0.9138 - 135ms/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.17660\n",
      "66/66 - 0s - loss: 0.0512 - accuracy: 0.9823 - val_loss: 0.2645 - val_accuracy: 0.9267 - 127ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.17660\n",
      "66/66 - 0s - loss: 0.0525 - accuracy: 0.9799 - val_loss: 0.2474 - val_accuracy: 0.9267 - 126ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.17660\n",
      "66/66 - 0s - loss: 0.0527 - accuracy: 0.9818 - val_loss: 0.2167 - val_accuracy: 0.9267 - 124ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.17660\n",
      "66/66 - 0s - loss: 0.0407 - accuracy: 0.9851 - val_loss: 0.2210 - val_accuracy: 0.9224 - 122ms/epoch - 2ms/step\n",
      "73/73 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Evaluate on training data\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0332 - accuracy: 0.9909\n",
      "test loss, test acc: [0.03321421891450882, 0.9909404516220093]\n",
      "Evaluate on test data\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3379 - accuracy: 0.9225\n",
      "test loss, test acc: [0.3379405736923218, 0.9224806427955627]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/manifold/_isomap.py:384: UserWarning: The number of connected components of the neighbors graph is 2 > 1. Completing the graph to fit Isomap might be slow. Increase the number of neighbors to avoid this issue.\n",
      "  self._fit_transform(X)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/scipy/sparse/_index.py:100: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.50702, saving model to sdp-tree-aeeem-1.weights.best.keras\n",
      "66/66 - 2s - loss: 0.6555 - accuracy: 0.6798 - val_loss: 0.5070 - val_accuracy: 0.7414 - 2s/epoch - 24ms/step\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: val_loss improved from 0.50702 to 0.47418, saving model to sdp-tree-aeeem-1.weights.best.keras\n",
      "66/66 - 0s - loss: 0.4711 - accuracy: 0.7943 - val_loss: 0.4742 - val_accuracy: 0.7888 - 201ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: val_loss improved from 0.47418 to 0.45244, saving model to sdp-tree-aeeem-1.weights.best.keras\n",
      "66/66 - 0s - loss: 0.4078 - accuracy: 0.8241 - val_loss: 0.4524 - val_accuracy: 0.7802 - 175ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: val_loss improved from 0.45244 to 0.41352, saving model to sdp-tree-aeeem-1.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3755 - accuracy: 0.8375 - val_loss: 0.4135 - val_accuracy: 0.8060 - 180ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: val_loss improved from 0.41352 to 0.38594, saving model to sdp-tree-aeeem-1.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3286 - accuracy: 0.8658 - val_loss: 0.3859 - val_accuracy: 0.8233 - 169ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: val_loss improved from 0.38594 to 0.37541, saving model to sdp-tree-aeeem-1.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3069 - accuracy: 0.8730 - val_loss: 0.3754 - val_accuracy: 0.8190 - 175ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: val_loss improved from 0.37541 to 0.34518, saving model to sdp-tree-aeeem-1.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2832 - accuracy: 0.8802 - val_loss: 0.3452 - val_accuracy: 0.8405 - 204ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: val_loss improved from 0.34518 to 0.34382, saving model to sdp-tree-aeeem-1.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2707 - accuracy: 0.8893 - val_loss: 0.3438 - val_accuracy: 0.8534 - 207ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: val_loss improved from 0.34382 to 0.32405, saving model to sdp-tree-aeeem-1.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2464 - accuracy: 0.9032 - val_loss: 0.3241 - val_accuracy: 0.8664 - 167ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: val_loss improved from 0.32405 to 0.30624, saving model to sdp-tree-aeeem-1.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2310 - accuracy: 0.9123 - val_loss: 0.3062 - val_accuracy: 0.8750 - 173ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.30624\n",
      "66/66 - 0s - loss: 0.2151 - accuracy: 0.9219 - val_loss: 0.3093 - val_accuracy: 0.8793 - 126ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: val_loss improved from 0.30624 to 0.29157, saving model to sdp-tree-aeeem-1.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2060 - accuracy: 0.9199 - val_loss: 0.2916 - val_accuracy: 0.8750 - 190ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: val_loss improved from 0.29157 to 0.23736, saving model to sdp-tree-aeeem-1.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1863 - accuracy: 0.9334 - val_loss: 0.2374 - val_accuracy: 0.9052 - 169ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.23736\n",
      "66/66 - 0s - loss: 0.1812 - accuracy: 0.9334 - val_loss: 0.2543 - val_accuracy: 0.9009 - 133ms/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.23736\n",
      "66/66 - 0s - loss: 0.1755 - accuracy: 0.9276 - val_loss: 0.2418 - val_accuracy: 0.9009 - 123ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.23736\n",
      "66/66 - 0s - loss: 0.1644 - accuracy: 0.9377 - val_loss: 0.2374 - val_accuracy: 0.8836 - 143ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: val_loss improved from 0.23736 to 0.22232, saving model to sdp-tree-aeeem-1.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1563 - accuracy: 0.9453 - val_loss: 0.2223 - val_accuracy: 0.9052 - 160ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.22232\n",
      "66/66 - 0s - loss: 0.1386 - accuracy: 0.9477 - val_loss: 0.2244 - val_accuracy: 0.9138 - 128ms/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: val_loss improved from 0.22232 to 0.22110, saving model to sdp-tree-aeeem-1.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1489 - accuracy: 0.9449 - val_loss: 0.2211 - val_accuracy: 0.8966 - 162ms/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: val_loss improved from 0.22110 to 0.21490, saving model to sdp-tree-aeeem-1.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1306 - accuracy: 0.9516 - val_loss: 0.2149 - val_accuracy: 0.9009 - 167ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: val_loss improved from 0.21490 to 0.21151, saving model to sdp-tree-aeeem-1.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1270 - accuracy: 0.9593 - val_loss: 0.2115 - val_accuracy: 0.9138 - 167ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: val_loss improved from 0.21151 to 0.17756, saving model to sdp-tree-aeeem-1.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1225 - accuracy: 0.9521 - val_loss: 0.1776 - val_accuracy: 0.9138 - 184ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: val_loss improved from 0.17756 to 0.16731, saving model to sdp-tree-aeeem-1.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1197 - accuracy: 0.9559 - val_loss: 0.1673 - val_accuracy: 0.9310 - 168ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: val_loss improved from 0.16731 to 0.16652, saving model to sdp-tree-aeeem-1.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1156 - accuracy: 0.9564 - val_loss: 0.1665 - val_accuracy: 0.9181 - 179ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: val_loss improved from 0.16652 to 0.16297, saving model to sdp-tree-aeeem-1.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0927 - accuracy: 0.9698 - val_loss: 0.1630 - val_accuracy: 0.9310 - 171ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.16297\n",
      "66/66 - 0s - loss: 0.1059 - accuracy: 0.9631 - val_loss: 0.1689 - val_accuracy: 0.9181 - 128ms/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.16297\n",
      "66/66 - 0s - loss: 0.0916 - accuracy: 0.9669 - val_loss: 0.1759 - val_accuracy: 0.9310 - 125ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: val_loss improved from 0.16297 to 0.15120, saving model to sdp-tree-aeeem-1.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1049 - accuracy: 0.9578 - val_loss: 0.1512 - val_accuracy: 0.9353 - 159ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.15120\n",
      "66/66 - 0s - loss: 0.0990 - accuracy: 0.9645 - val_loss: 0.1591 - val_accuracy: 0.9353 - 130ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.15120\n",
      "66/66 - 0s - loss: 0.0945 - accuracy: 0.9698 - val_loss: 0.1560 - val_accuracy: 0.9397 - 121ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.15120\n",
      "66/66 - 0s - loss: 0.0811 - accuracy: 0.9712 - val_loss: 0.1604 - val_accuracy: 0.9310 - 124ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.15120\n",
      "66/66 - 0s - loss: 0.0931 - accuracy: 0.9664 - val_loss: 0.1636 - val_accuracy: 0.9267 - 130ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.15120\n",
      "66/66 - 0s - loss: 0.0786 - accuracy: 0.9703 - val_loss: 0.1553 - val_accuracy: 0.9353 - 154ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.15120\n",
      "66/66 - 0s - loss: 0.0900 - accuracy: 0.9660 - val_loss: 0.1601 - val_accuracy: 0.9353 - 127ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.15120\n",
      "66/66 - 0s - loss: 0.0921 - accuracy: 0.9688 - val_loss: 0.1640 - val_accuracy: 0.9267 - 120ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.15120\n",
      "66/66 - 0s - loss: 0.0867 - accuracy: 0.9684 - val_loss: 0.1645 - val_accuracy: 0.9224 - 118ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.15120\n",
      "66/66 - 0s - loss: 0.0682 - accuracy: 0.9803 - val_loss: 0.1905 - val_accuracy: 0.9052 - 120ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 38: val_loss improved from 0.15120 to 0.15115, saving model to sdp-tree-aeeem-1.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0923 - accuracy: 0.9616 - val_loss: 0.1511 - val_accuracy: 0.9310 - 163ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.15115\n",
      "66/66 - 0s - loss: 0.0775 - accuracy: 0.9708 - val_loss: 0.1583 - val_accuracy: 0.9310 - 123ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 40: val_loss improved from 0.15115 to 0.14763, saving model to sdp-tree-aeeem-1.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0765 - accuracy: 0.9732 - val_loss: 0.1476 - val_accuracy: 0.9440 - 161ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: val_loss improved from 0.14763 to 0.13426, saving model to sdp-tree-aeeem-1.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0764 - accuracy: 0.9717 - val_loss: 0.1343 - val_accuracy: 0.9440 - 166ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.13426\n",
      "66/66 - 0s - loss: 0.0654 - accuracy: 0.9794 - val_loss: 0.1535 - val_accuracy: 0.9397 - 126ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.13426\n",
      "66/66 - 0s - loss: 0.0814 - accuracy: 0.9712 - val_loss: 0.1890 - val_accuracy: 0.9181 - 151ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.13426\n",
      "66/66 - 0s - loss: 0.0685 - accuracy: 0.9775 - val_loss: 0.1623 - val_accuracy: 0.9267 - 159ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.13426\n",
      "66/66 - 0s - loss: 0.0764 - accuracy: 0.9717 - val_loss: 0.1588 - val_accuracy: 0.9224 - 138ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.13426\n",
      "66/66 - 0s - loss: 0.0855 - accuracy: 0.9650 - val_loss: 0.1534 - val_accuracy: 0.9310 - 126ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.13426\n",
      "66/66 - 0s - loss: 0.0790 - accuracy: 0.9741 - val_loss: 0.1453 - val_accuracy: 0.9440 - 122ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.13426\n",
      "66/66 - 0s - loss: 0.0745 - accuracy: 0.9708 - val_loss: 0.1447 - val_accuracy: 0.9526 - 121ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.13426\n",
      "66/66 - 0s - loss: 0.0713 - accuracy: 0.9756 - val_loss: 0.1781 - val_accuracy: 0.9267 - 120ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.13426\n",
      "66/66 - 0s - loss: 0.0675 - accuracy: 0.9756 - val_loss: 0.1347 - val_accuracy: 0.9397 - 124ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 51: val_loss improved from 0.13426 to 0.13141, saving model to sdp-tree-aeeem-1.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0584 - accuracy: 0.9823 - val_loss: 0.1314 - val_accuracy: 0.9440 - 160ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.13141\n",
      "66/66 - 0s - loss: 0.0618 - accuracy: 0.9779 - val_loss: 0.1515 - val_accuracy: 0.9440 - 128ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.13141\n",
      "66/66 - 0s - loss: 0.0811 - accuracy: 0.9664 - val_loss: 0.1529 - val_accuracy: 0.9397 - 121ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 54: val_loss improved from 0.13141 to 0.12393, saving model to sdp-tree-aeeem-1.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0712 - accuracy: 0.9722 - val_loss: 0.1239 - val_accuracy: 0.9483 - 162ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.12393\n",
      "66/66 - 0s - loss: 0.0635 - accuracy: 0.9756 - val_loss: 0.1353 - val_accuracy: 0.9397 - 127ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.12393\n",
      "66/66 - 0s - loss: 0.0604 - accuracy: 0.9779 - val_loss: 0.1591 - val_accuracy: 0.9440 - 123ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.12393\n",
      "66/66 - 0s - loss: 0.0626 - accuracy: 0.9779 - val_loss: 0.1343 - val_accuracy: 0.9483 - 143ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.12393\n",
      "66/66 - 0s - loss: 0.0731 - accuracy: 0.9722 - val_loss: 0.1405 - val_accuracy: 0.9397 - 139ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.12393\n",
      "66/66 - 0s - loss: 0.0587 - accuracy: 0.9813 - val_loss: 0.1545 - val_accuracy: 0.9440 - 122ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.12393\n",
      "66/66 - 0s - loss: 0.0602 - accuracy: 0.9823 - val_loss: 0.1477 - val_accuracy: 0.9483 - 120ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.12393\n",
      "66/66 - 0s - loss: 0.0538 - accuracy: 0.9799 - val_loss: 0.1663 - val_accuracy: 0.9267 - 119ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.12393\n",
      "66/66 - 0s - loss: 0.0597 - accuracy: 0.9789 - val_loss: 0.1433 - val_accuracy: 0.9397 - 121ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.12393\n",
      "66/66 - 0s - loss: 0.0607 - accuracy: 0.9765 - val_loss: 0.1373 - val_accuracy: 0.9526 - 119ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.12393\n",
      "66/66 - 0s - loss: 0.0683 - accuracy: 0.9736 - val_loss: 0.1492 - val_accuracy: 0.9483 - 119ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.12393\n",
      "66/66 - 0s - loss: 0.0559 - accuracy: 0.9803 - val_loss: 0.1615 - val_accuracy: 0.9310 - 120ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.12393\n",
      "66/66 - 0s - loss: 0.0510 - accuracy: 0.9827 - val_loss: 0.1536 - val_accuracy: 0.9483 - 119ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.12393\n",
      "66/66 - 0s - loss: 0.0686 - accuracy: 0.9746 - val_loss: 0.1384 - val_accuracy: 0.9440 - 121ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.12393\n",
      "66/66 - 0s - loss: 0.0537 - accuracy: 0.9799 - val_loss: 0.1366 - val_accuracy: 0.9483 - 120ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.12393\n",
      "66/66 - 0s - loss: 0.0566 - accuracy: 0.9794 - val_loss: 0.1567 - val_accuracy: 0.9267 - 120ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.12393\n",
      "66/66 - 0s - loss: 0.0502 - accuracy: 0.9832 - val_loss: 0.1482 - val_accuracy: 0.9397 - 119ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.12393\n",
      "66/66 - 0s - loss: 0.0504 - accuracy: 0.9799 - val_loss: 0.1263 - val_accuracy: 0.9440 - 123ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.12393\n",
      "66/66 - 0s - loss: 0.0544 - accuracy: 0.9794 - val_loss: 0.1574 - val_accuracy: 0.9440 - 118ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.12393\n",
      "66/66 - 0s - loss: 0.0539 - accuracy: 0.9818 - val_loss: 0.1566 - val_accuracy: 0.9310 - 122ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.12393\n",
      "66/66 - 0s - loss: 0.0598 - accuracy: 0.9775 - val_loss: 0.1304 - val_accuracy: 0.9440 - 122ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: val_loss improved from 0.12393 to 0.11387, saving model to sdp-tree-aeeem-1.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0513 - accuracy: 0.9803 - val_loss: 0.1139 - val_accuracy: 0.9483 - 166ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.11387\n",
      "66/66 - 0s - loss: 0.0416 - accuracy: 0.9856 - val_loss: 0.1248 - val_accuracy: 0.9440 - 153ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: val_loss improved from 0.11387 to 0.11264, saving model to sdp-tree-aeeem-1.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0518 - accuracy: 0.9803 - val_loss: 0.1126 - val_accuracy: 0.9483 - 165ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.11264\n",
      "66/66 - 0s - loss: 0.0445 - accuracy: 0.9861 - val_loss: 0.1154 - val_accuracy: 0.9612 - 127ms/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.11264\n",
      "66/66 - 0s - loss: 0.0502 - accuracy: 0.9818 - val_loss: 0.1243 - val_accuracy: 0.9569 - 121ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.11264\n",
      "66/66 - 0s - loss: 0.0508 - accuracy: 0.9803 - val_loss: 0.1336 - val_accuracy: 0.9612 - 120ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.11264\n",
      "66/66 - 0s - loss: 0.0568 - accuracy: 0.9808 - val_loss: 0.1411 - val_accuracy: 0.9353 - 137ms/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.11264\n",
      "66/66 - 0s - loss: 0.0431 - accuracy: 0.9866 - val_loss: 0.1149 - val_accuracy: 0.9526 - 135ms/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.11264\n",
      "66/66 - 0s - loss: 0.0480 - accuracy: 0.9823 - val_loss: 0.1531 - val_accuracy: 0.9310 - 154ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.11264\n",
      "66/66 - 0s - loss: 0.0458 - accuracy: 0.9847 - val_loss: 0.1341 - val_accuracy: 0.9440 - 121ms/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.11264\n",
      "66/66 - 0s - loss: 0.0392 - accuracy: 0.9861 - val_loss: 0.1289 - val_accuracy: 0.9483 - 126ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.11264\n",
      "66/66 - 0s - loss: 0.0534 - accuracy: 0.9784 - val_loss: 0.1168 - val_accuracy: 0.9612 - 124ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.11264\n",
      "66/66 - 0s - loss: 0.0386 - accuracy: 0.9847 - val_loss: 0.1351 - val_accuracy: 0.9483 - 124ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.11264\n",
      "66/66 - 0s - loss: 0.0387 - accuracy: 0.9866 - val_loss: 0.1557 - val_accuracy: 0.9397 - 133ms/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.11264\n",
      "66/66 - 0s - loss: 0.0425 - accuracy: 0.9856 - val_loss: 0.1324 - val_accuracy: 0.9569 - 123ms/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: val_loss improved from 0.11264 to 0.10156, saving model to sdp-tree-aeeem-1.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0359 - accuracy: 0.9866 - val_loss: 0.1016 - val_accuracy: 0.9655 - 164ms/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.10156\n",
      "66/66 - 0s - loss: 0.0433 - accuracy: 0.9861 - val_loss: 0.1388 - val_accuracy: 0.9526 - 142ms/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.10156\n",
      "66/66 - 0s - loss: 0.0437 - accuracy: 0.9837 - val_loss: 0.1434 - val_accuracy: 0.9397 - 120ms/epoch - 2ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.10156\n",
      "66/66 - 0s - loss: 0.0369 - accuracy: 0.9895 - val_loss: 0.1382 - val_accuracy: 0.9440 - 120ms/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.10156\n",
      "66/66 - 0s - loss: 0.0462 - accuracy: 0.9832 - val_loss: 0.1331 - val_accuracy: 0.9526 - 124ms/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.10156\n",
      "66/66 - 0s - loss: 0.0312 - accuracy: 0.9880 - val_loss: 0.1183 - val_accuracy: 0.9526 - 127ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.10156\n",
      "66/66 - 0s - loss: 0.0405 - accuracy: 0.9851 - val_loss: 0.1244 - val_accuracy: 0.9440 - 127ms/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.10156\n",
      "66/66 - 0s - loss: 0.0298 - accuracy: 0.9919 - val_loss: 0.1426 - val_accuracy: 0.9440 - 121ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.10156\n",
      "66/66 - 0s - loss: 0.0434 - accuracy: 0.9851 - val_loss: 0.1176 - val_accuracy: 0.9526 - 132ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.10156\n",
      "66/66 - 0s - loss: 0.0377 - accuracy: 0.9885 - val_loss: 0.1195 - val_accuracy: 0.9483 - 121ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.10156\n",
      "66/66 - 0s - loss: 0.0438 - accuracy: 0.9856 - val_loss: 0.1442 - val_accuracy: 0.9310 - 123ms/epoch - 2ms/step\n",
      "73/73 [==============================] - 0s 980us/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Evaluate on training data\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0179 - accuracy: 0.9944\n",
      "test loss, test acc: [0.01792730577290058, 0.9943917393684387]\n",
      "Evaluate on test data\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.9070\n",
      "test loss, test acc: [0.4803639352321625, 0.9069767594337463]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/manifold/_isomap.py:384: UserWarning: The number of connected components of the neighbors graph is 2 > 1. Completing the graph to fit Isomap might be slow. Increase the number of neighbors to avoid this issue.\n",
      "  self._fit_transform(X)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/scipy/sparse/_index.py:100: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.46174, saving model to sdp-tree-aeeem-2.weights.best.keras\n",
      "66/66 - 2s - loss: 0.7330 - accuracy: 0.6347 - val_loss: 0.4617 - val_accuracy: 0.7845 - 2s/epoch - 25ms/step\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: val_loss improved from 0.46174 to 0.44674, saving model to sdp-tree-aeeem-2.weights.best.keras\n",
      "66/66 - 0s - loss: 0.5103 - accuracy: 0.7646 - val_loss: 0.4467 - val_accuracy: 0.7888 - 194ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.44674\n",
      "66/66 - 0s - loss: 0.4416 - accuracy: 0.7987 - val_loss: 0.4581 - val_accuracy: 0.7672 - 127ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: val_loss improved from 0.44674 to 0.43482, saving model to sdp-tree-aeeem-2.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3916 - accuracy: 0.8245 - val_loss: 0.4348 - val_accuracy: 0.7974 - 180ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: val_loss improved from 0.43482 to 0.41287, saving model to sdp-tree-aeeem-2.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3582 - accuracy: 0.8571 - val_loss: 0.4129 - val_accuracy: 0.8147 - 161ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.41287\n",
      "66/66 - 0s - loss: 0.3321 - accuracy: 0.8557 - val_loss: 0.4184 - val_accuracy: 0.7974 - 121ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: val_loss improved from 0.41287 to 0.38468, saving model to sdp-tree-aeeem-2.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2872 - accuracy: 0.8864 - val_loss: 0.3847 - val_accuracy: 0.8448 - 159ms/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: val_loss improved from 0.38468 to 0.38217, saving model to sdp-tree-aeeem-2.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2964 - accuracy: 0.8725 - val_loss: 0.3822 - val_accuracy: 0.8491 - 201ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: val_loss improved from 0.38217 to 0.35830, saving model to sdp-tree-aeeem-2.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2633 - accuracy: 0.8888 - val_loss: 0.3583 - val_accuracy: 0.8534 - 231ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: val_loss improved from 0.35830 to 0.34490, saving model to sdp-tree-aeeem-2.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2483 - accuracy: 0.9003 - val_loss: 0.3449 - val_accuracy: 0.8578 - 176ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: val_loss improved from 0.34490 to 0.34070, saving model to sdp-tree-aeeem-2.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2283 - accuracy: 0.9132 - val_loss: 0.3407 - val_accuracy: 0.8621 - 165ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: val_loss improved from 0.34070 to 0.32403, saving model to sdp-tree-aeeem-2.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2070 - accuracy: 0.9204 - val_loss: 0.3240 - val_accuracy: 0.8664 - 169ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: val_loss improved from 0.32403 to 0.28509, saving model to sdp-tree-aeeem-2.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1996 - accuracy: 0.9243 - val_loss: 0.2851 - val_accuracy: 0.8836 - 187ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: val_loss improved from 0.28509 to 0.28036, saving model to sdp-tree-aeeem-2.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1711 - accuracy: 0.9444 - val_loss: 0.2804 - val_accuracy: 0.8922 - 187ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.28036\n",
      "66/66 - 0s - loss: 0.1781 - accuracy: 0.9348 - val_loss: 0.2990 - val_accuracy: 0.8879 - 137ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: val_loss improved from 0.28036 to 0.26598, saving model to sdp-tree-aeeem-2.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1706 - accuracy: 0.9382 - val_loss: 0.2660 - val_accuracy: 0.9009 - 172ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: val_loss improved from 0.26598 to 0.25779, saving model to sdp-tree-aeeem-2.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1612 - accuracy: 0.9406 - val_loss: 0.2578 - val_accuracy: 0.8922 - 174ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: val_loss improved from 0.25779 to 0.24222, saving model to sdp-tree-aeeem-2.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1565 - accuracy: 0.9425 - val_loss: 0.2422 - val_accuracy: 0.9009 - 189ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: val_loss improved from 0.24222 to 0.24122, saving model to sdp-tree-aeeem-2.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1668 - accuracy: 0.9329 - val_loss: 0.2412 - val_accuracy: 0.9052 - 185ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.24122\n",
      "66/66 - 0s - loss: 0.1303 - accuracy: 0.9569 - val_loss: 0.2672 - val_accuracy: 0.8966 - 142ms/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: val_loss improved from 0.24122 to 0.23028, saving model to sdp-tree-aeeem-2.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1278 - accuracy: 0.9578 - val_loss: 0.2303 - val_accuracy: 0.8966 - 192ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.23028\n",
      "66/66 - 0s - loss: 0.1125 - accuracy: 0.9626 - val_loss: 0.2354 - val_accuracy: 0.9009 - 148ms/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.23028\n",
      "66/66 - 0s - loss: 0.1277 - accuracy: 0.9559 - val_loss: 0.2539 - val_accuracy: 0.8879 - 147ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.23028\n",
      "66/66 - 0s - loss: 0.1209 - accuracy: 0.9521 - val_loss: 0.2509 - val_accuracy: 0.9009 - 139ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.23028\n",
      "66/66 - 0s - loss: 0.1352 - accuracy: 0.9492 - val_loss: 0.2501 - val_accuracy: 0.8966 - 133ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.23028\n",
      "66/66 - 0s - loss: 0.1156 - accuracy: 0.9521 - val_loss: 0.2671 - val_accuracy: 0.8922 - 132ms/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: val_loss improved from 0.23028 to 0.21517, saving model to sdp-tree-aeeem-2.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1075 - accuracy: 0.9578 - val_loss: 0.2152 - val_accuracy: 0.9138 - 185ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: val_loss improved from 0.21517 to 0.21050, saving model to sdp-tree-aeeem-2.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1040 - accuracy: 0.9645 - val_loss: 0.2105 - val_accuracy: 0.9052 - 176ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.21050\n",
      "66/66 - 0s - loss: 0.1073 - accuracy: 0.9612 - val_loss: 0.2107 - val_accuracy: 0.9052 - 133ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.21050\n",
      "66/66 - 0s - loss: 0.1080 - accuracy: 0.9645 - val_loss: 0.2138 - val_accuracy: 0.9009 - 134ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: val_loss improved from 0.21050 to 0.18524, saving model to sdp-tree-aeeem-2.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0983 - accuracy: 0.9684 - val_loss: 0.1852 - val_accuracy: 0.9095 - 177ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.18524\n",
      "66/66 - 0s - loss: 0.0982 - accuracy: 0.9655 - val_loss: 0.2095 - val_accuracy: 0.8966 - 130ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.18524\n",
      "66/66 - 0s - loss: 0.0922 - accuracy: 0.9640 - val_loss: 0.1989 - val_accuracy: 0.9181 - 131ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.18524\n",
      "66/66 - 0s - loss: 0.0805 - accuracy: 0.9708 - val_loss: 0.1882 - val_accuracy: 0.9095 - 132ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.18524\n",
      "66/66 - 0s - loss: 0.0935 - accuracy: 0.9631 - val_loss: 0.1944 - val_accuracy: 0.9181 - 144ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.18524\n",
      "66/66 - 0s - loss: 0.0807 - accuracy: 0.9698 - val_loss: 0.1898 - val_accuracy: 0.9224 - 154ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.18524\n",
      "66/66 - 0s - loss: 0.0918 - accuracy: 0.9660 - val_loss: 0.2021 - val_accuracy: 0.9095 - 136ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.18524\n",
      "66/66 - 0s - loss: 0.0863 - accuracy: 0.9674 - val_loss: 0.2102 - val_accuracy: 0.9009 - 132ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.18524\n",
      "66/66 - 0s - loss: 0.0716 - accuracy: 0.9751 - val_loss: 0.1879 - val_accuracy: 0.9224 - 125ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 40: val_loss improved from 0.18524 to 0.17906, saving model to sdp-tree-aeeem-2.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0765 - accuracy: 0.9727 - val_loss: 0.1791 - val_accuracy: 0.9138 - 164ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: val_loss improved from 0.17906 to 0.17102, saving model to sdp-tree-aeeem-2.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0678 - accuracy: 0.9775 - val_loss: 0.1710 - val_accuracy: 0.9224 - 237ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 42: val_loss improved from 0.17102 to 0.16517, saving model to sdp-tree-aeeem-2.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0766 - accuracy: 0.9712 - val_loss: 0.1652 - val_accuracy: 0.9224 - 201ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.16517\n",
      "66/66 - 0s - loss: 0.0897 - accuracy: 0.9660 - val_loss: 0.1849 - val_accuracy: 0.9095 - 149ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.16517\n",
      "66/66 - 0s - loss: 0.0747 - accuracy: 0.9760 - val_loss: 0.1736 - val_accuracy: 0.9224 - 154ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.16517\n",
      "66/66 - 0s - loss: 0.0710 - accuracy: 0.9746 - val_loss: 0.2166 - val_accuracy: 0.9052 - 192ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.16517\n",
      "66/66 - 0s - loss: 0.0669 - accuracy: 0.9784 - val_loss: 0.1982 - val_accuracy: 0.9138 - 146ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.16517\n",
      "66/66 - 0s - loss: 0.0570 - accuracy: 0.9756 - val_loss: 0.1978 - val_accuracy: 0.9052 - 143ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.16517\n",
      "66/66 - 0s - loss: 0.0730 - accuracy: 0.9760 - val_loss: 0.1843 - val_accuracy: 0.9267 - 126ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.16517\n",
      "66/66 - 0s - loss: 0.0722 - accuracy: 0.9760 - val_loss: 0.1933 - val_accuracy: 0.9181 - 129ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.16517\n",
      "66/66 - 0s - loss: 0.0695 - accuracy: 0.9732 - val_loss: 0.1758 - val_accuracy: 0.9267 - 131ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.16517\n",
      "66/66 - 0s - loss: 0.0645 - accuracy: 0.9765 - val_loss: 0.1986 - val_accuracy: 0.9052 - 131ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.16517\n",
      "66/66 - 0s - loss: 0.0475 - accuracy: 0.9847 - val_loss: 0.1874 - val_accuracy: 0.9224 - 134ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.16517\n",
      "66/66 - 0s - loss: 0.0690 - accuracy: 0.9741 - val_loss: 0.2043 - val_accuracy: 0.9138 - 128ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.16517\n",
      "66/66 - 0s - loss: 0.0571 - accuracy: 0.9775 - val_loss: 0.2040 - val_accuracy: 0.9224 - 130ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.16517\n",
      "66/66 - 0s - loss: 0.0589 - accuracy: 0.9803 - val_loss: 0.1831 - val_accuracy: 0.9267 - 137ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.16517\n",
      "66/66 - 0s - loss: 0.0589 - accuracy: 0.9808 - val_loss: 0.1853 - val_accuracy: 0.9181 - 134ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.16517\n",
      "66/66 - 0s - loss: 0.0575 - accuracy: 0.9784 - val_loss: 0.2128 - val_accuracy: 0.9009 - 151ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.16517\n",
      "66/66 - 0s - loss: 0.0588 - accuracy: 0.9794 - val_loss: 0.1939 - val_accuracy: 0.9181 - 155ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.16517\n",
      "66/66 - 0s - loss: 0.0706 - accuracy: 0.9693 - val_loss: 0.2019 - val_accuracy: 0.9310 - 136ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.16517\n",
      "66/66 - 0s - loss: 0.0785 - accuracy: 0.9693 - val_loss: 0.1890 - val_accuracy: 0.9181 - 140ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 61: val_loss improved from 0.16517 to 0.15848, saving model to sdp-tree-aeeem-2.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0592 - accuracy: 0.9741 - val_loss: 0.1585 - val_accuracy: 0.9353 - 183ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0553 - accuracy: 0.9784 - val_loss: 0.1763 - val_accuracy: 0.9267 - 137ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0531 - accuracy: 0.9775 - val_loss: 0.2197 - val_accuracy: 0.9095 - 129ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0502 - accuracy: 0.9808 - val_loss: 0.1827 - val_accuracy: 0.9224 - 134ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0576 - accuracy: 0.9789 - val_loss: 0.1948 - val_accuracy: 0.9138 - 151ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0554 - accuracy: 0.9794 - val_loss: 0.2073 - val_accuracy: 0.9267 - 136ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0592 - accuracy: 0.9799 - val_loss: 0.2168 - val_accuracy: 0.9095 - 129ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0495 - accuracy: 0.9808 - val_loss: 0.2129 - val_accuracy: 0.9138 - 128ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0544 - accuracy: 0.9813 - val_loss: 0.2500 - val_accuracy: 0.8922 - 123ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0652 - accuracy: 0.9779 - val_loss: 0.2375 - val_accuracy: 0.9052 - 127ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0561 - accuracy: 0.9779 - val_loss: 0.2272 - val_accuracy: 0.9095 - 120ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0563 - accuracy: 0.9789 - val_loss: 0.2235 - val_accuracy: 0.9095 - 129ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0670 - accuracy: 0.9746 - val_loss: 0.2282 - val_accuracy: 0.9181 - 122ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0487 - accuracy: 0.9818 - val_loss: 0.2021 - val_accuracy: 0.9267 - 124ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0490 - accuracy: 0.9851 - val_loss: 0.2037 - val_accuracy: 0.9181 - 137ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0552 - accuracy: 0.9789 - val_loss: 0.1844 - val_accuracy: 0.9267 - 121ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0549 - accuracy: 0.9808 - val_loss: 0.1964 - val_accuracy: 0.9310 - 128ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0617 - accuracy: 0.9751 - val_loss: 0.2097 - val_accuracy: 0.9267 - 120ms/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0468 - accuracy: 0.9808 - val_loss: 0.2135 - val_accuracy: 0.9353 - 144ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0456 - accuracy: 0.9842 - val_loss: 0.2064 - val_accuracy: 0.9224 - 125ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0522 - accuracy: 0.9818 - val_loss: 0.2310 - val_accuracy: 0.9095 - 122ms/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0397 - accuracy: 0.9851 - val_loss: 0.2159 - val_accuracy: 0.9267 - 125ms/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0481 - accuracy: 0.9818 - val_loss: 0.1925 - val_accuracy: 0.9310 - 121ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0442 - accuracy: 0.9856 - val_loss: 0.2007 - val_accuracy: 0.9267 - 188ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0541 - accuracy: 0.9799 - val_loss: 0.2080 - val_accuracy: 0.9267 - 135ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0459 - accuracy: 0.9856 - val_loss: 0.2180 - val_accuracy: 0.9181 - 133ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0425 - accuracy: 0.9875 - val_loss: 0.2053 - val_accuracy: 0.9224 - 159ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0563 - accuracy: 0.9799 - val_loss: 0.1973 - val_accuracy: 0.9310 - 126ms/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0419 - accuracy: 0.9866 - val_loss: 0.2254 - val_accuracy: 0.9224 - 124ms/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0405 - accuracy: 0.9861 - val_loss: 0.2291 - val_accuracy: 0.9095 - 123ms/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0450 - accuracy: 0.9861 - val_loss: 0.1949 - val_accuracy: 0.9267 - 125ms/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0399 - accuracy: 0.9842 - val_loss: 0.2328 - val_accuracy: 0.9138 - 125ms/epoch - 2ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0522 - accuracy: 0.9808 - val_loss: 0.1920 - val_accuracy: 0.9267 - 125ms/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0405 - accuracy: 0.9851 - val_loss: 0.2135 - val_accuracy: 0.9224 - 125ms/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0428 - accuracy: 0.9827 - val_loss: 0.2326 - val_accuracy: 0.9224 - 123ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0441 - accuracy: 0.9851 - val_loss: 0.2277 - val_accuracy: 0.9181 - 126ms/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0359 - accuracy: 0.9866 - val_loss: 0.2060 - val_accuracy: 0.9353 - 122ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0379 - accuracy: 0.9866 - val_loss: 0.2153 - val_accuracy: 0.9267 - 124ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0422 - accuracy: 0.9847 - val_loss: 0.1856 - val_accuracy: 0.9310 - 121ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.15848\n",
      "66/66 - 0s - loss: 0.0342 - accuracy: 0.9861 - val_loss: 0.2140 - val_accuracy: 0.9267 - 130ms/epoch - 2ms/step\n",
      "73/73 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Evaluate on training data\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0385 - accuracy: 0.9914\n",
      "test loss, test acc: [0.03848079591989517, 0.9913718700408936]\n",
      "Evaluate on test data\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5850 - accuracy: 0.8760\n",
      "test loss, test acc: [0.584984540939331, 0.8759689927101135]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/manifold/_isomap.py:384: UserWarning: The number of connected components of the neighbors graph is 2 > 1. Completing the graph to fit Isomap might be slow. Increase the number of neighbors to avoid this issue.\n",
      "  self._fit_transform(X)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/scipy/sparse/_index.py:100: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.44181, saving model to sdp-tree-aeeem-3.weights.best.keras\n",
      "66/66 - 1s - loss: 0.6366 - accuracy: 0.6745 - val_loss: 0.4418 - val_accuracy: 0.8103 - 1s/epoch - 21ms/step\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.44181\n",
      "66/66 - 0s - loss: 0.5066 - accuracy: 0.7555 - val_loss: 0.4465 - val_accuracy: 0.7974 - 125ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.44181\n",
      "66/66 - 0s - loss: 0.4329 - accuracy: 0.8049 - val_loss: 0.4532 - val_accuracy: 0.8060 - 124ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: val_loss improved from 0.44181 to 0.42518, saving model to sdp-tree-aeeem-3.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3886 - accuracy: 0.8274 - val_loss: 0.4252 - val_accuracy: 0.7974 - 174ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: val_loss improved from 0.42518 to 0.38132, saving model to sdp-tree-aeeem-3.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3497 - accuracy: 0.8543 - val_loss: 0.3813 - val_accuracy: 0.8448 - 173ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: val_loss improved from 0.38132 to 0.35648, saving model to sdp-tree-aeeem-3.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3311 - accuracy: 0.8619 - val_loss: 0.3565 - val_accuracy: 0.8621 - 165ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: val_loss improved from 0.35648 to 0.34102, saving model to sdp-tree-aeeem-3.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3123 - accuracy: 0.8639 - val_loss: 0.3410 - val_accuracy: 0.8621 - 159ms/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.34102\n",
      "66/66 - 0s - loss: 0.2780 - accuracy: 0.8902 - val_loss: 0.3429 - val_accuracy: 0.8578 - 119ms/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: val_loss improved from 0.34102 to 0.31509, saving model to sdp-tree-aeeem-3.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2619 - accuracy: 0.8969 - val_loss: 0.3151 - val_accuracy: 0.8750 - 154ms/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: val_loss improved from 0.31509 to 0.28480, saving model to sdp-tree-aeeem-3.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2485 - accuracy: 0.8988 - val_loss: 0.2848 - val_accuracy: 0.8879 - 159ms/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.28480\n",
      "66/66 - 0s - loss: 0.2455 - accuracy: 0.8993 - val_loss: 0.2978 - val_accuracy: 0.8836 - 136ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: val_loss improved from 0.28480 to 0.27294, saving model to sdp-tree-aeeem-3.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2166 - accuracy: 0.9195 - val_loss: 0.2729 - val_accuracy: 0.8966 - 187ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: val_loss improved from 0.27294 to 0.25557, saving model to sdp-tree-aeeem-3.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2083 - accuracy: 0.9223 - val_loss: 0.2556 - val_accuracy: 0.8879 - 197ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: val_loss improved from 0.25557 to 0.24324, saving model to sdp-tree-aeeem-3.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1926 - accuracy: 0.9252 - val_loss: 0.2432 - val_accuracy: 0.9009 - 164ms/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 15: val_loss improved from 0.24324 to 0.23600, saving model to sdp-tree-aeeem-3.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1814 - accuracy: 0.9310 - val_loss: 0.2360 - val_accuracy: 0.9095 - 177ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: val_loss improved from 0.23600 to 0.22552, saving model to sdp-tree-aeeem-3.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1994 - accuracy: 0.9209 - val_loss: 0.2255 - val_accuracy: 0.9009 - 157ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: val_loss improved from 0.22552 to 0.20870, saving model to sdp-tree-aeeem-3.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1688 - accuracy: 0.9338 - val_loss: 0.2087 - val_accuracy: 0.9310 - 159ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.20870\n",
      "66/66 - 0s - loss: 0.1728 - accuracy: 0.9358 - val_loss: 0.2097 - val_accuracy: 0.9224 - 123ms/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: val_loss improved from 0.20870 to 0.19825, saving model to sdp-tree-aeeem-3.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1636 - accuracy: 0.9362 - val_loss: 0.1983 - val_accuracy: 0.9310 - 192ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: val_loss improved from 0.19825 to 0.19352, saving model to sdp-tree-aeeem-3.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1563 - accuracy: 0.9434 - val_loss: 0.1935 - val_accuracy: 0.9310 - 171ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.19352\n",
      "66/66 - 0s - loss: 0.1469 - accuracy: 0.9415 - val_loss: 0.2144 - val_accuracy: 0.9138 - 144ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: val_loss improved from 0.19352 to 0.18860, saving model to sdp-tree-aeeem-3.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1333 - accuracy: 0.9482 - val_loss: 0.1886 - val_accuracy: 0.9397 - 180ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: val_loss improved from 0.18860 to 0.18825, saving model to sdp-tree-aeeem-3.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1242 - accuracy: 0.9511 - val_loss: 0.1882 - val_accuracy: 0.9353 - 170ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: val_loss improved from 0.18825 to 0.18517, saving model to sdp-tree-aeeem-3.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1299 - accuracy: 0.9554 - val_loss: 0.1852 - val_accuracy: 0.9353 - 178ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.18517\n",
      "66/66 - 0s - loss: 0.1239 - accuracy: 0.9525 - val_loss: 0.1929 - val_accuracy: 0.9224 - 136ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: val_loss improved from 0.18517 to 0.15275, saving model to sdp-tree-aeeem-3.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1232 - accuracy: 0.9535 - val_loss: 0.1527 - val_accuracy: 0.9440 - 200ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.15275\n",
      "66/66 - 0s - loss: 0.1131 - accuracy: 0.9597 - val_loss: 0.1713 - val_accuracy: 0.9353 - 120ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.15275\n",
      "66/66 - 0s - loss: 0.1077 - accuracy: 0.9640 - val_loss: 0.1697 - val_accuracy: 0.9353 - 126ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: val_loss improved from 0.15275 to 0.14514, saving model to sdp-tree-aeeem-3.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1059 - accuracy: 0.9607 - val_loss: 0.1451 - val_accuracy: 0.9353 - 168ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.14514\n",
      "66/66 - 0s - loss: 0.0968 - accuracy: 0.9650 - val_loss: 0.1478 - val_accuracy: 0.9440 - 122ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.14514\n",
      "66/66 - 0s - loss: 0.1068 - accuracy: 0.9578 - val_loss: 0.1785 - val_accuracy: 0.9353 - 119ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.14514\n",
      "66/66 - 0s - loss: 0.1012 - accuracy: 0.9593 - val_loss: 0.1642 - val_accuracy: 0.9353 - 120ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.14514\n",
      "66/66 - 0s - loss: 0.1155 - accuracy: 0.9535 - val_loss: 0.1719 - val_accuracy: 0.9353 - 121ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.14514\n",
      "66/66 - 0s - loss: 0.1008 - accuracy: 0.9703 - val_loss: 0.1532 - val_accuracy: 0.9440 - 122ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.14514\n",
      "66/66 - 0s - loss: 0.1024 - accuracy: 0.9583 - val_loss: 0.1589 - val_accuracy: 0.9397 - 120ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.14514\n",
      "66/66 - 0s - loss: 0.0835 - accuracy: 0.9688 - val_loss: 0.1513 - val_accuracy: 0.9483 - 118ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.14514\n",
      "66/66 - 0s - loss: 0.0852 - accuracy: 0.9674 - val_loss: 0.1609 - val_accuracy: 0.9353 - 134ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.14514\n",
      "66/66 - 0s - loss: 0.0853 - accuracy: 0.9679 - val_loss: 0.1465 - val_accuracy: 0.9440 - 137ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.14514\n",
      "66/66 - 0s - loss: 0.0818 - accuracy: 0.9756 - val_loss: 0.1454 - val_accuracy: 0.9397 - 132ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 40: val_loss improved from 0.14514 to 0.13531, saving model to sdp-tree-aeeem-3.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0827 - accuracy: 0.9693 - val_loss: 0.1353 - val_accuracy: 0.9526 - 162ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.13531\n",
      "66/66 - 0s - loss: 0.0891 - accuracy: 0.9703 - val_loss: 0.1508 - val_accuracy: 0.9397 - 121ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.13531\n",
      "66/66 - 0s - loss: 0.0824 - accuracy: 0.9712 - val_loss: 0.1401 - val_accuracy: 0.9526 - 124ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.13531\n",
      "66/66 - 0s - loss: 0.0784 - accuracy: 0.9708 - val_loss: 0.1506 - val_accuracy: 0.9440 - 202ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.13531\n",
      "66/66 - 0s - loss: 0.0822 - accuracy: 0.9703 - val_loss: 0.1407 - val_accuracy: 0.9440 - 328ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.13531\n",
      "66/66 - 0s - loss: 0.0776 - accuracy: 0.9746 - val_loss: 0.1522 - val_accuracy: 0.9353 - 165ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.13531\n",
      "66/66 - 0s - loss: 0.0638 - accuracy: 0.9770 - val_loss: 0.1495 - val_accuracy: 0.9483 - 144ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.13531\n",
      "66/66 - 0s - loss: 0.0823 - accuracy: 0.9679 - val_loss: 0.1403 - val_accuracy: 0.9569 - 135ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.13531\n",
      "66/66 - 0s - loss: 0.0668 - accuracy: 0.9770 - val_loss: 0.1564 - val_accuracy: 0.9483 - 135ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.13531\n",
      "66/66 - 0s - loss: 0.0706 - accuracy: 0.9775 - val_loss: 0.1370 - val_accuracy: 0.9569 - 125ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 50: val_loss improved from 0.13531 to 0.13290, saving model to sdp-tree-aeeem-3.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0639 - accuracy: 0.9818 - val_loss: 0.1329 - val_accuracy: 0.9440 - 215ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 51: val_loss improved from 0.13290 to 0.12229, saving model to sdp-tree-aeeem-3.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0698 - accuracy: 0.9779 - val_loss: 0.1223 - val_accuracy: 0.9698 - 309ms/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0726 - accuracy: 0.9746 - val_loss: 0.1401 - val_accuracy: 0.9483 - 290ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0825 - accuracy: 0.9655 - val_loss: 0.1462 - val_accuracy: 0.9440 - 180ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0859 - accuracy: 0.9664 - val_loss: 0.1477 - val_accuracy: 0.9612 - 166ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0641 - accuracy: 0.9741 - val_loss: 0.1632 - val_accuracy: 0.9526 - 126ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0741 - accuracy: 0.9736 - val_loss: 0.1751 - val_accuracy: 0.9267 - 147ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0703 - accuracy: 0.9741 - val_loss: 0.1494 - val_accuracy: 0.9483 - 202ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0743 - accuracy: 0.9717 - val_loss: 0.1409 - val_accuracy: 0.9526 - 240ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0640 - accuracy: 0.9813 - val_loss: 0.1517 - val_accuracy: 0.9526 - 210ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0724 - accuracy: 0.9741 - val_loss: 0.1717 - val_accuracy: 0.9310 - 131ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0647 - accuracy: 0.9775 - val_loss: 0.1920 - val_accuracy: 0.9440 - 125ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0586 - accuracy: 0.9770 - val_loss: 0.1762 - val_accuracy: 0.9483 - 131ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0623 - accuracy: 0.9751 - val_loss: 0.1696 - val_accuracy: 0.9397 - 141ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0670 - accuracy: 0.9775 - val_loss: 0.1784 - val_accuracy: 0.9483 - 207ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0665 - accuracy: 0.9722 - val_loss: 0.1649 - val_accuracy: 0.9440 - 238ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0838 - accuracy: 0.9703 - val_loss: 0.1493 - val_accuracy: 0.9483 - 181ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0704 - accuracy: 0.9732 - val_loss: 0.1822 - val_accuracy: 0.9353 - 135ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0588 - accuracy: 0.9765 - val_loss: 0.1723 - val_accuracy: 0.9397 - 142ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0696 - accuracy: 0.9736 - val_loss: 0.1927 - val_accuracy: 0.9267 - 137ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0553 - accuracy: 0.9842 - val_loss: 0.1701 - val_accuracy: 0.9397 - 140ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0571 - accuracy: 0.9760 - val_loss: 0.1589 - val_accuracy: 0.9353 - 137ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0645 - accuracy: 0.9789 - val_loss: 0.1413 - val_accuracy: 0.9526 - 129ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0622 - accuracy: 0.9770 - val_loss: 0.1604 - val_accuracy: 0.9353 - 128ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0523 - accuracy: 0.9813 - val_loss: 0.1383 - val_accuracy: 0.9526 - 128ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0591 - accuracy: 0.9732 - val_loss: 0.1568 - val_accuracy: 0.9483 - 127ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0544 - accuracy: 0.9813 - val_loss: 0.1885 - val_accuracy: 0.9397 - 127ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0624 - accuracy: 0.9779 - val_loss: 0.1861 - val_accuracy: 0.9440 - 127ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0620 - accuracy: 0.9751 - val_loss: 0.1534 - val_accuracy: 0.9526 - 131ms/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0587 - accuracy: 0.9794 - val_loss: 0.1438 - val_accuracy: 0.9440 - 128ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0534 - accuracy: 0.9799 - val_loss: 0.1474 - val_accuracy: 0.9440 - 128ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0569 - accuracy: 0.9794 - val_loss: 0.1530 - val_accuracy: 0.9483 - 125ms/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0547 - accuracy: 0.9823 - val_loss: 0.1369 - val_accuracy: 0.9612 - 123ms/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0503 - accuracy: 0.9842 - val_loss: 0.1260 - val_accuracy: 0.9569 - 122ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0631 - accuracy: 0.9765 - val_loss: 0.1452 - val_accuracy: 0.9483 - 131ms/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0393 - accuracy: 0.9875 - val_loss: 0.1682 - val_accuracy: 0.9440 - 135ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0496 - accuracy: 0.9808 - val_loss: 0.1819 - val_accuracy: 0.9440 - 136ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0462 - accuracy: 0.9832 - val_loss: 0.1837 - val_accuracy: 0.9397 - 138ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0405 - accuracy: 0.9856 - val_loss: 0.1619 - val_accuracy: 0.9483 - 149ms/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0497 - accuracy: 0.9851 - val_loss: 0.1645 - val_accuracy: 0.9440 - 204ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0578 - accuracy: 0.9779 - val_loss: 0.1824 - val_accuracy: 0.9353 - 143ms/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0546 - accuracy: 0.9794 - val_loss: 0.1638 - val_accuracy: 0.9483 - 130ms/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0488 - accuracy: 0.9842 - val_loss: 0.1511 - val_accuracy: 0.9397 - 133ms/epoch - 2ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0536 - accuracy: 0.9813 - val_loss: 0.1819 - val_accuracy: 0.9353 - 134ms/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0676 - accuracy: 0.9746 - val_loss: 0.1749 - val_accuracy: 0.9310 - 130ms/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0425 - accuracy: 0.9832 - val_loss: 0.1663 - val_accuracy: 0.9440 - 131ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0473 - accuracy: 0.9823 - val_loss: 0.1685 - val_accuracy: 0.9353 - 127ms/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0303 - accuracy: 0.9890 - val_loss: 0.1646 - val_accuracy: 0.9267 - 127ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0465 - accuracy: 0.9842 - val_loss: 0.1522 - val_accuracy: 0.9397 - 125ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0515 - accuracy: 0.9818 - val_loss: 0.1414 - val_accuracy: 0.9353 - 154ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.12229\n",
      "66/66 - 0s - loss: 0.0488 - accuracy: 0.9813 - val_loss: 0.1544 - val_accuracy: 0.9310 - 155ms/epoch - 2ms/step\n",
      "73/73 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Evaluate on training data\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0370 - accuracy: 0.9935\n",
      "test loss, test acc: [0.03702733293175697, 0.9935289025306702]\n",
      "Evaluate on test data\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3610 - accuracy: 0.9070\n",
      "test loss, test acc: [0.36100706458091736, 0.9069767594337463]\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.48991, saving model to sdp-tree-aeeem-4.weights.best.keras\n",
      "66/66 - 2s - loss: 0.7291 - accuracy: 0.6457 - val_loss: 0.4899 - val_accuracy: 0.7198 - 2s/epoch - 25ms/step\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: val_loss improved from 0.48991 to 0.47076, saving model to sdp-tree-aeeem-4.weights.best.keras\n",
      "66/66 - 0s - loss: 0.5082 - accuracy: 0.7661 - val_loss: 0.4708 - val_accuracy: 0.7414 - 199ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.47076\n",
      "66/66 - 0s - loss: 0.4275 - accuracy: 0.8049 - val_loss: 0.4724 - val_accuracy: 0.7586 - 136ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: val_loss improved from 0.47076 to 0.43972, saving model to sdp-tree-aeeem-4.weights.best.keras\n",
      "66/66 - 0s - loss: 0.4001 - accuracy: 0.8317 - val_loss: 0.4397 - val_accuracy: 0.8017 - 176ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: val_loss improved from 0.43972 to 0.41426, saving model to sdp-tree-aeeem-4.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3527 - accuracy: 0.8528 - val_loss: 0.4143 - val_accuracy: 0.8103 - 176ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: val_loss improved from 0.41426 to 0.41355, saving model to sdp-tree-aeeem-4.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3306 - accuracy: 0.8624 - val_loss: 0.4136 - val_accuracy: 0.8103 - 166ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: val_loss improved from 0.41355 to 0.39963, saving model to sdp-tree-aeeem-4.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3067 - accuracy: 0.8730 - val_loss: 0.3996 - val_accuracy: 0.8233 - 164ms/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: val_loss improved from 0.39963 to 0.38238, saving model to sdp-tree-aeeem-4.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2959 - accuracy: 0.8849 - val_loss: 0.3824 - val_accuracy: 0.8190 - 169ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: val_loss improved from 0.38238 to 0.35868, saving model to sdp-tree-aeeem-4.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2589 - accuracy: 0.9060 - val_loss: 0.3587 - val_accuracy: 0.8362 - 175ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: val_loss improved from 0.35868 to 0.34245, saving model to sdp-tree-aeeem-4.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2574 - accuracy: 0.9056 - val_loss: 0.3424 - val_accuracy: 0.8405 - 178ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: val_loss improved from 0.34245 to 0.31095, saving model to sdp-tree-aeeem-4.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2200 - accuracy: 0.9075 - val_loss: 0.3109 - val_accuracy: 0.8664 - 189ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: val_loss improved from 0.31095 to 0.28964, saving model to sdp-tree-aeeem-4.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2268 - accuracy: 0.9108 - val_loss: 0.2896 - val_accuracy: 0.8750 - 210ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.28964\n",
      "66/66 - 0s - loss: 0.2098 - accuracy: 0.9185 - val_loss: 0.3184 - val_accuracy: 0.8707 - 130ms/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.28964\n",
      "66/66 - 0s - loss: 0.1917 - accuracy: 0.9286 - val_loss: 0.2963 - val_accuracy: 0.8621 - 130ms/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.28964\n",
      "66/66 - 0s - loss: 0.1909 - accuracy: 0.9271 - val_loss: 0.2935 - val_accuracy: 0.8750 - 121ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: val_loss improved from 0.28964 to 0.27524, saving model to sdp-tree-aeeem-4.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1663 - accuracy: 0.9401 - val_loss: 0.2752 - val_accuracy: 0.8836 - 156ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: val_loss improved from 0.27524 to 0.26753, saving model to sdp-tree-aeeem-4.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1647 - accuracy: 0.9410 - val_loss: 0.2675 - val_accuracy: 0.8922 - 164ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: val_loss improved from 0.26753 to 0.25055, saving model to sdp-tree-aeeem-4.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1589 - accuracy: 0.9434 - val_loss: 0.2506 - val_accuracy: 0.8750 - 179ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.25055\n",
      "66/66 - 0s - loss: 0.1376 - accuracy: 0.9492 - val_loss: 0.2696 - val_accuracy: 0.8836 - 129ms/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.25055\n",
      "66/66 - 0s - loss: 0.1497 - accuracy: 0.9434 - val_loss: 0.2676 - val_accuracy: 0.8707 - 127ms/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.25055\n",
      "66/66 - 0s - loss: 0.1312 - accuracy: 0.9578 - val_loss: 0.2578 - val_accuracy: 0.8966 - 125ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: val_loss improved from 0.25055 to 0.21455, saving model to sdp-tree-aeeem-4.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1475 - accuracy: 0.9477 - val_loss: 0.2146 - val_accuracy: 0.8966 - 165ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.21455\n",
      "66/66 - 0s - loss: 0.1298 - accuracy: 0.9511 - val_loss: 0.2326 - val_accuracy: 0.8793 - 119ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.21455\n",
      "66/66 - 0s - loss: 0.1130 - accuracy: 0.9616 - val_loss: 0.2280 - val_accuracy: 0.9181 - 113ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.21455\n",
      "66/66 - 0s - loss: 0.1118 - accuracy: 0.9631 - val_loss: 0.2246 - val_accuracy: 0.9009 - 127ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.21455\n",
      "66/66 - 0s - loss: 0.1021 - accuracy: 0.9636 - val_loss: 0.2258 - val_accuracy: 0.8966 - 133ms/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.21455\n",
      "66/66 - 0s - loss: 0.1039 - accuracy: 0.9593 - val_loss: 0.2320 - val_accuracy: 0.8966 - 117ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.21455\n",
      "66/66 - 0s - loss: 0.0939 - accuracy: 0.9650 - val_loss: 0.2175 - val_accuracy: 0.9095 - 136ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.21455\n",
      "66/66 - 0s - loss: 0.1005 - accuracy: 0.9669 - val_loss: 0.2179 - val_accuracy: 0.9009 - 117ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 30: val_loss improved from 0.21455 to 0.19919, saving model to sdp-tree-aeeem-4.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0936 - accuracy: 0.9640 - val_loss: 0.1992 - val_accuracy: 0.9095 - 154ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: val_loss improved from 0.19919 to 0.19581, saving model to sdp-tree-aeeem-4.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1014 - accuracy: 0.9645 - val_loss: 0.1958 - val_accuracy: 0.8966 - 176ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.19581\n",
      "66/66 - 0s - loss: 0.0886 - accuracy: 0.9693 - val_loss: 0.2281 - val_accuracy: 0.8836 - 125ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.19581\n",
      "66/66 - 0s - loss: 0.0913 - accuracy: 0.9660 - val_loss: 0.2352 - val_accuracy: 0.8793 - 117ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.19581\n",
      "66/66 - 0s - loss: 0.0871 - accuracy: 0.9664 - val_loss: 0.2109 - val_accuracy: 0.8966 - 115ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.19581\n",
      "66/66 - 0s - loss: 0.0822 - accuracy: 0.9732 - val_loss: 0.2021 - val_accuracy: 0.8879 - 119ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 36: val_loss improved from 0.19581 to 0.18598, saving model to sdp-tree-aeeem-4.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0848 - accuracy: 0.9688 - val_loss: 0.1860 - val_accuracy: 0.8966 - 156ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.18598\n",
      "66/66 - 0s - loss: 0.0780 - accuracy: 0.9722 - val_loss: 0.2255 - val_accuracy: 0.8922 - 139ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.18598\n",
      "66/66 - 0s - loss: 0.0801 - accuracy: 0.9736 - val_loss: 0.2071 - val_accuracy: 0.9009 - 137ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.18598\n",
      "66/66 - 0s - loss: 0.0846 - accuracy: 0.9751 - val_loss: 0.2036 - val_accuracy: 0.9009 - 118ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 40: val_loss improved from 0.18598 to 0.18402, saving model to sdp-tree-aeeem-4.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0792 - accuracy: 0.9708 - val_loss: 0.1840 - val_accuracy: 0.9052 - 155ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.18402\n",
      "66/66 - 0s - loss: 0.0776 - accuracy: 0.9717 - val_loss: 0.2150 - val_accuracy: 0.8793 - 117ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.18402\n",
      "66/66 - 0s - loss: 0.0792 - accuracy: 0.9717 - val_loss: 0.1918 - val_accuracy: 0.9009 - 114ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.18402\n",
      "66/66 - 0s - loss: 0.0660 - accuracy: 0.9789 - val_loss: 0.2070 - val_accuracy: 0.8922 - 116ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.18402\n",
      "66/66 - 0s - loss: 0.0541 - accuracy: 0.9813 - val_loss: 0.1948 - val_accuracy: 0.9052 - 114ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.18402\n",
      "66/66 - 0s - loss: 0.0669 - accuracy: 0.9756 - val_loss: 0.2052 - val_accuracy: 0.8922 - 115ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.18402\n",
      "66/66 - 0s - loss: 0.0659 - accuracy: 0.9741 - val_loss: 0.1891 - val_accuracy: 0.9095 - 118ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.18402\n",
      "66/66 - 0s - loss: 0.0753 - accuracy: 0.9722 - val_loss: 0.1875 - val_accuracy: 0.9009 - 117ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.18402\n",
      "66/66 - 0s - loss: 0.0524 - accuracy: 0.9808 - val_loss: 0.2135 - val_accuracy: 0.8966 - 125ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 49: val_loss improved from 0.18402 to 0.16200, saving model to sdp-tree-aeeem-4.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0751 - accuracy: 0.9736 - val_loss: 0.1620 - val_accuracy: 0.9181 - 188ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0681 - accuracy: 0.9765 - val_loss: 0.1951 - val_accuracy: 0.9052 - 167ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0662 - accuracy: 0.9770 - val_loss: 0.2019 - val_accuracy: 0.9052 - 130ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0626 - accuracy: 0.9756 - val_loss: 0.1693 - val_accuracy: 0.9181 - 117ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0682 - accuracy: 0.9779 - val_loss: 0.2012 - val_accuracy: 0.9095 - 118ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0637 - accuracy: 0.9784 - val_loss: 0.1829 - val_accuracy: 0.9181 - 120ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0600 - accuracy: 0.9784 - val_loss: 0.1875 - val_accuracy: 0.9095 - 118ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0482 - accuracy: 0.9837 - val_loss: 0.1903 - val_accuracy: 0.9009 - 117ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0508 - accuracy: 0.9827 - val_loss: 0.1888 - val_accuracy: 0.9095 - 114ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0582 - accuracy: 0.9799 - val_loss: 0.1748 - val_accuracy: 0.9138 - 115ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0540 - accuracy: 0.9808 - val_loss: 0.1814 - val_accuracy: 0.9138 - 117ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0620 - accuracy: 0.9770 - val_loss: 0.1930 - val_accuracy: 0.9009 - 139ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0558 - accuracy: 0.9789 - val_loss: 0.1963 - val_accuracy: 0.9095 - 118ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0532 - accuracy: 0.9813 - val_loss: 0.2154 - val_accuracy: 0.8922 - 115ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0504 - accuracy: 0.9789 - val_loss: 0.2111 - val_accuracy: 0.9138 - 118ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0452 - accuracy: 0.9847 - val_loss: 0.2150 - val_accuracy: 0.9009 - 136ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0559 - accuracy: 0.9770 - val_loss: 0.2493 - val_accuracy: 0.9009 - 116ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0509 - accuracy: 0.9837 - val_loss: 0.2174 - val_accuracy: 0.9052 - 117ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0583 - accuracy: 0.9779 - val_loss: 0.1864 - val_accuracy: 0.9181 - 115ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0511 - accuracy: 0.9818 - val_loss: 0.1713 - val_accuracy: 0.9052 - 114ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0455 - accuracy: 0.9856 - val_loss: 0.2059 - val_accuracy: 0.9052 - 113ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0529 - accuracy: 0.9784 - val_loss: 0.1962 - val_accuracy: 0.9095 - 114ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0552 - accuracy: 0.9789 - val_loss: 0.1955 - val_accuracy: 0.9009 - 115ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0590 - accuracy: 0.9765 - val_loss: 0.1902 - val_accuracy: 0.9095 - 117ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0479 - accuracy: 0.9842 - val_loss: 0.2278 - val_accuracy: 0.8966 - 113ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0607 - accuracy: 0.9803 - val_loss: 0.2287 - val_accuracy: 0.9095 - 115ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0507 - accuracy: 0.9832 - val_loss: 0.2018 - val_accuracy: 0.9095 - 115ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0490 - accuracy: 0.9823 - val_loss: 0.2169 - val_accuracy: 0.9052 - 112ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0456 - accuracy: 0.9851 - val_loss: 0.2237 - val_accuracy: 0.9095 - 113ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0429 - accuracy: 0.9842 - val_loss: 0.2591 - val_accuracy: 0.8922 - 114ms/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0485 - accuracy: 0.9827 - val_loss: 0.2358 - val_accuracy: 0.9052 - 113ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0393 - accuracy: 0.9866 - val_loss: 0.2123 - val_accuracy: 0.8922 - 113ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0468 - accuracy: 0.9813 - val_loss: 0.2378 - val_accuracy: 0.8966 - 113ms/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0582 - accuracy: 0.9789 - val_loss: 0.2445 - val_accuracy: 0.8966 - 113ms/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0547 - accuracy: 0.9794 - val_loss: 0.2070 - val_accuracy: 0.9138 - 113ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0463 - accuracy: 0.9799 - val_loss: 0.2183 - val_accuracy: 0.9095 - 113ms/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0417 - accuracy: 0.9871 - val_loss: 0.2648 - val_accuracy: 0.9009 - 116ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0469 - accuracy: 0.9842 - val_loss: 0.1976 - val_accuracy: 0.9138 - 141ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0501 - accuracy: 0.9818 - val_loss: 0.2032 - val_accuracy: 0.9009 - 151ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0501 - accuracy: 0.9847 - val_loss: 0.2065 - val_accuracy: 0.9009 - 177ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0474 - accuracy: 0.9842 - val_loss: 0.2035 - val_accuracy: 0.9138 - 130ms/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0545 - accuracy: 0.9775 - val_loss: 0.2186 - val_accuracy: 0.9052 - 137ms/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0543 - accuracy: 0.9794 - val_loss: 0.1997 - val_accuracy: 0.9095 - 134ms/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0437 - accuracy: 0.9832 - val_loss: 0.2226 - val_accuracy: 0.9138 - 128ms/epoch - 2ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0447 - accuracy: 0.9842 - val_loss: 0.2718 - val_accuracy: 0.8966 - 141ms/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0540 - accuracy: 0.9827 - val_loss: 0.2272 - val_accuracy: 0.9138 - 136ms/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0417 - accuracy: 0.9861 - val_loss: 0.2340 - val_accuracy: 0.9009 - 140ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0428 - accuracy: 0.9861 - val_loss: 0.2369 - val_accuracy: 0.9009 - 142ms/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0383 - accuracy: 0.9866 - val_loss: 0.2058 - val_accuracy: 0.9052 - 140ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0485 - accuracy: 0.9818 - val_loss: 0.2451 - val_accuracy: 0.9052 - 130ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0328 - accuracy: 0.9875 - val_loss: 0.2283 - val_accuracy: 0.9095 - 133ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.16200\n",
      "66/66 - 0s - loss: 0.0323 - accuracy: 0.9880 - val_loss: 0.2233 - val_accuracy: 0.9009 - 119ms/epoch - 2ms/step\n",
      "73/73 [==============================] - 0s 977us/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Evaluate on training data\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0384 - accuracy: 0.9888\n",
      "test loss, test acc: [0.03842751681804657, 0.9887834191322327]\n",
      "Evaluate on test data\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.9109\n",
      "test loss, test acc: [0.30752938985824585, 0.9108527302742004]\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.46396, saving model to sdp-tree-aeeem-5.weights.best.keras\n",
      "66/66 - 2s - loss: 0.6784 - accuracy: 0.6755 - val_loss: 0.4640 - val_accuracy: 0.7716 - 2s/epoch - 27ms/step\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: val_loss improved from 0.46396 to 0.45686, saving model to sdp-tree-aeeem-5.weights.best.keras\n",
      "66/66 - 0s - loss: 0.4754 - accuracy: 0.7756 - val_loss: 0.4569 - val_accuracy: 0.7629 - 221ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: val_loss improved from 0.45686 to 0.41324, saving model to sdp-tree-aeeem-5.weights.best.keras\n",
      "66/66 - 0s - loss: 0.4040 - accuracy: 0.8284 - val_loss: 0.4132 - val_accuracy: 0.7802 - 205ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: val_loss improved from 0.41324 to 0.37538, saving model to sdp-tree-aeeem-5.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3824 - accuracy: 0.8370 - val_loss: 0.3754 - val_accuracy: 0.8233 - 202ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.37538\n",
      "66/66 - 0s - loss: 0.3373 - accuracy: 0.8600 - val_loss: 0.3793 - val_accuracy: 0.8060 - 152ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: val_loss improved from 0.37538 to 0.35244, saving model to sdp-tree-aeeem-5.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3125 - accuracy: 0.8720 - val_loss: 0.3524 - val_accuracy: 0.8405 - 190ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: val_loss improved from 0.35244 to 0.33222, saving model to sdp-tree-aeeem-5.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2692 - accuracy: 0.8974 - val_loss: 0.3322 - val_accuracy: 0.8621 - 191ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: val_loss improved from 0.33222 to 0.30713, saving model to sdp-tree-aeeem-5.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2589 - accuracy: 0.8993 - val_loss: 0.3071 - val_accuracy: 0.8793 - 211ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: val_loss improved from 0.30713 to 0.27705, saving model to sdp-tree-aeeem-5.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2588 - accuracy: 0.8917 - val_loss: 0.2770 - val_accuracy: 0.8966 - 225ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: val_loss improved from 0.27705 to 0.27470, saving model to sdp-tree-aeeem-5.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2251 - accuracy: 0.9180 - val_loss: 0.2747 - val_accuracy: 0.8966 - 200ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.27470\n",
      "66/66 - 0s - loss: 0.2179 - accuracy: 0.9147 - val_loss: 0.2758 - val_accuracy: 0.9009 - 142ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.27470\n",
      "66/66 - 0s - loss: 0.2095 - accuracy: 0.9151 - val_loss: 0.2786 - val_accuracy: 0.8922 - 140ms/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: val_loss improved from 0.27470 to 0.26615, saving model to sdp-tree-aeeem-5.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1987 - accuracy: 0.9166 - val_loss: 0.2662 - val_accuracy: 0.9009 - 192ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: val_loss improved from 0.26615 to 0.24384, saving model to sdp-tree-aeeem-5.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1952 - accuracy: 0.9276 - val_loss: 0.2438 - val_accuracy: 0.9095 - 201ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 15: val_loss improved from 0.24384 to 0.23291, saving model to sdp-tree-aeeem-5.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1912 - accuracy: 0.9295 - val_loss: 0.2329 - val_accuracy: 0.9138 - 189ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.23291\n",
      "66/66 - 0s - loss: 0.1582 - accuracy: 0.9401 - val_loss: 0.2414 - val_accuracy: 0.9052 - 147ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.23291\n",
      "66/66 - 0s - loss: 0.1496 - accuracy: 0.9434 - val_loss: 0.2345 - val_accuracy: 0.9009 - 156ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.23291\n",
      "66/66 - 0s - loss: 0.1625 - accuracy: 0.9377 - val_loss: 0.2416 - val_accuracy: 0.8966 - 177ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: val_loss improved from 0.23291 to 0.20957, saving model to sdp-tree-aeeem-5.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1479 - accuracy: 0.9463 - val_loss: 0.2096 - val_accuracy: 0.9052 - 213ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: val_loss improved from 0.20957 to 0.20953, saving model to sdp-tree-aeeem-5.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1223 - accuracy: 0.9549 - val_loss: 0.2095 - val_accuracy: 0.9009 - 190ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: val_loss improved from 0.20953 to 0.20714, saving model to sdp-tree-aeeem-5.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1138 - accuracy: 0.9631 - val_loss: 0.2071 - val_accuracy: 0.9224 - 198ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: val_loss improved from 0.20714 to 0.20559, saving model to sdp-tree-aeeem-5.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1257 - accuracy: 0.9530 - val_loss: 0.2056 - val_accuracy: 0.9181 - 199ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.20559\n",
      "66/66 - 0s - loss: 0.1222 - accuracy: 0.9597 - val_loss: 0.2190 - val_accuracy: 0.9095 - 153ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: val_loss improved from 0.20559 to 0.19678, saving model to sdp-tree-aeeem-5.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1043 - accuracy: 0.9602 - val_loss: 0.1968 - val_accuracy: 0.9138 - 211ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.19678\n",
      "66/66 - 0s - loss: 0.1136 - accuracy: 0.9573 - val_loss: 0.2241 - val_accuracy: 0.9095 - 147ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.19678\n",
      "66/66 - 0s - loss: 0.1118 - accuracy: 0.9597 - val_loss: 0.2290 - val_accuracy: 0.9095 - 146ms/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.19678\n",
      "66/66 - 0s - loss: 0.0940 - accuracy: 0.9664 - val_loss: 0.2069 - val_accuracy: 0.9095 - 146ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.19678\n",
      "66/66 - 0s - loss: 0.0959 - accuracy: 0.9650 - val_loss: 0.2074 - val_accuracy: 0.9224 - 182ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.19678\n",
      "66/66 - 1s - loss: 0.1156 - accuracy: 0.9583 - val_loss: 0.1973 - val_accuracy: 0.9224 - 606ms/epoch - 9ms/step\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.19678\n",
      "66/66 - 0s - loss: 0.0971 - accuracy: 0.9636 - val_loss: 0.2294 - val_accuracy: 0.8966 - 225ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.19678\n",
      "66/66 - 0s - loss: 0.0933 - accuracy: 0.9679 - val_loss: 0.1973 - val_accuracy: 0.9181 - 185ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: val_loss improved from 0.19678 to 0.19461, saving model to sdp-tree-aeeem-5.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0915 - accuracy: 0.9679 - val_loss: 0.1946 - val_accuracy: 0.9181 - 471ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.19461\n",
      "66/66 - 0s - loss: 0.0902 - accuracy: 0.9650 - val_loss: 0.2259 - val_accuracy: 0.9052 - 171ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: val_loss improved from 0.19461 to 0.17691, saving model to sdp-tree-aeeem-5.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0892 - accuracy: 0.9698 - val_loss: 0.1769 - val_accuracy: 0.9267 - 229ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.17691\n",
      "66/66 - 0s - loss: 0.0861 - accuracy: 0.9727 - val_loss: 0.1831 - val_accuracy: 0.9353 - 166ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 36: val_loss improved from 0.17691 to 0.16971, saving model to sdp-tree-aeeem-5.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0833 - accuracy: 0.9688 - val_loss: 0.1697 - val_accuracy: 0.9353 - 251ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.16971\n",
      "66/66 - 0s - loss: 0.0986 - accuracy: 0.9626 - val_loss: 0.2104 - val_accuracy: 0.9267 - 182ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.16971\n",
      "66/66 - 0s - loss: 0.0886 - accuracy: 0.9693 - val_loss: 0.2305 - val_accuracy: 0.9052 - 201ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.16971\n",
      "66/66 - 0s - loss: 0.0642 - accuracy: 0.9775 - val_loss: 0.1932 - val_accuracy: 0.9310 - 166ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.16971\n",
      "66/66 - 0s - loss: 0.0701 - accuracy: 0.9756 - val_loss: 0.2014 - val_accuracy: 0.9353 - 163ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.16971\n",
      "66/66 - 0s - loss: 0.0699 - accuracy: 0.9760 - val_loss: 0.1882 - val_accuracy: 0.9353 - 161ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.16971\n",
      "66/66 - 0s - loss: 0.0778 - accuracy: 0.9708 - val_loss: 0.1923 - val_accuracy: 0.9353 - 154ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.16971\n",
      "66/66 - 0s - loss: 0.0698 - accuracy: 0.9741 - val_loss: 0.2030 - val_accuracy: 0.9224 - 138ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.16971\n",
      "66/66 - 0s - loss: 0.0560 - accuracy: 0.9823 - val_loss: 0.1911 - val_accuracy: 0.9353 - 147ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.16971\n",
      "66/66 - 0s - loss: 0.0709 - accuracy: 0.9722 - val_loss: 0.1773 - val_accuracy: 0.9310 - 167ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.16971\n",
      "66/66 - 0s - loss: 0.0662 - accuracy: 0.9770 - val_loss: 0.1803 - val_accuracy: 0.9310 - 169ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.16971\n",
      "66/66 - 0s - loss: 0.0750 - accuracy: 0.9717 - val_loss: 0.1942 - val_accuracy: 0.9310 - 163ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.16971\n",
      "66/66 - 0s - loss: 0.0681 - accuracy: 0.9732 - val_loss: 0.2047 - val_accuracy: 0.9353 - 143ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.16971\n",
      "66/66 - 0s - loss: 0.0611 - accuracy: 0.9803 - val_loss: 0.2017 - val_accuracy: 0.9310 - 146ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.16971\n",
      "66/66 - 0s - loss: 0.0701 - accuracy: 0.9746 - val_loss: 0.1999 - val_accuracy: 0.9224 - 144ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.16971\n",
      "66/66 - 0s - loss: 0.0658 - accuracy: 0.9746 - val_loss: 0.1725 - val_accuracy: 0.9440 - 160ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.16971\n",
      "66/66 - 0s - loss: 0.0663 - accuracy: 0.9770 - val_loss: 0.1872 - val_accuracy: 0.9353 - 151ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.16971\n",
      "66/66 - 0s - loss: 0.0583 - accuracy: 0.9770 - val_loss: 0.1725 - val_accuracy: 0.9397 - 146ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.16971\n",
      "66/66 - 0s - loss: 0.0618 - accuracy: 0.9775 - val_loss: 0.1714 - val_accuracy: 0.9353 - 154ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.16971\n",
      "66/66 - 0s - loss: 0.0576 - accuracy: 0.9808 - val_loss: 0.1836 - val_accuracy: 0.9224 - 154ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.16971\n",
      "66/66 - 0s - loss: 0.0598 - accuracy: 0.9794 - val_loss: 0.1766 - val_accuracy: 0.9353 - 154ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 57: val_loss improved from 0.16971 to 0.16473, saving model to sdp-tree-aeeem-5.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0457 - accuracy: 0.9851 - val_loss: 0.1647 - val_accuracy: 0.9267 - 223ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.16473\n",
      "66/66 - 0s - loss: 0.0612 - accuracy: 0.9789 - val_loss: 0.1658 - val_accuracy: 0.9310 - 156ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.16473\n",
      "66/66 - 0s - loss: 0.0600 - accuracy: 0.9760 - val_loss: 0.2049 - val_accuracy: 0.9224 - 146ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.16473\n",
      "66/66 - 0s - loss: 0.0503 - accuracy: 0.9818 - val_loss: 0.1995 - val_accuracy: 0.9310 - 149ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.16473\n",
      "66/66 - 0s - loss: 0.0656 - accuracy: 0.9727 - val_loss: 0.1932 - val_accuracy: 0.9397 - 157ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.16473\n",
      "66/66 - 0s - loss: 0.0615 - accuracy: 0.9779 - val_loss: 0.2008 - val_accuracy: 0.9397 - 149ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.16473\n",
      "66/66 - 0s - loss: 0.0596 - accuracy: 0.9760 - val_loss: 0.2178 - val_accuracy: 0.9224 - 147ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.16473\n",
      "66/66 - 0s - loss: 0.0576 - accuracy: 0.9808 - val_loss: 0.1905 - val_accuracy: 0.9440 - 144ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.16473\n",
      "66/66 - 0s - loss: 0.0519 - accuracy: 0.9799 - val_loss: 0.1949 - val_accuracy: 0.9353 - 146ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.16473\n",
      "66/66 - 0s - loss: 0.0525 - accuracy: 0.9823 - val_loss: 0.1827 - val_accuracy: 0.9483 - 145ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.16473\n",
      "66/66 - 0s - loss: 0.0684 - accuracy: 0.9784 - val_loss: 0.2112 - val_accuracy: 0.9397 - 153ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.16473\n",
      "66/66 - 0s - loss: 0.0539 - accuracy: 0.9837 - val_loss: 0.2169 - val_accuracy: 0.9181 - 148ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.16473\n",
      "66/66 - 0s - loss: 0.0566 - accuracy: 0.9847 - val_loss: 0.2227 - val_accuracy: 0.9267 - 151ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.16473\n",
      "66/66 - 0s - loss: 0.0546 - accuracy: 0.9823 - val_loss: 0.2014 - val_accuracy: 0.9353 - 158ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.16473\n",
      "66/66 - 0s - loss: 0.0574 - accuracy: 0.9760 - val_loss: 0.1901 - val_accuracy: 0.9440 - 137ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.16473\n",
      "66/66 - 0s - loss: 0.0578 - accuracy: 0.9779 - val_loss: 0.2135 - val_accuracy: 0.9353 - 131ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.16473\n",
      "66/66 - 0s - loss: 0.0489 - accuracy: 0.9827 - val_loss: 0.1684 - val_accuracy: 0.9397 - 173ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: val_loss improved from 0.16473 to 0.15776, saving model to sdp-tree-aeeem-5.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0545 - accuracy: 0.9799 - val_loss: 0.1578 - val_accuracy: 0.9440 - 232ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.15776\n",
      "66/66 - 0s - loss: 0.0590 - accuracy: 0.9803 - val_loss: 0.1883 - val_accuracy: 0.9353 - 136ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.15776\n",
      "66/66 - 0s - loss: 0.0667 - accuracy: 0.9784 - val_loss: 0.1937 - val_accuracy: 0.9310 - 140ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.15776\n",
      "66/66 - 0s - loss: 0.0423 - accuracy: 0.9837 - val_loss: 0.2102 - val_accuracy: 0.9310 - 146ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.15776\n",
      "66/66 - 0s - loss: 0.0511 - accuracy: 0.9808 - val_loss: 0.2214 - val_accuracy: 0.9267 - 138ms/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.15776\n",
      "66/66 - 0s - loss: 0.0495 - accuracy: 0.9808 - val_loss: 0.2065 - val_accuracy: 0.9267 - 148ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.15776\n",
      "66/66 - 0s - loss: 0.0615 - accuracy: 0.9775 - val_loss: 0.2279 - val_accuracy: 0.9138 - 141ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.15776\n",
      "66/66 - 0s - loss: 0.0476 - accuracy: 0.9818 - val_loss: 0.2322 - val_accuracy: 0.9095 - 173ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.15776\n",
      "66/66 - 0s - loss: 0.0561 - accuracy: 0.9779 - val_loss: 0.2075 - val_accuracy: 0.9310 - 168ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.15776\n",
      "66/66 - 0s - loss: 0.0547 - accuracy: 0.9770 - val_loss: 0.2094 - val_accuracy: 0.9267 - 164ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.15776\n",
      "66/66 - 0s - loss: 0.0457 - accuracy: 0.9832 - val_loss: 0.2150 - val_accuracy: 0.9310 - 162ms/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.15776\n",
      "66/66 - 0s - loss: 0.0496 - accuracy: 0.9832 - val_loss: 0.2222 - val_accuracy: 0.9353 - 155ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.15776\n",
      "66/66 - 0s - loss: 0.0438 - accuracy: 0.9813 - val_loss: 0.2517 - val_accuracy: 0.9267 - 152ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.15776\n",
      "66/66 - 0s - loss: 0.0340 - accuracy: 0.9880 - val_loss: 0.2276 - val_accuracy: 0.9267 - 151ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.15776\n",
      "66/66 - 0s - loss: 0.0565 - accuracy: 0.9775 - val_loss: 0.2217 - val_accuracy: 0.9440 - 220ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.15776\n",
      "66/66 - 0s - loss: 0.0489 - accuracy: 0.9803 - val_loss: 0.2330 - val_accuracy: 0.9353 - 167ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.15776\n",
      "66/66 - 0s - loss: 0.0518 - accuracy: 0.9803 - val_loss: 0.2077 - val_accuracy: 0.9267 - 150ms/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.15776\n",
      "66/66 - 0s - loss: 0.0454 - accuracy: 0.9827 - val_loss: 0.1866 - val_accuracy: 0.9440 - 155ms/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.15776\n",
      "66/66 - 0s - loss: 0.0495 - accuracy: 0.9823 - val_loss: 0.1975 - val_accuracy: 0.9483 - 152ms/epoch - 2ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.15776\n",
      "66/66 - 0s - loss: 0.0423 - accuracy: 0.9871 - val_loss: 0.2003 - val_accuracy: 0.9526 - 149ms/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.15776\n",
      "66/66 - 0s - loss: 0.0355 - accuracy: 0.9861 - val_loss: 0.2037 - val_accuracy: 0.9483 - 152ms/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.15776\n",
      "66/66 - 0s - loss: 0.0365 - accuracy: 0.9847 - val_loss: 0.2004 - val_accuracy: 0.9397 - 145ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.15776\n",
      "66/66 - 0s - loss: 0.0342 - accuracy: 0.9880 - val_loss: 0.1968 - val_accuracy: 0.9353 - 155ms/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.15776\n",
      "66/66 - 0s - loss: 0.0428 - accuracy: 0.9875 - val_loss: 0.1919 - val_accuracy: 0.9440 - 147ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.15776\n",
      "66/66 - 0s - loss: 0.0393 - accuracy: 0.9847 - val_loss: 0.2003 - val_accuracy: 0.9483 - 151ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.15776\n",
      "66/66 - 0s - loss: 0.0427 - accuracy: 0.9856 - val_loss: 0.2017 - val_accuracy: 0.9440 - 140ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.15776\n",
      "66/66 - 0s - loss: 0.0479 - accuracy: 0.9842 - val_loss: 0.2365 - val_accuracy: 0.9440 - 161ms/epoch - 2ms/step\n",
      "73/73 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "Evaluate on training data\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0269 - accuracy: 0.9931\n",
      "test loss, test acc: [0.026909489184617996, 0.9930974841117859]\n",
      "Evaluate on test data\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.9225\n",
      "test loss, test acc: [0.38503405451774597, 0.9224806427955627]\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.75126, saving model to sdp-tree-aeeem-6.weights.best.keras\n",
      "66/66 - 1s - loss: 0.7160 - accuracy: 0.6464 - val_loss: 0.7513 - val_accuracy: 0.5000 - 1s/epoch - 22ms/step\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: val_loss improved from 0.75126 to 0.60827, saving model to sdp-tree-aeeem-6.weights.best.keras\n",
      "66/66 - 0s - loss: 0.5231 - accuracy: 0.7470 - val_loss: 0.6083 - val_accuracy: 0.6293 - 168ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: val_loss improved from 0.60827 to 0.51772, saving model to sdp-tree-aeeem-6.weights.best.keras\n",
      "66/66 - 0s - loss: 0.4486 - accuracy: 0.7930 - val_loss: 0.5177 - val_accuracy: 0.7328 - 189ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: val_loss improved from 0.51772 to 0.47533, saving model to sdp-tree-aeeem-6.weights.best.keras\n",
      "66/66 - 0s - loss: 0.4035 - accuracy: 0.8261 - val_loss: 0.4753 - val_accuracy: 0.7931 - 189ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: val_loss improved from 0.47533 to 0.40441, saving model to sdp-tree-aeeem-6.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3583 - accuracy: 0.8457 - val_loss: 0.4044 - val_accuracy: 0.8276 - 186ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: val_loss improved from 0.40441 to 0.38290, saving model to sdp-tree-aeeem-6.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3330 - accuracy: 0.8610 - val_loss: 0.3829 - val_accuracy: 0.8491 - 190ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: val_loss improved from 0.38290 to 0.36222, saving model to sdp-tree-aeeem-6.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3012 - accuracy: 0.8769 - val_loss: 0.3622 - val_accuracy: 0.8621 - 172ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: val_loss improved from 0.36222 to 0.31847, saving model to sdp-tree-aeeem-6.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2700 - accuracy: 0.8979 - val_loss: 0.3185 - val_accuracy: 0.8966 - 168ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: val_loss improved from 0.31847 to 0.31150, saving model to sdp-tree-aeeem-6.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2486 - accuracy: 0.9023 - val_loss: 0.3115 - val_accuracy: 0.8879 - 182ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: val_loss improved from 0.31150 to 0.29628, saving model to sdp-tree-aeeem-6.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2522 - accuracy: 0.8994 - val_loss: 0.2963 - val_accuracy: 0.8922 - 185ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: val_loss improved from 0.29628 to 0.27153, saving model to sdp-tree-aeeem-6.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2202 - accuracy: 0.9133 - val_loss: 0.2715 - val_accuracy: 0.9095 - 186ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: val_loss improved from 0.27153 to 0.25165, saving model to sdp-tree-aeeem-6.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2112 - accuracy: 0.9214 - val_loss: 0.2516 - val_accuracy: 0.9095 - 187ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: val_loss improved from 0.25165 to 0.24763, saving model to sdp-tree-aeeem-6.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1949 - accuracy: 0.9276 - val_loss: 0.2476 - val_accuracy: 0.9353 - 166ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: val_loss improved from 0.24763 to 0.22273, saving model to sdp-tree-aeeem-6.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1786 - accuracy: 0.9329 - val_loss: 0.2227 - val_accuracy: 0.9267 - 164ms/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.22273\n",
      "66/66 - 0s - loss: 0.1840 - accuracy: 0.9272 - val_loss: 0.2324 - val_accuracy: 0.9267 - 134ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.22273\n",
      "66/66 - 0s - loss: 0.1720 - accuracy: 0.9358 - val_loss: 0.2290 - val_accuracy: 0.9310 - 129ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: val_loss improved from 0.22273 to 0.21292, saving model to sdp-tree-aeeem-6.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1696 - accuracy: 0.9348 - val_loss: 0.2129 - val_accuracy: 0.9181 - 161ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.21292\n",
      "66/66 - 0s - loss: 0.1527 - accuracy: 0.9473 - val_loss: 0.2209 - val_accuracy: 0.9397 - 127ms/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.21292\n",
      "66/66 - 0s - loss: 0.1581 - accuracy: 0.9425 - val_loss: 0.2323 - val_accuracy: 0.9267 - 134ms/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: val_loss improved from 0.21292 to 0.19964, saving model to sdp-tree-aeeem-6.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1434 - accuracy: 0.9506 - val_loss: 0.1996 - val_accuracy: 0.9483 - 164ms/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.19964\n",
      "66/66 - 0s - loss: 0.1546 - accuracy: 0.9459 - val_loss: 0.2088 - val_accuracy: 0.9483 - 126ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: val_loss improved from 0.19964 to 0.19002, saving model to sdp-tree-aeeem-6.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1223 - accuracy: 0.9593 - val_loss: 0.1900 - val_accuracy: 0.9397 - 171ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.19002\n",
      "66/66 - 0s - loss: 0.1288 - accuracy: 0.9526 - val_loss: 0.1944 - val_accuracy: 0.9440 - 123ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.19002\n",
      "66/66 - 0s - loss: 0.1177 - accuracy: 0.9598 - val_loss: 0.2119 - val_accuracy: 0.9267 - 120ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: val_loss improved from 0.19002 to 0.17494, saving model to sdp-tree-aeeem-6.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0969 - accuracy: 0.9679 - val_loss: 0.1749 - val_accuracy: 0.9569 - 162ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: val_loss improved from 0.17494 to 0.16856, saving model to sdp-tree-aeeem-6.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0995 - accuracy: 0.9679 - val_loss: 0.1686 - val_accuracy: 0.9440 - 187ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: val_loss improved from 0.16856 to 0.16602, saving model to sdp-tree-aeeem-6.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1085 - accuracy: 0.9598 - val_loss: 0.1660 - val_accuracy: 0.9483 - 202ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.16602\n",
      "66/66 - 0s - loss: 0.1347 - accuracy: 0.9483 - val_loss: 0.1687 - val_accuracy: 0.9526 - 122ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.16602\n",
      "66/66 - 0s - loss: 0.1097 - accuracy: 0.9598 - val_loss: 0.1968 - val_accuracy: 0.9440 - 119ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.16602\n",
      "66/66 - 0s - loss: 0.1050 - accuracy: 0.9602 - val_loss: 0.1726 - val_accuracy: 0.9353 - 120ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.16602\n",
      "66/66 - 0s - loss: 0.1106 - accuracy: 0.9598 - val_loss: 0.1696 - val_accuracy: 0.9397 - 134ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.16602\n",
      "66/66 - 0s - loss: 0.0950 - accuracy: 0.9655 - val_loss: 0.1677 - val_accuracy: 0.9397 - 118ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: val_loss improved from 0.16602 to 0.15169, saving model to sdp-tree-aeeem-6.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0939 - accuracy: 0.9689 - val_loss: 0.1517 - val_accuracy: 0.9483 - 160ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: val_loss improved from 0.15169 to 0.13764, saving model to sdp-tree-aeeem-6.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0868 - accuracy: 0.9698 - val_loss: 0.1376 - val_accuracy: 0.9526 - 167ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.13764\n",
      "66/66 - 0s - loss: 0.0929 - accuracy: 0.9665 - val_loss: 0.1686 - val_accuracy: 0.9440 - 120ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.13764\n",
      "66/66 - 0s - loss: 0.1036 - accuracy: 0.9665 - val_loss: 0.1678 - val_accuracy: 0.9397 - 116ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.13764\n",
      "66/66 - 0s - loss: 0.0835 - accuracy: 0.9713 - val_loss: 0.1649 - val_accuracy: 0.9310 - 115ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.13764\n",
      "66/66 - 0s - loss: 0.0791 - accuracy: 0.9717 - val_loss: 0.1591 - val_accuracy: 0.9353 - 139ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.13764\n",
      "66/66 - 0s - loss: 0.0747 - accuracy: 0.9770 - val_loss: 0.1641 - val_accuracy: 0.9353 - 132ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.13764\n",
      "66/66 - 0s - loss: 0.0784 - accuracy: 0.9732 - val_loss: 0.1612 - val_accuracy: 0.9569 - 126ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.13764\n",
      "66/66 - 0s - loss: 0.0685 - accuracy: 0.9789 - val_loss: 0.1568 - val_accuracy: 0.9526 - 138ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.13764\n",
      "66/66 - 0s - loss: 0.0734 - accuracy: 0.9727 - val_loss: 0.1500 - val_accuracy: 0.9483 - 123ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.13764\n",
      "66/66 - 0s - loss: 0.0873 - accuracy: 0.9674 - val_loss: 0.1589 - val_accuracy: 0.9353 - 122ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.13764\n",
      "66/66 - 0s - loss: 0.0796 - accuracy: 0.9698 - val_loss: 0.1561 - val_accuracy: 0.9526 - 124ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.13764\n",
      "66/66 - 0s - loss: 0.0685 - accuracy: 0.9770 - val_loss: 0.1726 - val_accuracy: 0.9397 - 136ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.13764\n",
      "66/66 - 0s - loss: 0.0679 - accuracy: 0.9780 - val_loss: 0.1648 - val_accuracy: 0.9483 - 128ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.13764\n",
      "66/66 - 0s - loss: 0.0778 - accuracy: 0.9698 - val_loss: 0.1931 - val_accuracy: 0.9310 - 128ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.13764\n",
      "66/66 - 0s - loss: 0.0701 - accuracy: 0.9756 - val_loss: 0.1619 - val_accuracy: 0.9483 - 125ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.13764\n",
      "66/66 - 0s - loss: 0.0684 - accuracy: 0.9775 - val_loss: 0.1730 - val_accuracy: 0.9526 - 121ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.13764\n",
      "66/66 - 0s - loss: 0.0603 - accuracy: 0.9780 - val_loss: 0.1677 - val_accuracy: 0.9483 - 128ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.13764\n",
      "66/66 - 0s - loss: 0.0632 - accuracy: 0.9765 - val_loss: 0.1703 - val_accuracy: 0.9569 - 151ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.13764\n",
      "66/66 - 0s - loss: 0.0607 - accuracy: 0.9799 - val_loss: 0.1570 - val_accuracy: 0.9483 - 137ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.13764\n",
      "66/66 - 0s - loss: 0.0627 - accuracy: 0.9775 - val_loss: 0.1780 - val_accuracy: 0.9397 - 134ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.13764\n",
      "66/66 - 0s - loss: 0.0594 - accuracy: 0.9823 - val_loss: 0.1415 - val_accuracy: 0.9483 - 133ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 55: val_loss improved from 0.13764 to 0.13035, saving model to sdp-tree-aeeem-6.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0562 - accuracy: 0.9751 - val_loss: 0.1303 - val_accuracy: 0.9483 - 185ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.13035\n",
      "66/66 - 0s - loss: 0.0621 - accuracy: 0.9780 - val_loss: 0.1801 - val_accuracy: 0.9526 - 149ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.13035\n",
      "66/66 - 0s - loss: 0.0505 - accuracy: 0.9828 - val_loss: 0.1692 - val_accuracy: 0.9483 - 146ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.13035\n",
      "66/66 - 0s - loss: 0.0565 - accuracy: 0.9804 - val_loss: 0.1782 - val_accuracy: 0.9353 - 156ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.13035\n",
      "66/66 - 0s - loss: 0.0622 - accuracy: 0.9780 - val_loss: 0.1968 - val_accuracy: 0.9181 - 178ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.13035\n",
      "66/66 - 0s - loss: 0.0589 - accuracy: 0.9804 - val_loss: 0.1537 - val_accuracy: 0.9440 - 120ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.13035\n",
      "66/66 - 0s - loss: 0.0634 - accuracy: 0.9760 - val_loss: 0.1689 - val_accuracy: 0.9397 - 117ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.13035\n",
      "66/66 - 0s - loss: 0.0669 - accuracy: 0.9775 - val_loss: 0.1530 - val_accuracy: 0.9569 - 121ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.13035\n",
      "66/66 - 0s - loss: 0.0534 - accuracy: 0.9813 - val_loss: 0.1446 - val_accuracy: 0.9612 - 134ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.13035\n",
      "66/66 - 0s - loss: 0.0621 - accuracy: 0.9765 - val_loss: 0.1785 - val_accuracy: 0.9483 - 128ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.13035\n",
      "66/66 - 0s - loss: 0.0514 - accuracy: 0.9804 - val_loss: 0.1725 - val_accuracy: 0.9397 - 133ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.13035\n",
      "66/66 - 0s - loss: 0.0592 - accuracy: 0.9780 - val_loss: 0.1506 - val_accuracy: 0.9569 - 123ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.13035\n",
      "66/66 - 0s - loss: 0.0733 - accuracy: 0.9751 - val_loss: 0.1590 - val_accuracy: 0.9569 - 115ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.13035\n",
      "66/66 - 0s - loss: 0.0509 - accuracy: 0.9832 - val_loss: 0.1475 - val_accuracy: 0.9526 - 128ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.13035\n",
      "66/66 - 0s - loss: 0.0521 - accuracy: 0.9808 - val_loss: 0.1591 - val_accuracy: 0.9526 - 123ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.13035\n",
      "66/66 - 0s - loss: 0.0587 - accuracy: 0.9808 - val_loss: 0.1516 - val_accuracy: 0.9440 - 117ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.13035\n",
      "66/66 - 0s - loss: 0.0617 - accuracy: 0.9751 - val_loss: 0.1473 - val_accuracy: 0.9526 - 193ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.13035\n",
      "66/66 - 0s - loss: 0.0537 - accuracy: 0.9799 - val_loss: 0.1478 - val_accuracy: 0.9569 - 233ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.13035\n",
      "66/66 - 0s - loss: 0.0579 - accuracy: 0.9780 - val_loss: 0.1466 - val_accuracy: 0.9526 - 186ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.13035\n",
      "66/66 - 0s - loss: 0.0485 - accuracy: 0.9823 - val_loss: 0.1777 - val_accuracy: 0.9440 - 166ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: val_loss improved from 0.13035 to 0.13008, saving model to sdp-tree-aeeem-6.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0518 - accuracy: 0.9808 - val_loss: 0.1301 - val_accuracy: 0.9655 - 210ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.13008\n",
      "66/66 - 0s - loss: 0.0515 - accuracy: 0.9794 - val_loss: 0.1416 - val_accuracy: 0.9612 - 132ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.13008\n",
      "66/66 - 0s - loss: 0.0477 - accuracy: 0.9861 - val_loss: 0.1407 - val_accuracy: 0.9440 - 146ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.13008\n",
      "66/66 - 0s - loss: 0.0434 - accuracy: 0.9828 - val_loss: 0.1307 - val_accuracy: 0.9526 - 148ms/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.13008\n",
      "66/66 - 0s - loss: 0.0438 - accuracy: 0.9861 - val_loss: 0.1663 - val_accuracy: 0.9397 - 146ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.13008\n",
      "66/66 - 0s - loss: 0.0452 - accuracy: 0.9847 - val_loss: 0.1408 - val_accuracy: 0.9440 - 125ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.13008\n",
      "66/66 - 0s - loss: 0.0470 - accuracy: 0.9828 - val_loss: 0.1532 - val_accuracy: 0.9353 - 127ms/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.13008\n",
      "66/66 - 0s - loss: 0.0414 - accuracy: 0.9871 - val_loss: 0.1596 - val_accuracy: 0.9483 - 234ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: val_loss improved from 0.13008 to 0.12856, saving model to sdp-tree-aeeem-6.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0424 - accuracy: 0.9861 - val_loss: 0.1286 - val_accuracy: 0.9655 - 164ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.12856\n",
      "66/66 - 0s - loss: 0.0439 - accuracy: 0.9832 - val_loss: 0.1829 - val_accuracy: 0.9440 - 125ms/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.12856\n",
      "66/66 - 0s - loss: 0.0568 - accuracy: 0.9789 - val_loss: 0.1430 - val_accuracy: 0.9440 - 119ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.12856\n",
      "66/66 - 0s - loss: 0.0534 - accuracy: 0.9832 - val_loss: 0.1407 - val_accuracy: 0.9526 - 123ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.12856\n",
      "66/66 - 0s - loss: 0.0629 - accuracy: 0.9813 - val_loss: 0.1528 - val_accuracy: 0.9526 - 122ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.12856\n",
      "66/66 - 0s - loss: 0.0377 - accuracy: 0.9856 - val_loss: 0.1394 - val_accuracy: 0.9612 - 124ms/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.12856\n",
      "66/66 - 0s - loss: 0.0431 - accuracy: 0.9837 - val_loss: 0.1599 - val_accuracy: 0.9526 - 124ms/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.12856\n",
      "66/66 - 0s - loss: 0.0434 - accuracy: 0.9856 - val_loss: 0.1459 - val_accuracy: 0.9483 - 124ms/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.12856\n",
      "66/66 - 0s - loss: 0.0488 - accuracy: 0.9837 - val_loss: 0.1534 - val_accuracy: 0.9569 - 137ms/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.12856\n",
      "66/66 - 0s - loss: 0.0396 - accuracy: 0.9875 - val_loss: 0.1477 - val_accuracy: 0.9526 - 122ms/epoch - 2ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.12856\n",
      "66/66 - 0s - loss: 0.0422 - accuracy: 0.9861 - val_loss: 0.1698 - val_accuracy: 0.9569 - 121ms/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.12856\n",
      "66/66 - 0s - loss: 0.0482 - accuracy: 0.9808 - val_loss: 0.1667 - val_accuracy: 0.9569 - 129ms/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.12856\n",
      "66/66 - 0s - loss: 0.0462 - accuracy: 0.9837 - val_loss: 0.1348 - val_accuracy: 0.9612 - 136ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.12856\n",
      "66/66 - 0s - loss: 0.0444 - accuracy: 0.9842 - val_loss: 0.1685 - val_accuracy: 0.9440 - 120ms/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.12856\n",
      "66/66 - 0s - loss: 0.0565 - accuracy: 0.9789 - val_loss: 0.1708 - val_accuracy: 0.9526 - 124ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.12856\n",
      "66/66 - 0s - loss: 0.0515 - accuracy: 0.9828 - val_loss: 0.1353 - val_accuracy: 0.9612 - 123ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.12856\n",
      "66/66 - 0s - loss: 0.0509 - accuracy: 0.9804 - val_loss: 0.1628 - val_accuracy: 0.9569 - 126ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.12856\n",
      "66/66 - 0s - loss: 0.0433 - accuracy: 0.9851 - val_loss: 0.1640 - val_accuracy: 0.9526 - 124ms/epoch - 2ms/step\n",
      "73/73 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Evaluate on training data\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0290 - accuracy: 0.9948\n",
      "test loss, test acc: [0.029043816030025482, 0.9948253631591797]\n",
      "Evaluate on test data\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4102 - accuracy: 0.8911\n",
      "test loss, test acc: [0.41015148162841797, 0.8910505771636963]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/manifold/_isomap.py:384: UserWarning: The number of connected components of the neighbors graph is 2 > 1. Completing the graph to fit Isomap might be slow. Increase the number of neighbors to avoid this issue.\n",
      "  self._fit_transform(X)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/scipy/sparse/_index.py:100: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.73684, saving model to sdp-tree-aeeem-7.weights.best.keras\n",
      "66/66 - 2s - loss: 0.6980 - accuracy: 0.6713 - val_loss: 0.7368 - val_accuracy: 0.5129 - 2s/epoch - 25ms/step\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: val_loss improved from 0.73684 to 0.60202, saving model to sdp-tree-aeeem-7.weights.best.keras\n",
      "66/66 - 0s - loss: 0.4813 - accuracy: 0.7782 - val_loss: 0.6020 - val_accuracy: 0.6422 - 182ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: val_loss improved from 0.60202 to 0.49275, saving model to sdp-tree-aeeem-7.weights.best.keras\n",
      "66/66 - 0s - loss: 0.4107 - accuracy: 0.8203 - val_loss: 0.4927 - val_accuracy: 0.7198 - 174ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: val_loss improved from 0.49275 to 0.43068, saving model to sdp-tree-aeeem-7.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3729 - accuracy: 0.8285 - val_loss: 0.4307 - val_accuracy: 0.7802 - 185ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: val_loss improved from 0.43068 to 0.37255, saving model to sdp-tree-aeeem-7.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3362 - accuracy: 0.8601 - val_loss: 0.3726 - val_accuracy: 0.8362 - 183ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.37255\n",
      "66/66 - 0s - loss: 0.3191 - accuracy: 0.8711 - val_loss: 0.3854 - val_accuracy: 0.8276 - 138ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: val_loss improved from 0.37255 to 0.32893, saving model to sdp-tree-aeeem-7.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2854 - accuracy: 0.8855 - val_loss: 0.3289 - val_accuracy: 0.8534 - 167ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: val_loss improved from 0.32893 to 0.31669, saving model to sdp-tree-aeeem-7.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2706 - accuracy: 0.8888 - val_loss: 0.3167 - val_accuracy: 0.8836 - 179ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: val_loss improved from 0.31669 to 0.29094, saving model to sdp-tree-aeeem-7.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2432 - accuracy: 0.9037 - val_loss: 0.2909 - val_accuracy: 0.8966 - 193ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: val_loss improved from 0.29094 to 0.27406, saving model to sdp-tree-aeeem-7.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2294 - accuracy: 0.9042 - val_loss: 0.2741 - val_accuracy: 0.9009 - 181ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.27406\n",
      "66/66 - 0s - loss: 0.2107 - accuracy: 0.9166 - val_loss: 0.2787 - val_accuracy: 0.8836 - 126ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: val_loss improved from 0.27406 to 0.25192, saving model to sdp-tree-aeeem-7.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1995 - accuracy: 0.9276 - val_loss: 0.2519 - val_accuracy: 0.9009 - 171ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: val_loss improved from 0.25192 to 0.24225, saving model to sdp-tree-aeeem-7.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1864 - accuracy: 0.9339 - val_loss: 0.2423 - val_accuracy: 0.9095 - 170ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.24225\n",
      "66/66 - 0s - loss: 0.1793 - accuracy: 0.9324 - val_loss: 0.2435 - val_accuracy: 0.9052 - 128ms/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 15: val_loss improved from 0.24225 to 0.23083, saving model to sdp-tree-aeeem-7.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1663 - accuracy: 0.9396 - val_loss: 0.2308 - val_accuracy: 0.9009 - 182ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.23083\n",
      "66/66 - 0s - loss: 0.1600 - accuracy: 0.9439 - val_loss: 0.2417 - val_accuracy: 0.8879 - 124ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: val_loss improved from 0.23083 to 0.22630, saving model to sdp-tree-aeeem-7.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1670 - accuracy: 0.9411 - val_loss: 0.2263 - val_accuracy: 0.9052 - 169ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: val_loss improved from 0.22630 to 0.22328, saving model to sdp-tree-aeeem-7.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1535 - accuracy: 0.9444 - val_loss: 0.2233 - val_accuracy: 0.9224 - 179ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: val_loss improved from 0.22328 to 0.21897, saving model to sdp-tree-aeeem-7.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1363 - accuracy: 0.9502 - val_loss: 0.2190 - val_accuracy: 0.9095 - 169ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.21897\n",
      "66/66 - 0s - loss: 0.1261 - accuracy: 0.9554 - val_loss: 0.2388 - val_accuracy: 0.9009 - 125ms/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.21897\n",
      "66/66 - 0s - loss: 0.1261 - accuracy: 0.9559 - val_loss: 0.2292 - val_accuracy: 0.8966 - 125ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: val_loss improved from 0.21897 to 0.18582, saving model to sdp-tree-aeeem-7.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1113 - accuracy: 0.9593 - val_loss: 0.1858 - val_accuracy: 0.9181 - 165ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.18582\n",
      "66/66 - 0s - loss: 0.1166 - accuracy: 0.9569 - val_loss: 0.1885 - val_accuracy: 0.9181 - 128ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: val_loss improved from 0.18582 to 0.18514, saving model to sdp-tree-aeeem-7.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1071 - accuracy: 0.9665 - val_loss: 0.1851 - val_accuracy: 0.9181 - 249ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: val_loss improved from 0.18514 to 0.18341, saving model to sdp-tree-aeeem-7.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1031 - accuracy: 0.9641 - val_loss: 0.1834 - val_accuracy: 0.9181 - 187ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: val_loss improved from 0.18341 to 0.17295, saving model to sdp-tree-aeeem-7.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1116 - accuracy: 0.9569 - val_loss: 0.1729 - val_accuracy: 0.9224 - 181ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: val_loss improved from 0.17295 to 0.15908, saving model to sdp-tree-aeeem-7.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1114 - accuracy: 0.9598 - val_loss: 0.1591 - val_accuracy: 0.9267 - 168ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.15908\n",
      "66/66 - 0s - loss: 0.1050 - accuracy: 0.9655 - val_loss: 0.1794 - val_accuracy: 0.9138 - 126ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.15908\n",
      "66/66 - 0s - loss: 0.0938 - accuracy: 0.9655 - val_loss: 0.1840 - val_accuracy: 0.9095 - 123ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.15908\n",
      "66/66 - 0s - loss: 0.0840 - accuracy: 0.9689 - val_loss: 0.1709 - val_accuracy: 0.9181 - 122ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.15908\n",
      "66/66 - 0s - loss: 0.0772 - accuracy: 0.9741 - val_loss: 0.1597 - val_accuracy: 0.9267 - 121ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.15908\n",
      "66/66 - 0s - loss: 0.0801 - accuracy: 0.9722 - val_loss: 0.1821 - val_accuracy: 0.9095 - 122ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: val_loss improved from 0.15908 to 0.14293, saving model to sdp-tree-aeeem-7.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0692 - accuracy: 0.9756 - val_loss: 0.1429 - val_accuracy: 0.9310 - 164ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.14293\n",
      "66/66 - 0s - loss: 0.0699 - accuracy: 0.9746 - val_loss: 0.1818 - val_accuracy: 0.9138 - 124ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.14293\n",
      "66/66 - 0s - loss: 0.0831 - accuracy: 0.9727 - val_loss: 0.1789 - val_accuracy: 0.9138 - 122ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.14293\n",
      "66/66 - 0s - loss: 0.0770 - accuracy: 0.9727 - val_loss: 0.1999 - val_accuracy: 0.9138 - 136ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.14293\n",
      "66/66 - 0s - loss: 0.0824 - accuracy: 0.9698 - val_loss: 0.1596 - val_accuracy: 0.9181 - 137ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.14293\n",
      "66/66 - 0s - loss: 0.0795 - accuracy: 0.9684 - val_loss: 0.1455 - val_accuracy: 0.9267 - 126ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.14293\n",
      "66/66 - 0s - loss: 0.0623 - accuracy: 0.9813 - val_loss: 0.1639 - val_accuracy: 0.9224 - 121ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.14293\n",
      "66/66 - 0s - loss: 0.0662 - accuracy: 0.9760 - val_loss: 0.2044 - val_accuracy: 0.9095 - 120ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.14293\n",
      "66/66 - 0s - loss: 0.0596 - accuracy: 0.9813 - val_loss: 0.1587 - val_accuracy: 0.9181 - 120ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 42: val_loss improved from 0.14293 to 0.14122, saving model to sdp-tree-aeeem-7.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0625 - accuracy: 0.9780 - val_loss: 0.1412 - val_accuracy: 0.9310 - 170ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0614 - accuracy: 0.9804 - val_loss: 0.1785 - val_accuracy: 0.9181 - 128ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0625 - accuracy: 0.9789 - val_loss: 0.1836 - val_accuracy: 0.9095 - 163ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0644 - accuracy: 0.9775 - val_loss: 0.1785 - val_accuracy: 0.9138 - 127ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0553 - accuracy: 0.9823 - val_loss: 0.1695 - val_accuracy: 0.9181 - 142ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0629 - accuracy: 0.9789 - val_loss: 0.1831 - val_accuracy: 0.9181 - 131ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0644 - accuracy: 0.9751 - val_loss: 0.2248 - val_accuracy: 0.9052 - 129ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0659 - accuracy: 0.9765 - val_loss: 0.2174 - val_accuracy: 0.9095 - 143ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0537 - accuracy: 0.9794 - val_loss: 0.1895 - val_accuracy: 0.9138 - 132ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0553 - accuracy: 0.9799 - val_loss: 0.1858 - val_accuracy: 0.9224 - 138ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0537 - accuracy: 0.9789 - val_loss: 0.1605 - val_accuracy: 0.9138 - 134ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0423 - accuracy: 0.9875 - val_loss: 0.1636 - val_accuracy: 0.9224 - 136ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0676 - accuracy: 0.9722 - val_loss: 0.1666 - val_accuracy: 0.9181 - 197ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0670 - accuracy: 0.9780 - val_loss: 0.1611 - val_accuracy: 0.9224 - 144ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0544 - accuracy: 0.9794 - val_loss: 0.1792 - val_accuracy: 0.9181 - 151ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0713 - accuracy: 0.9751 - val_loss: 0.1788 - val_accuracy: 0.9095 - 153ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0646 - accuracy: 0.9775 - val_loss: 0.2128 - val_accuracy: 0.9095 - 133ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0599 - accuracy: 0.9770 - val_loss: 0.1854 - val_accuracy: 0.9138 - 230ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0583 - accuracy: 0.9808 - val_loss: 0.1827 - val_accuracy: 0.9052 - 132ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0533 - accuracy: 0.9828 - val_loss: 0.2175 - val_accuracy: 0.9009 - 127ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0579 - accuracy: 0.9799 - val_loss: 0.1574 - val_accuracy: 0.9224 - 123ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0561 - accuracy: 0.9784 - val_loss: 0.1722 - val_accuracy: 0.9095 - 124ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0631 - accuracy: 0.9746 - val_loss: 0.1433 - val_accuracy: 0.9397 - 120ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0504 - accuracy: 0.9828 - val_loss: 0.1733 - val_accuracy: 0.9181 - 124ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0465 - accuracy: 0.9842 - val_loss: 0.1872 - val_accuracy: 0.9095 - 125ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0506 - accuracy: 0.9828 - val_loss: 0.1708 - val_accuracy: 0.9095 - 130ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0474 - accuracy: 0.9856 - val_loss: 0.1577 - val_accuracy: 0.9095 - 125ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0546 - accuracy: 0.9780 - val_loss: 0.1471 - val_accuracy: 0.9267 - 122ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0535 - accuracy: 0.9818 - val_loss: 0.1845 - val_accuracy: 0.9181 - 121ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0372 - accuracy: 0.9871 - val_loss: 0.1577 - val_accuracy: 0.9267 - 124ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0468 - accuracy: 0.9828 - val_loss: 0.1554 - val_accuracy: 0.9267 - 120ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0446 - accuracy: 0.9823 - val_loss: 0.1986 - val_accuracy: 0.9224 - 120ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0447 - accuracy: 0.9832 - val_loss: 0.1674 - val_accuracy: 0.9310 - 120ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0438 - accuracy: 0.9866 - val_loss: 0.1750 - val_accuracy: 0.9267 - 123ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0382 - accuracy: 0.9861 - val_loss: 0.1840 - val_accuracy: 0.9224 - 120ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.14122\n",
      "66/66 - 0s - loss: 0.0497 - accuracy: 0.9799 - val_loss: 0.1790 - val_accuracy: 0.9138 - 122ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: val_loss improved from 0.14122 to 0.12396, saving model to sdp-tree-aeeem-7.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0434 - accuracy: 0.9847 - val_loss: 0.1240 - val_accuracy: 0.9483 - 176ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.12396\n",
      "66/66 - 0s - loss: 0.0427 - accuracy: 0.9818 - val_loss: 0.1816 - val_accuracy: 0.9181 - 126ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.12396\n",
      "66/66 - 0s - loss: 0.0511 - accuracy: 0.9828 - val_loss: 0.1514 - val_accuracy: 0.9397 - 124ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.12396\n",
      "66/66 - 0s - loss: 0.0473 - accuracy: 0.9818 - val_loss: 0.1585 - val_accuracy: 0.9224 - 121ms/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.12396\n",
      "66/66 - 0s - loss: 0.0515 - accuracy: 0.9804 - val_loss: 0.1658 - val_accuracy: 0.9224 - 139ms/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.12396\n",
      "66/66 - 0s - loss: 0.0407 - accuracy: 0.9861 - val_loss: 0.1772 - val_accuracy: 0.9224 - 134ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.12396\n",
      "66/66 - 0s - loss: 0.0496 - accuracy: 0.9828 - val_loss: 0.1496 - val_accuracy: 0.9310 - 123ms/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.12396\n",
      "66/66 - 0s - loss: 0.0417 - accuracy: 0.9851 - val_loss: 0.1612 - val_accuracy: 0.9440 - 120ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.12396\n",
      "66/66 - 0s - loss: 0.0458 - accuracy: 0.9832 - val_loss: 0.1660 - val_accuracy: 0.9310 - 122ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.12396\n",
      "66/66 - 0s - loss: 0.0367 - accuracy: 0.9856 - val_loss: 0.1626 - val_accuracy: 0.9267 - 123ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.12396\n",
      "66/66 - 0s - loss: 0.0517 - accuracy: 0.9804 - val_loss: 0.1846 - val_accuracy: 0.9138 - 124ms/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.12396\n",
      "66/66 - 0s - loss: 0.0535 - accuracy: 0.9780 - val_loss: 0.1730 - val_accuracy: 0.9267 - 121ms/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.12396\n",
      "66/66 - 0s - loss: 0.0613 - accuracy: 0.9780 - val_loss: 0.1604 - val_accuracy: 0.9397 - 121ms/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.12396\n",
      "66/66 - 0s - loss: 0.0416 - accuracy: 0.9871 - val_loss: 0.1666 - val_accuracy: 0.9353 - 121ms/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.12396\n",
      "66/66 - 0s - loss: 0.0408 - accuracy: 0.9861 - val_loss: 0.1404 - val_accuracy: 0.9353 - 122ms/epoch - 2ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.12396\n",
      "66/66 - 0s - loss: 0.0417 - accuracy: 0.9856 - val_loss: 0.1619 - val_accuracy: 0.9310 - 121ms/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.12396\n",
      "66/66 - 0s - loss: 0.0396 - accuracy: 0.9842 - val_loss: 0.1398 - val_accuracy: 0.9440 - 121ms/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.12396\n",
      "66/66 - 0s - loss: 0.0313 - accuracy: 0.9890 - val_loss: 0.1475 - val_accuracy: 0.9353 - 120ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.12396\n",
      "66/66 - 0s - loss: 0.0457 - accuracy: 0.9856 - val_loss: 0.1457 - val_accuracy: 0.9353 - 198ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.12396\n",
      "66/66 - 0s - loss: 0.0380 - accuracy: 0.9832 - val_loss: 0.1427 - val_accuracy: 0.9353 - 120ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.12396\n",
      "66/66 - 0s - loss: 0.0465 - accuracy: 0.9842 - val_loss: 0.1245 - val_accuracy: 0.9440 - 122ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.12396\n",
      "66/66 - 0s - loss: 0.0487 - accuracy: 0.9804 - val_loss: 0.1536 - val_accuracy: 0.9440 - 119ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.12396\n",
      "66/66 - 0s - loss: 0.0381 - accuracy: 0.9890 - val_loss: 0.1583 - val_accuracy: 0.9310 - 120ms/epoch - 2ms/step\n",
      "73/73 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Evaluate on training data\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0228 - accuracy: 0.9927\n",
      "test loss, test acc: [0.022769084200263023, 0.9926692247390747]\n",
      "Evaluate on test data\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4166 - accuracy: 0.9105\n",
      "test loss, test acc: [0.41655245423316956, 0.9105058312416077]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/manifold/_isomap.py:384: UserWarning: The number of connected components of the neighbors graph is 3 > 1. Completing the graph to fit Isomap might be slow. Increase the number of neighbors to avoid this issue.\n",
      "  self._fit_transform(X)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/scipy/sparse/_index.py:100: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.46730, saving model to sdp-tree-aeeem-8.weights.best.keras\n",
      "66/66 - 2s - loss: 0.7076 - accuracy: 0.6550 - val_loss: 0.4673 - val_accuracy: 0.7026 - 2s/epoch - 24ms/step\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.46730\n",
      "66/66 - 0s - loss: 0.5227 - accuracy: 0.7441 - val_loss: 0.4738 - val_accuracy: 0.7716 - 144ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: val_loss improved from 0.46730 to 0.44442, saving model to sdp-tree-aeeem-8.weights.best.keras\n",
      "66/66 - 0s - loss: 0.4537 - accuracy: 0.7992 - val_loss: 0.4444 - val_accuracy: 0.7716 - 190ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: val_loss improved from 0.44442 to 0.43262, saving model to sdp-tree-aeeem-8.weights.best.keras\n",
      "66/66 - 0s - loss: 0.4091 - accuracy: 0.8160 - val_loss: 0.4326 - val_accuracy: 0.7716 - 172ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: val_loss improved from 0.43262 to 0.39934, saving model to sdp-tree-aeeem-8.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3729 - accuracy: 0.8385 - val_loss: 0.3993 - val_accuracy: 0.7888 - 177ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: val_loss improved from 0.39934 to 0.34831, saving model to sdp-tree-aeeem-8.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3386 - accuracy: 0.8596 - val_loss: 0.3483 - val_accuracy: 0.8491 - 192ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: val_loss improved from 0.34831 to 0.31908, saving model to sdp-tree-aeeem-8.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3170 - accuracy: 0.8697 - val_loss: 0.3191 - val_accuracy: 0.8879 - 249ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.31908\n",
      "66/66 - 0s - loss: 0.2855 - accuracy: 0.8850 - val_loss: 0.3262 - val_accuracy: 0.8621 - 145ms/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.31908\n",
      "66/66 - 0s - loss: 0.2822 - accuracy: 0.8860 - val_loss: 0.3267 - val_accuracy: 0.8664 - 125ms/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: val_loss improved from 0.31908 to 0.28837, saving model to sdp-tree-aeeem-8.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2488 - accuracy: 0.9066 - val_loss: 0.2884 - val_accuracy: 0.8879 - 180ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: val_loss improved from 0.28837 to 0.26924, saving model to sdp-tree-aeeem-8.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2339 - accuracy: 0.9114 - val_loss: 0.2692 - val_accuracy: 0.8922 - 168ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: val_loss improved from 0.26924 to 0.24261, saving model to sdp-tree-aeeem-8.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2159 - accuracy: 0.9205 - val_loss: 0.2426 - val_accuracy: 0.9009 - 182ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.24261\n",
      "66/66 - 0s - loss: 0.1999 - accuracy: 0.9205 - val_loss: 0.2611 - val_accuracy: 0.8879 - 137ms/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: val_loss improved from 0.24261 to 0.21276, saving model to sdp-tree-aeeem-8.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1946 - accuracy: 0.9329 - val_loss: 0.2128 - val_accuracy: 0.9267 - 282ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.21276\n",
      "66/66 - 0s - loss: 0.1891 - accuracy: 0.9262 - val_loss: 0.2200 - val_accuracy: 0.9224 - 162ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.21276\n",
      "66/66 - 0s - loss: 0.1780 - accuracy: 0.9315 - val_loss: 0.2155 - val_accuracy: 0.9310 - 126ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: val_loss improved from 0.21276 to 0.20319, saving model to sdp-tree-aeeem-8.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1646 - accuracy: 0.9406 - val_loss: 0.2032 - val_accuracy: 0.9138 - 182ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.20319\n",
      "66/66 - 0s - loss: 0.1516 - accuracy: 0.9449 - val_loss: 0.2062 - val_accuracy: 0.9181 - 128ms/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: val_loss improved from 0.20319 to 0.20170, saving model to sdp-tree-aeeem-8.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1539 - accuracy: 0.9449 - val_loss: 0.2017 - val_accuracy: 0.9138 - 168ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: val_loss improved from 0.20170 to 0.16895, saving model to sdp-tree-aeeem-8.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1479 - accuracy: 0.9473 - val_loss: 0.1690 - val_accuracy: 0.9440 - 167ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.16895\n",
      "66/66 - 0s - loss: 0.1533 - accuracy: 0.9459 - val_loss: 0.1888 - val_accuracy: 0.9138 - 130ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.16895\n",
      "66/66 - 0s - loss: 0.1419 - accuracy: 0.9473 - val_loss: 0.1712 - val_accuracy: 0.9267 - 140ms/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.16895\n",
      "66/66 - 0s - loss: 0.1401 - accuracy: 0.9502 - val_loss: 0.1801 - val_accuracy: 0.9095 - 142ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: val_loss improved from 0.16895 to 0.16112, saving model to sdp-tree-aeeem-8.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1268 - accuracy: 0.9550 - val_loss: 0.1611 - val_accuracy: 0.9267 - 245ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.16112\n",
      "66/66 - 0s - loss: 0.1257 - accuracy: 0.9607 - val_loss: 0.1664 - val_accuracy: 0.9440 - 132ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: val_loss improved from 0.16112 to 0.13884, saving model to sdp-tree-aeeem-8.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1165 - accuracy: 0.9574 - val_loss: 0.1388 - val_accuracy: 0.9569 - 184ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.13884\n",
      "66/66 - 0s - loss: 0.1185 - accuracy: 0.9559 - val_loss: 0.1577 - val_accuracy: 0.9353 - 141ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: val_loss improved from 0.13884 to 0.13149, saving model to sdp-tree-aeeem-8.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1134 - accuracy: 0.9564 - val_loss: 0.1315 - val_accuracy: 0.9526 - 169ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.13149\n",
      "66/66 - 0s - loss: 0.1136 - accuracy: 0.9593 - val_loss: 0.1456 - val_accuracy: 0.9440 - 126ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.13149\n",
      "66/66 - 0s - loss: 0.0971 - accuracy: 0.9684 - val_loss: 0.1535 - val_accuracy: 0.9440 - 127ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.13149\n",
      "66/66 - 0s - loss: 0.1097 - accuracy: 0.9574 - val_loss: 0.1700 - val_accuracy: 0.9353 - 122ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: val_loss improved from 0.13149 to 0.12969, saving model to sdp-tree-aeeem-8.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0914 - accuracy: 0.9669 - val_loss: 0.1297 - val_accuracy: 0.9483 - 168ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: val_loss improved from 0.12969 to 0.12659, saving model to sdp-tree-aeeem-8.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0914 - accuracy: 0.9736 - val_loss: 0.1266 - val_accuracy: 0.9483 - 180ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.12659\n",
      "66/66 - 0s - loss: 0.0953 - accuracy: 0.9669 - val_loss: 0.1295 - val_accuracy: 0.9526 - 136ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.12659\n",
      "66/66 - 0s - loss: 0.0821 - accuracy: 0.9698 - val_loss: 0.1592 - val_accuracy: 0.9267 - 122ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.12659\n",
      "66/66 - 0s - loss: 0.0965 - accuracy: 0.9679 - val_loss: 0.1360 - val_accuracy: 0.9612 - 136ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 37: val_loss improved from 0.12659 to 0.12538, saving model to sdp-tree-aeeem-8.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0814 - accuracy: 0.9732 - val_loss: 0.1254 - val_accuracy: 0.9612 - 173ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.12538\n",
      "66/66 - 0s - loss: 0.0843 - accuracy: 0.9717 - val_loss: 0.1370 - val_accuracy: 0.9440 - 125ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 39: val_loss improved from 0.12538 to 0.12301, saving model to sdp-tree-aeeem-8.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0899 - accuracy: 0.9679 - val_loss: 0.1230 - val_accuracy: 0.9612 - 167ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.12301\n",
      "66/66 - 0s - loss: 0.0840 - accuracy: 0.9727 - val_loss: 0.1245 - val_accuracy: 0.9440 - 129ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: val_loss improved from 0.12301 to 0.11962, saving model to sdp-tree-aeeem-8.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0797 - accuracy: 0.9746 - val_loss: 0.1196 - val_accuracy: 0.9483 - 169ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 42: val_loss improved from 0.11962 to 0.11885, saving model to sdp-tree-aeeem-8.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0799 - accuracy: 0.9708 - val_loss: 0.1188 - val_accuracy: 0.9569 - 168ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 43: val_loss improved from 0.11885 to 0.10744, saving model to sdp-tree-aeeem-8.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0930 - accuracy: 0.9650 - val_loss: 0.1074 - val_accuracy: 0.9569 - 167ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.10744\n",
      "66/66 - 0s - loss: 0.0846 - accuracy: 0.9732 - val_loss: 0.1393 - val_accuracy: 0.9526 - 226ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.10744\n",
      "66/66 - 0s - loss: 0.0738 - accuracy: 0.9770 - val_loss: 0.1190 - val_accuracy: 0.9440 - 156ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46: val_loss improved from 0.10744 to 0.10712, saving model to sdp-tree-aeeem-8.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0668 - accuracy: 0.9775 - val_loss: 0.1071 - val_accuracy: 0.9655 - 169ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.10712\n",
      "66/66 - 0s - loss: 0.0677 - accuracy: 0.9760 - val_loss: 0.1354 - val_accuracy: 0.9397 - 127ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.10712\n",
      "66/66 - 0s - loss: 0.0746 - accuracy: 0.9741 - val_loss: 0.1180 - val_accuracy: 0.9483 - 120ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.10712\n",
      "66/66 - 0s - loss: 0.0755 - accuracy: 0.9717 - val_loss: 0.1221 - val_accuracy: 0.9353 - 128ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 50: val_loss improved from 0.10712 to 0.09712, saving model to sdp-tree-aeeem-8.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0643 - accuracy: 0.9775 - val_loss: 0.0971 - val_accuracy: 0.9655 - 173ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.09712\n",
      "66/66 - 0s - loss: 0.0606 - accuracy: 0.9794 - val_loss: 0.1276 - val_accuracy: 0.9440 - 126ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.09712\n",
      "66/66 - 0s - loss: 0.0701 - accuracy: 0.9756 - val_loss: 0.1330 - val_accuracy: 0.9526 - 122ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.09712\n",
      "66/66 - 0s - loss: 0.0634 - accuracy: 0.9794 - val_loss: 0.1116 - val_accuracy: 0.9526 - 123ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 54: val_loss improved from 0.09712 to 0.09597, saving model to sdp-tree-aeeem-8.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0699 - accuracy: 0.9713 - val_loss: 0.0960 - val_accuracy: 0.9483 - 166ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.09597\n",
      "66/66 - 0s - loss: 0.0666 - accuracy: 0.9741 - val_loss: 0.1089 - val_accuracy: 0.9526 - 124ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.09597\n",
      "66/66 - 0s - loss: 0.0584 - accuracy: 0.9794 - val_loss: 0.1337 - val_accuracy: 0.9397 - 121ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.09597\n",
      "66/66 - 0s - loss: 0.0615 - accuracy: 0.9775 - val_loss: 0.1061 - val_accuracy: 0.9483 - 170ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.09597\n",
      "66/66 - 0s - loss: 0.0515 - accuracy: 0.9842 - val_loss: 0.1310 - val_accuracy: 0.9440 - 140ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.09597\n",
      "66/66 - 0s - loss: 0.0682 - accuracy: 0.9780 - val_loss: 0.1200 - val_accuracy: 0.9483 - 131ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.09597\n",
      "66/66 - 0s - loss: 0.0682 - accuracy: 0.9736 - val_loss: 0.1524 - val_accuracy: 0.9267 - 137ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.09597\n",
      "66/66 - 0s - loss: 0.0529 - accuracy: 0.9823 - val_loss: 0.1222 - val_accuracy: 0.9526 - 123ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.09597\n",
      "66/66 - 0s - loss: 0.0508 - accuracy: 0.9823 - val_loss: 0.1323 - val_accuracy: 0.9526 - 124ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.09597\n",
      "66/66 - 0s - loss: 0.0618 - accuracy: 0.9794 - val_loss: 0.1365 - val_accuracy: 0.9440 - 122ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.09597\n",
      "66/66 - 0s - loss: 0.0525 - accuracy: 0.9837 - val_loss: 0.1290 - val_accuracy: 0.9397 - 127ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.09597\n",
      "66/66 - 0s - loss: 0.0602 - accuracy: 0.9789 - val_loss: 0.1232 - val_accuracy: 0.9440 - 156ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.09597\n",
      "66/66 - 0s - loss: 0.0510 - accuracy: 0.9847 - val_loss: 0.1350 - val_accuracy: 0.9440 - 127ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.09597\n",
      "66/66 - 0s - loss: 0.0676 - accuracy: 0.9722 - val_loss: 0.1164 - val_accuracy: 0.9440 - 143ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.09597\n",
      "66/66 - 0s - loss: 0.0597 - accuracy: 0.9789 - val_loss: 0.1067 - val_accuracy: 0.9569 - 124ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.09597\n",
      "66/66 - 0s - loss: 0.0613 - accuracy: 0.9804 - val_loss: 0.1135 - val_accuracy: 0.9526 - 155ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.09597\n",
      "66/66 - 0s - loss: 0.0593 - accuracy: 0.9784 - val_loss: 0.1234 - val_accuracy: 0.9526 - 123ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.09597\n",
      "66/66 - 0s - loss: 0.0552 - accuracy: 0.9808 - val_loss: 0.1154 - val_accuracy: 0.9612 - 128ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.09597\n",
      "66/66 - 0s - loss: 0.0633 - accuracy: 0.9727 - val_loss: 0.1230 - val_accuracy: 0.9483 - 128ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.09597\n",
      "66/66 - 0s - loss: 0.0526 - accuracy: 0.9818 - val_loss: 0.1144 - val_accuracy: 0.9483 - 122ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.09597\n",
      "66/66 - 0s - loss: 0.0575 - accuracy: 0.9813 - val_loss: 0.1395 - val_accuracy: 0.9353 - 126ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.09597\n",
      "66/66 - 0s - loss: 0.0524 - accuracy: 0.9828 - val_loss: 0.1191 - val_accuracy: 0.9483 - 120ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.09597\n",
      "66/66 - 0s - loss: 0.0536 - accuracy: 0.9799 - val_loss: 0.1313 - val_accuracy: 0.9483 - 128ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.09597\n",
      "66/66 - 0s - loss: 0.0541 - accuracy: 0.9832 - val_loss: 0.1501 - val_accuracy: 0.9267 - 145ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.09597\n",
      "66/66 - 0s - loss: 0.0553 - accuracy: 0.9765 - val_loss: 0.1257 - val_accuracy: 0.9353 - 220ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.09597\n",
      "66/66 - 0s - loss: 0.0576 - accuracy: 0.9775 - val_loss: 0.1439 - val_accuracy: 0.9440 - 130ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: val_loss improved from 0.09597 to 0.08710, saving model to sdp-tree-aeeem-8.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0497 - accuracy: 0.9832 - val_loss: 0.0871 - val_accuracy: 0.9784 - 169ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.08710\n",
      "66/66 - 0s - loss: 0.0511 - accuracy: 0.9794 - val_loss: 0.1050 - val_accuracy: 0.9569 - 146ms/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.08710\n",
      "66/66 - 0s - loss: 0.0436 - accuracy: 0.9808 - val_loss: 0.1025 - val_accuracy: 0.9612 - 132ms/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.08710\n",
      "66/66 - 0s - loss: 0.0445 - accuracy: 0.9851 - val_loss: 0.1124 - val_accuracy: 0.9483 - 123ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.08710\n",
      "66/66 - 0s - loss: 0.0503 - accuracy: 0.9808 - val_loss: 0.1018 - val_accuracy: 0.9698 - 121ms/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.08710\n",
      "66/66 - 0s - loss: 0.0409 - accuracy: 0.9856 - val_loss: 0.0931 - val_accuracy: 0.9612 - 122ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.08710\n",
      "66/66 - 0s - loss: 0.0458 - accuracy: 0.9847 - val_loss: 0.0895 - val_accuracy: 0.9612 - 128ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.08710\n",
      "66/66 - 0s - loss: 0.0428 - accuracy: 0.9871 - val_loss: 0.0949 - val_accuracy: 0.9655 - 120ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.08710\n",
      "66/66 - 0s - loss: 0.0444 - accuracy: 0.9861 - val_loss: 0.1168 - val_accuracy: 0.9483 - 127ms/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.08710\n",
      "66/66 - 0s - loss: 0.0508 - accuracy: 0.9794 - val_loss: 0.1230 - val_accuracy: 0.9483 - 137ms/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.08710\n",
      "66/66 - 0s - loss: 0.0602 - accuracy: 0.9784 - val_loss: 0.1203 - val_accuracy: 0.9569 - 124ms/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.08710\n",
      "66/66 - 0s - loss: 0.0472 - accuracy: 0.9794 - val_loss: 0.0978 - val_accuracy: 0.9569 - 191ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.08710\n",
      "66/66 - 0s - loss: 0.0627 - accuracy: 0.9746 - val_loss: 0.0992 - val_accuracy: 0.9612 - 144ms/epoch - 2ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.08710\n",
      "66/66 - 0s - loss: 0.0441 - accuracy: 0.9842 - val_loss: 0.1318 - val_accuracy: 0.9440 - 128ms/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.08710\n",
      "66/66 - 0s - loss: 0.0508 - accuracy: 0.9818 - val_loss: 0.1466 - val_accuracy: 0.9397 - 135ms/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.08710\n",
      "66/66 - 0s - loss: 0.0386 - accuracy: 0.9885 - val_loss: 0.1406 - val_accuracy: 0.9440 - 143ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.08710\n",
      "66/66 - 0s - loss: 0.0588 - accuracy: 0.9832 - val_loss: 0.1164 - val_accuracy: 0.9526 - 126ms/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.08710\n",
      "66/66 - 0s - loss: 0.0679 - accuracy: 0.9756 - val_loss: 0.0937 - val_accuracy: 0.9655 - 129ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.08710\n",
      "66/66 - 0s - loss: 0.0529 - accuracy: 0.9789 - val_loss: 0.1209 - val_accuracy: 0.9526 - 139ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.08710\n",
      "66/66 - 0s - loss: 0.0386 - accuracy: 0.9842 - val_loss: 0.1185 - val_accuracy: 0.9440 - 124ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.08710\n",
      "66/66 - 0s - loss: 0.0449 - accuracy: 0.9851 - val_loss: 0.1373 - val_accuracy: 0.9353 - 123ms/epoch - 2ms/step\n",
      "73/73 [==============================] - 0s 969us/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Evaluate on training data\n",
      "73/73 [==============================] - 0s 991us/step - loss: 0.0263 - accuracy: 0.9953\n",
      "test loss, test acc: [0.026314767077565193, 0.9952566027641296]\n",
      "Evaluate on test data\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8949\n",
      "test loss, test acc: [0.33049148321151733, 0.8949416279792786]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/manifold/_isomap.py:384: UserWarning: The number of connected components of the neighbors graph is 2 > 1. Completing the graph to fit Isomap might be slow. Increase the number of neighbors to avoid this issue.\n",
      "  self._fit_transform(X)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/scipy/sparse/_index.py:100: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.60142, saving model to sdp-tree-aeeem-9.weights.best.keras\n",
      "66/66 - 2s - loss: 0.6487 - accuracy: 0.6895 - val_loss: 0.6014 - val_accuracy: 0.6121 - 2s/epoch - 25ms/step\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: val_loss improved from 0.60142 to 0.49103, saving model to sdp-tree-aeeem-9.weights.best.keras\n",
      "66/66 - 0s - loss: 0.4968 - accuracy: 0.7638 - val_loss: 0.4910 - val_accuracy: 0.7284 - 184ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: val_loss improved from 0.49103 to 0.43295, saving model to sdp-tree-aeeem-9.weights.best.keras\n",
      "66/66 - 0s - loss: 0.4302 - accuracy: 0.8079 - val_loss: 0.4330 - val_accuracy: 0.7802 - 170ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: val_loss improved from 0.43295 to 0.38388, saving model to sdp-tree-aeeem-9.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3947 - accuracy: 0.8256 - val_loss: 0.3839 - val_accuracy: 0.8362 - 176ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: val_loss improved from 0.38388 to 0.33311, saving model to sdp-tree-aeeem-9.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3506 - accuracy: 0.8457 - val_loss: 0.3331 - val_accuracy: 0.8534 - 174ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: val_loss improved from 0.33311 to 0.32689, saving model to sdp-tree-aeeem-9.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3187 - accuracy: 0.8678 - val_loss: 0.3269 - val_accuracy: 0.8534 - 185ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: val_loss improved from 0.32689 to 0.31548, saving model to sdp-tree-aeeem-9.weights.best.keras\n",
      "66/66 - 0s - loss: 0.3054 - accuracy: 0.8745 - val_loss: 0.3155 - val_accuracy: 0.8534 - 174ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: val_loss improved from 0.31548 to 0.28677, saving model to sdp-tree-aeeem-9.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2853 - accuracy: 0.8869 - val_loss: 0.2868 - val_accuracy: 0.8750 - 172ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: val_loss improved from 0.28677 to 0.28274, saving model to sdp-tree-aeeem-9.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2602 - accuracy: 0.8965 - val_loss: 0.2827 - val_accuracy: 0.8836 - 168ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: val_loss improved from 0.28274 to 0.23809, saving model to sdp-tree-aeeem-9.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2503 - accuracy: 0.8994 - val_loss: 0.2381 - val_accuracy: 0.8966 - 175ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.23809\n",
      "66/66 - 0s - loss: 0.2133 - accuracy: 0.9166 - val_loss: 0.2401 - val_accuracy: 0.8966 - 130ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: val_loss improved from 0.23809 to 0.21188, saving model to sdp-tree-aeeem-9.weights.best.keras\n",
      "66/66 - 0s - loss: 0.2093 - accuracy: 0.9181 - val_loss: 0.2119 - val_accuracy: 0.9138 - 171ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.21188\n",
      "66/66 - 0s - loss: 0.1962 - accuracy: 0.9248 - val_loss: 0.2245 - val_accuracy: 0.9052 - 146ms/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: val_loss improved from 0.21188 to 0.20386, saving model to sdp-tree-aeeem-9.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1861 - accuracy: 0.9281 - val_loss: 0.2039 - val_accuracy: 0.9138 - 168ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 15: val_loss improved from 0.20386 to 0.20282, saving model to sdp-tree-aeeem-9.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1638 - accuracy: 0.9391 - val_loss: 0.2028 - val_accuracy: 0.9052 - 172ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: val_loss improved from 0.20282 to 0.17670, saving model to sdp-tree-aeeem-9.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1537 - accuracy: 0.9502 - val_loss: 0.1767 - val_accuracy: 0.9224 - 205ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.17670\n",
      "66/66 - 0s - loss: 0.1460 - accuracy: 0.9545 - val_loss: 0.1833 - val_accuracy: 0.9440 - 124ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.17670\n",
      "66/66 - 0s - loss: 0.1425 - accuracy: 0.9463 - val_loss: 0.1884 - val_accuracy: 0.9310 - 134ms/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: val_loss improved from 0.17670 to 0.16725, saving model to sdp-tree-aeeem-9.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1457 - accuracy: 0.9545 - val_loss: 0.1672 - val_accuracy: 0.9310 - 168ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: val_loss improved from 0.16725 to 0.14709, saving model to sdp-tree-aeeem-9.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1354 - accuracy: 0.9497 - val_loss: 0.1471 - val_accuracy: 0.9440 - 168ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.14709\n",
      "66/66 - 0s - loss: 0.1215 - accuracy: 0.9578 - val_loss: 0.1564 - val_accuracy: 0.9353 - 129ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.14709\n",
      "66/66 - 0s - loss: 0.1323 - accuracy: 0.9506 - val_loss: 0.1604 - val_accuracy: 0.9353 - 136ms/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.14709\n",
      "66/66 - 0s - loss: 0.1146 - accuracy: 0.9636 - val_loss: 0.1552 - val_accuracy: 0.9397 - 123ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.14709\n",
      "66/66 - 0s - loss: 0.1090 - accuracy: 0.9641 - val_loss: 0.1656 - val_accuracy: 0.9267 - 123ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.14709\n",
      "66/66 - 0s - loss: 0.1011 - accuracy: 0.9674 - val_loss: 0.1598 - val_accuracy: 0.9353 - 124ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.14709\n",
      "66/66 - 0s - loss: 0.1087 - accuracy: 0.9598 - val_loss: 0.1759 - val_accuracy: 0.9181 - 225ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: val_loss improved from 0.14709 to 0.14382, saving model to sdp-tree-aeeem-9.weights.best.keras\n",
      "66/66 - 0s - loss: 0.1017 - accuracy: 0.9660 - val_loss: 0.1438 - val_accuracy: 0.9483 - 177ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: val_loss improved from 0.14382 to 0.14332, saving model to sdp-tree-aeeem-9.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0977 - accuracy: 0.9655 - val_loss: 0.1433 - val_accuracy: 0.9397 - 180ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: val_loss improved from 0.14332 to 0.13134, saving model to sdp-tree-aeeem-9.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0924 - accuracy: 0.9689 - val_loss: 0.1313 - val_accuracy: 0.9483 - 170ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.13134\n",
      "66/66 - 0s - loss: 0.0968 - accuracy: 0.9665 - val_loss: 0.1487 - val_accuracy: 0.9353 - 130ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.13134\n",
      "66/66 - 0s - loss: 0.0908 - accuracy: 0.9660 - val_loss: 0.1513 - val_accuracy: 0.9483 - 137ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.13134\n",
      "66/66 - 0s - loss: 0.0887 - accuracy: 0.9698 - val_loss: 0.1448 - val_accuracy: 0.9310 - 130ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.13134\n",
      "66/66 - 0s - loss: 0.0801 - accuracy: 0.9741 - val_loss: 0.1375 - val_accuracy: 0.9526 - 125ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: val_loss improved from 0.13134 to 0.12836, saving model to sdp-tree-aeeem-9.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0757 - accuracy: 0.9727 - val_loss: 0.1284 - val_accuracy: 0.9440 - 167ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.12836\n",
      "66/66 - 0s - loss: 0.0784 - accuracy: 0.9722 - val_loss: 0.1291 - val_accuracy: 0.9440 - 128ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.12836\n",
      "66/66 - 0s - loss: 0.0746 - accuracy: 0.9698 - val_loss: 0.1352 - val_accuracy: 0.9397 - 126ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.12836\n",
      "66/66 - 0s - loss: 0.0741 - accuracy: 0.9736 - val_loss: 0.1291 - val_accuracy: 0.9526 - 127ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.12836\n",
      "66/66 - 0s - loss: 0.0725 - accuracy: 0.9756 - val_loss: 0.1607 - val_accuracy: 0.9353 - 127ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.12836\n",
      "66/66 - 0s - loss: 0.0606 - accuracy: 0.9823 - val_loss: 0.1323 - val_accuracy: 0.9526 - 128ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 40: val_loss improved from 0.12836 to 0.11641, saving model to sdp-tree-aeeem-9.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0745 - accuracy: 0.9756 - val_loss: 0.1164 - val_accuracy: 0.9612 - 181ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.11641\n",
      "66/66 - 0s - loss: 0.0713 - accuracy: 0.9770 - val_loss: 0.1244 - val_accuracy: 0.9526 - 137ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.11641\n",
      "66/66 - 0s - loss: 0.0657 - accuracy: 0.9784 - val_loss: 0.1460 - val_accuracy: 0.9397 - 122ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.11641\n",
      "66/66 - 0s - loss: 0.0636 - accuracy: 0.9780 - val_loss: 0.1540 - val_accuracy: 0.9397 - 121ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.11641\n",
      "66/66 - 0s - loss: 0.0628 - accuracy: 0.9789 - val_loss: 0.1500 - val_accuracy: 0.9353 - 121ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.11641\n",
      "66/66 - 0s - loss: 0.0764 - accuracy: 0.9727 - val_loss: 0.1515 - val_accuracy: 0.9267 - 122ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.11641\n",
      "66/66 - 0s - loss: 0.0495 - accuracy: 0.9861 - val_loss: 0.1585 - val_accuracy: 0.9397 - 122ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.11641\n",
      "66/66 - 0s - loss: 0.0558 - accuracy: 0.9760 - val_loss: 0.1677 - val_accuracy: 0.9353 - 123ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.11641\n",
      "66/66 - 0s - loss: 0.0696 - accuracy: 0.9732 - val_loss: 0.1259 - val_accuracy: 0.9440 - 121ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.11641\n",
      "66/66 - 0s - loss: 0.0592 - accuracy: 0.9780 - val_loss: 0.1428 - val_accuracy: 0.9397 - 124ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.11641\n",
      "66/66 - 0s - loss: 0.0671 - accuracy: 0.9746 - val_loss: 0.1529 - val_accuracy: 0.9397 - 124ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.11641\n",
      "66/66 - 0s - loss: 0.0633 - accuracy: 0.9751 - val_loss: 0.1505 - val_accuracy: 0.9353 - 132ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.11641\n",
      "66/66 - 0s - loss: 0.0545 - accuracy: 0.9799 - val_loss: 0.1812 - val_accuracy: 0.9440 - 144ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.11641\n",
      "66/66 - 0s - loss: 0.0510 - accuracy: 0.9847 - val_loss: 0.1673 - val_accuracy: 0.9224 - 122ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.11641\n",
      "66/66 - 0s - loss: 0.0649 - accuracy: 0.9765 - val_loss: 0.1561 - val_accuracy: 0.9353 - 124ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.11641\n",
      "66/66 - 0s - loss: 0.0626 - accuracy: 0.9756 - val_loss: 0.1418 - val_accuracy: 0.9353 - 125ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.11641\n",
      "66/66 - 0s - loss: 0.0432 - accuracy: 0.9832 - val_loss: 0.1292 - val_accuracy: 0.9440 - 126ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.11641\n",
      "66/66 - 0s - loss: 0.0548 - accuracy: 0.9789 - val_loss: 0.1180 - val_accuracy: 0.9483 - 122ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.11641\n",
      "66/66 - 0s - loss: 0.0576 - accuracy: 0.9780 - val_loss: 0.1385 - val_accuracy: 0.9483 - 121ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.11641\n",
      "66/66 - 0s - loss: 0.0421 - accuracy: 0.9875 - val_loss: 0.1447 - val_accuracy: 0.9353 - 122ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.11641\n",
      "66/66 - 0s - loss: 0.0492 - accuracy: 0.9842 - val_loss: 0.1794 - val_accuracy: 0.9310 - 122ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.11641\n",
      "66/66 - 0s - loss: 0.0531 - accuracy: 0.9813 - val_loss: 0.1645 - val_accuracy: 0.9224 - 217ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.11641\n",
      "66/66 - 0s - loss: 0.0548 - accuracy: 0.9789 - val_loss: 0.2004 - val_accuracy: 0.9181 - 127ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.11641\n",
      "66/66 - 0s - loss: 0.0451 - accuracy: 0.9818 - val_loss: 0.1170 - val_accuracy: 0.9483 - 165ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.11641\n",
      "66/66 - 0s - loss: 0.0395 - accuracy: 0.9890 - val_loss: 0.1279 - val_accuracy: 0.9440 - 123ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.11641\n",
      "66/66 - 0s - loss: 0.0489 - accuracy: 0.9837 - val_loss: 0.1393 - val_accuracy: 0.9353 - 122ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.11641\n",
      "66/66 - 0s - loss: 0.0373 - accuracy: 0.9871 - val_loss: 0.1228 - val_accuracy: 0.9397 - 125ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.11641\n",
      "66/66 - 0s - loss: 0.0450 - accuracy: 0.9856 - val_loss: 0.1214 - val_accuracy: 0.9483 - 123ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.11641\n",
      "66/66 - 0s - loss: 0.0478 - accuracy: 0.9818 - val_loss: 0.1181 - val_accuracy: 0.9483 - 121ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: val_loss improved from 0.11641 to 0.11465, saving model to sdp-tree-aeeem-9.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0468 - accuracy: 0.9813 - val_loss: 0.1146 - val_accuracy: 0.9483 - 170ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.11465\n",
      "66/66 - 0s - loss: 0.0488 - accuracy: 0.9861 - val_loss: 0.1191 - val_accuracy: 0.9483 - 141ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.11465\n",
      "66/66 - 0s - loss: 0.0427 - accuracy: 0.9847 - val_loss: 0.1255 - val_accuracy: 0.9397 - 131ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: val_loss improved from 0.11465 to 0.11038, saving model to sdp-tree-aeeem-9.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0392 - accuracy: 0.9851 - val_loss: 0.1104 - val_accuracy: 0.9526 - 164ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.11038\n",
      "66/66 - 0s - loss: 0.0572 - accuracy: 0.9808 - val_loss: 0.1316 - val_accuracy: 0.9397 - 126ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.11038\n",
      "66/66 - 0s - loss: 0.0506 - accuracy: 0.9842 - val_loss: 0.1775 - val_accuracy: 0.9181 - 121ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.11038\n",
      "66/66 - 0s - loss: 0.0433 - accuracy: 0.9866 - val_loss: 0.1547 - val_accuracy: 0.9138 - 123ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.11038\n",
      "66/66 - 0s - loss: 0.0369 - accuracy: 0.9885 - val_loss: 0.1756 - val_accuracy: 0.9181 - 121ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.11038\n",
      "66/66 - 0s - loss: 0.0433 - accuracy: 0.9837 - val_loss: 0.1591 - val_accuracy: 0.9310 - 121ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.11038\n",
      "66/66 - 0s - loss: 0.0440 - accuracy: 0.9828 - val_loss: 0.1321 - val_accuracy: 0.9526 - 124ms/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.11038\n",
      "66/66 - 0s - loss: 0.0387 - accuracy: 0.9856 - val_loss: 0.1643 - val_accuracy: 0.9310 - 124ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.11038\n",
      "66/66 - 0s - loss: 0.0400 - accuracy: 0.9856 - val_loss: 0.1474 - val_accuracy: 0.9397 - 120ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.11038\n",
      "66/66 - 0s - loss: 0.0482 - accuracy: 0.9837 - val_loss: 0.1512 - val_accuracy: 0.9353 - 124ms/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.11038\n",
      "66/66 - 0s - loss: 0.0409 - accuracy: 0.9866 - val_loss: 0.1426 - val_accuracy: 0.9440 - 122ms/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.11038\n",
      "66/66 - 0s - loss: 0.0541 - accuracy: 0.9837 - val_loss: 0.1139 - val_accuracy: 0.9483 - 124ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.11038\n",
      "66/66 - 0s - loss: 0.0383 - accuracy: 0.9856 - val_loss: 0.1459 - val_accuracy: 0.9353 - 136ms/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.11038\n",
      "66/66 - 0s - loss: 0.0381 - accuracy: 0.9866 - val_loss: 0.1471 - val_accuracy: 0.9353 - 125ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.11038\n",
      "66/66 - 0s - loss: 0.0554 - accuracy: 0.9828 - val_loss: 0.1288 - val_accuracy: 0.9526 - 123ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.11038\n",
      "66/66 - 0s - loss: 0.0347 - accuracy: 0.9871 - val_loss: 0.1121 - val_accuracy: 0.9612 - 138ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: val_loss improved from 0.11038 to 0.10325, saving model to sdp-tree-aeeem-9.weights.best.keras\n",
      "66/66 - 0s - loss: 0.0443 - accuracy: 0.9856 - val_loss: 0.1033 - val_accuracy: 0.9569 - 166ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.10325\n",
      "66/66 - 0s - loss: 0.0431 - accuracy: 0.9832 - val_loss: 0.1477 - val_accuracy: 0.9353 - 126ms/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.10325\n",
      "66/66 - 0s - loss: 0.0474 - accuracy: 0.9813 - val_loss: 0.1215 - val_accuracy: 0.9569 - 123ms/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.10325\n",
      "66/66 - 0s - loss: 0.0449 - accuracy: 0.9832 - val_loss: 0.1484 - val_accuracy: 0.9440 - 124ms/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.10325\n",
      "66/66 - 0s - loss: 0.0463 - accuracy: 0.9847 - val_loss: 0.1613 - val_accuracy: 0.9397 - 126ms/epoch - 2ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.10325\n",
      "66/66 - 0s - loss: 0.0585 - accuracy: 0.9770 - val_loss: 0.1191 - val_accuracy: 0.9483 - 123ms/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.10325\n",
      "66/66 - 0s - loss: 0.0474 - accuracy: 0.9837 - val_loss: 0.1095 - val_accuracy: 0.9483 - 140ms/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.10325\n",
      "66/66 - 0s - loss: 0.0388 - accuracy: 0.9842 - val_loss: 0.1399 - val_accuracy: 0.9440 - 126ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.10325\n",
      "66/66 - 0s - loss: 0.0514 - accuracy: 0.9818 - val_loss: 0.1727 - val_accuracy: 0.9267 - 122ms/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.10325\n",
      "66/66 - 0s - loss: 0.0458 - accuracy: 0.9837 - val_loss: 0.1486 - val_accuracy: 0.9353 - 230ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.10325\n",
      "66/66 - 0s - loss: 0.0450 - accuracy: 0.9832 - val_loss: 0.1699 - val_accuracy: 0.9310 - 139ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.10325\n",
      "66/66 - 0s - loss: 0.0450 - accuracy: 0.9871 - val_loss: 0.1410 - val_accuracy: 0.9440 - 132ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.10325\n",
      "66/66 - 0s - loss: 0.0461 - accuracy: 0.9828 - val_loss: 0.1366 - val_accuracy: 0.9440 - 127ms/epoch - 2ms/step\n",
      "73/73 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "Evaluate on training data\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0351 - accuracy: 0.9944\n",
      "test loss, test acc: [0.03512304648756981, 0.9943941235542297]\n",
      "Evaluate on test data\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4688 - accuracy: 0.9027\n",
      "test loss, test acc: [0.46876442432403564, 0.9027237296104431]\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "histories = []\n",
    "\n",
    "lst_accu_stratified = []\n",
    "lst_f1_stratified = []\n",
    "lst_precision_stratified = []\n",
    "lst_recall_stratified = []\n",
    "lst_auc_stratified = []\n",
    "\n",
    "lst_accu_stratified_val = []\n",
    "lst_f1_stratified_val = []\n",
    "lst_precision_stratified_val = []\n",
    "lst_recall_stratified_val = []\n",
    "lst_auc_stratified_val = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=19)\n",
    "\n",
    "for train_index, test_index in skf.split(X_norm_scale_smote, y_smote):\n",
    "\n",
    "    x_train_fold, x_test_fold = X_norm_scale_smote[train_index], X_norm_scale_smote[test_index]\n",
    "    y_train_fold, y_test_fold = y_smote[train_index], y_smote[test_index]\n",
    " \n",
    "    rte = RandomTreesEmbedding(n_estimators=1000, random_state=0, max_depth=10).fit(x_train_fold)\n",
    "    x_sparse_embedding_train = rte.transform(x_train_fold)\n",
    "    x_sparse_embedding_test = rte.transform(x_test_fold)\n",
    "    \n",
    "    with open('rte-tree-aeeem-{0}.pickle'.format(counter), 'wb') as handle:\n",
    "        pickle.dump(rte, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    from sklearn.manifold import Isomap\n",
    "    manifold = Isomap(n_components=100)\n",
    "    x_sparse_manifold_train = manifold.fit_transform(x_sparse_embedding_train)\n",
    "    x_sparse_manifold_test = manifold.transform(x_sparse_embedding_test)\n",
    "    \n",
    "    with open('manifold-tree-aeeem-{0}.pickle'.format(counter), 'wb') as handle:\n",
    "        pickle.dump(manifold, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    scaler2 = StandardScaler()\n",
    "    x_sparse_manifold_train = scaler2.fit_transform(x_sparse_manifold_train)\n",
    "    x_sparse_manifold_test = scaler2.transform(x_sparse_manifold_test)\n",
    "    \n",
    "    with open('scaler-tree-aeeem-{0}.pickle'.format(counter), 'wb') as handle:\n",
    "        pickle.dump(scaler2, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    input_X_train1 = layers.Input(\n",
    "    shape=(x_sparse_manifold_train.shape[1],), name=\"X_train1\")  \n",
    "    \n",
    "    input_X_train2 = layers.Input(shape=(x_train_fold.shape[1],), name=\"X_train2\")\n",
    "\n",
    "    layer_X_train1 = layers.Dense(64,activation='relu',name=\"X_train1_layer\")(input_X_train1)\n",
    "    layer_X_train1 = layers.BatchNormalization()(layer_X_train1)\n",
    "    layer_X_train1 = layers.Dropout(0.3)(layer_X_train1)\n",
    "    \n",
    "    layer_X_train2 = layers.Dense(64,activation='relu',name=\"X_train2_layer\")(input_X_train2)\n",
    "    layer_X_train2 = layers.BatchNormalization()(layer_X_train2)\n",
    "    layer_X_train2 = layers.Dropout(0.3)(layer_X_train2)\n",
    "    \n",
    "    # Merge all available features into a single large vector via concatenation\n",
    "    concat = layers.concatenate([layer_X_train1, layer_X_train2])\n",
    "\n",
    "    layer_final = layers.Dense(1, activation='sigmoid', name=\"classifier\")(concat)\n",
    "    sdp_classifier = Model(inputs=[input_X_train1, input_X_train2], outputs=layer_final)\n",
    "\n",
    "    checkpointer=ModelCheckpoint(filepath='sdp-tree-aeeem-{0}.weights.best.keras'.format(counter),verbose=1,save_best_only=True)\n",
    "\n",
    "    sdp_classifier.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'] )\n",
    "    \n",
    "    hist = sdp_classifier.fit([x_sparse_manifold_train,x_train_fold], y_train_fold, \n",
    "                    batch_size=32, epochs=100, validation_split= 0.1, callbacks=[checkpointer], \n",
    "                    verbose=2, shuffle=True)\n",
    "    \n",
    "    with open('sdp-classifier-tree-aeeem-{0}.pickle'.format(counter), 'wb') as handle:\n",
    "        pickle.dump(sdp_classifier, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "\n",
    "    sdp_classifier.load_weights('sdp-tree-aeeem-{0}.weights.best.keras'.format(counter))\n",
    "\n",
    "    histories.append(hist)\n",
    "\n",
    "    results = sdp_classifier.predict([x_sparse_manifold_train,x_train_fold])\n",
    "    results = np.round(results)\n",
    "    \n",
    "    lst_accu_stratified.append(accuracy_score(y_train_fold, results))\n",
    "    lst_f1_stratified.append(f1_score(y_train_fold, results, average='weighted') )\n",
    "    lst_precision_stratified.append(precision_score(results, y_train_fold, average='weighted') )\n",
    "    lst_recall_stratified.append(recall_score(results, y_train_fold, average='weighted') )\n",
    "    fpr, tpr, thresholds = roc_curve(y_train_fold, results)\n",
    "    lst_auc_stratified.append(auc(fpr, tpr))\n",
    "    \n",
    "    results = sdp_classifier.predict([x_sparse_manifold_test,x_test_fold])\n",
    "    results = np.round(results)\n",
    "    \n",
    "    lst_accu_stratified_val.append(accuracy_score(y_test_fold, results))\n",
    "    lst_f1_stratified_val.append(f1_score(results, y_test_fold, average='weighted') )\n",
    "    lst_precision_stratified_val.append(precision_score(results, y_test_fold, average='weighted') )\n",
    "    lst_recall_stratified_val.append(recall_score(results, y_test_fold, average='weighted') )\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_fold, results)\n",
    "    lst_auc_stratified_val.append(auc(fpr, tpr))\n",
    "\n",
    "    print(\"Evaluate on training data\")\n",
    "    results = sdp_classifier.evaluate([x_sparse_manifold_train, x_train_fold], y_train_fold)\n",
    "    print(\"test loss, test acc:\", results)\n",
    "\n",
    "    print(\"Evaluate on test data\")\n",
    "    results = sdp_classifier.evaluate([x_sparse_manifold_test , x_test_fold], y_test_fold)\n",
    "    print(\"test loss, test acc:\", results)\n",
    "    counter += 1\n",
    "    \n",
    "\n",
    "dict_test = {  \"train_accu\":lst_accu_stratified, \n",
    "               \"train_precision\":lst_precision_stratified, \"train_recall\":lst_recall_stratified,\n",
    "               \"train_auc\":lst_auc_stratified, \"train_f1\":lst_f1_stratified,\n",
    "             \n",
    "               \"test_accu\":lst_accu_stratified_val, \n",
    "               \"test_precision\":lst_precision_stratified_val, \"test_recall\":lst_recall_stratified_val, \n",
    "               \"test_auc\":lst_auc_stratified_val, \"test_f1\":lst_f1_stratified_val,\n",
    "               \"Input\": x_train_fold.shape[1], \"RTE\": x_sparse_manifold_train.shape[1]}\n",
    "\n",
    "dict_test_result = pd.DataFrame.from_dict(dict_test)\n",
    "dict_test_result.to_csv(\"hasil.csv\")\n",
    "\n",
    "with open('histories-tree-manifold-aeeem.pickle'.format(counter), 'wb') as handle:\n",
    "        pickle.dump(histories, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "e4cbdbde-167a-4748-8d7a-16f3adb6a187",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accu</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_accu</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>Input</th>\n",
       "      <th>RTE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.990940</td>\n",
       "      <td>0.990986</td>\n",
       "      <td>0.990940</td>\n",
       "      <td>0.990940</td>\n",
       "      <td>0.990940</td>\n",
       "      <td>0.922481</td>\n",
       "      <td>0.925485</td>\n",
       "      <td>0.922481</td>\n",
       "      <td>0.922481</td>\n",
       "      <td>0.922597</td>\n",
       "      <td>61</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.994392</td>\n",
       "      <td>0.994401</td>\n",
       "      <td>0.994392</td>\n",
       "      <td>0.994392</td>\n",
       "      <td>0.994392</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.909981</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.907117</td>\n",
       "      <td>61</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.991372</td>\n",
       "      <td>0.991467</td>\n",
       "      <td>0.991372</td>\n",
       "      <td>0.991372</td>\n",
       "      <td>0.991371</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.887988</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.876719</td>\n",
       "      <td>61</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.993529</td>\n",
       "      <td>0.993547</td>\n",
       "      <td>0.993529</td>\n",
       "      <td>0.993529</td>\n",
       "      <td>0.993529</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.907097</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.906982</td>\n",
       "      <td>61</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.988783</td>\n",
       "      <td>0.988879</td>\n",
       "      <td>0.988783</td>\n",
       "      <td>0.988783</td>\n",
       "      <td>0.988783</td>\n",
       "      <td>0.910853</td>\n",
       "      <td>0.914488</td>\n",
       "      <td>0.910853</td>\n",
       "      <td>0.910853</td>\n",
       "      <td>0.911015</td>\n",
       "      <td>61</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.993097</td>\n",
       "      <td>0.993193</td>\n",
       "      <td>0.993097</td>\n",
       "      <td>0.993097</td>\n",
       "      <td>0.993097</td>\n",
       "      <td>0.922481</td>\n",
       "      <td>0.922601</td>\n",
       "      <td>0.922481</td>\n",
       "      <td>0.922481</td>\n",
       "      <td>0.922485</td>\n",
       "      <td>61</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.994825</td>\n",
       "      <td>0.994839</td>\n",
       "      <td>0.994825</td>\n",
       "      <td>0.994826</td>\n",
       "      <td>0.994825</td>\n",
       "      <td>0.891051</td>\n",
       "      <td>0.892121</td>\n",
       "      <td>0.891051</td>\n",
       "      <td>0.891140</td>\n",
       "      <td>0.891100</td>\n",
       "      <td>61</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.992669</td>\n",
       "      <td>0.992699</td>\n",
       "      <td>0.992669</td>\n",
       "      <td>0.992671</td>\n",
       "      <td>0.992669</td>\n",
       "      <td>0.910506</td>\n",
       "      <td>0.912934</td>\n",
       "      <td>0.910506</td>\n",
       "      <td>0.910641</td>\n",
       "      <td>0.910603</td>\n",
       "      <td>61</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.995257</td>\n",
       "      <td>0.995275</td>\n",
       "      <td>0.995257</td>\n",
       "      <td>0.995255</td>\n",
       "      <td>0.995257</td>\n",
       "      <td>0.894942</td>\n",
       "      <td>0.901803</td>\n",
       "      <td>0.894942</td>\n",
       "      <td>0.894713</td>\n",
       "      <td>0.895325</td>\n",
       "      <td>61</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.994394</td>\n",
       "      <td>0.994457</td>\n",
       "      <td>0.994394</td>\n",
       "      <td>0.994392</td>\n",
       "      <td>0.994394</td>\n",
       "      <td>0.902724</td>\n",
       "      <td>0.916140</td>\n",
       "      <td>0.902724</td>\n",
       "      <td>0.902404</td>\n",
       "      <td>0.903409</td>\n",
       "      <td>61</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_accu  train_precision  train_recall  train_auc  train_f1  test_accu  \\\n",
       "0    0.990940         0.990986      0.990940   0.990940  0.990940   0.922481   \n",
       "1    0.994392         0.994401      0.994392   0.994392  0.994392   0.906977   \n",
       "2    0.991372         0.991467      0.991372   0.991372  0.991371   0.875969   \n",
       "3    0.993529         0.993547      0.993529   0.993529  0.993529   0.906977   \n",
       "4    0.988783         0.988879      0.988783   0.988783  0.988783   0.910853   \n",
       "5    0.993097         0.993193      0.993097   0.993097  0.993097   0.922481   \n",
       "6    0.994825         0.994839      0.994825   0.994826  0.994825   0.891051   \n",
       "7    0.992669         0.992699      0.992669   0.992671  0.992669   0.910506   \n",
       "8    0.995257         0.995275      0.995257   0.995255  0.995257   0.894942   \n",
       "9    0.994394         0.994457      0.994394   0.994392  0.994394   0.902724   \n",
       "\n",
       "   test_precision  test_recall  test_auc   test_f1  Input  RTE  \n",
       "0        0.925485     0.922481  0.922481  0.922597     61  100  \n",
       "1        0.909981     0.906977  0.906977  0.907117     61  100  \n",
       "2        0.887988     0.875969  0.875969  0.876719     61  100  \n",
       "3        0.907097     0.906977  0.906977  0.906982     61  100  \n",
       "4        0.914488     0.910853  0.910853  0.911015     61  100  \n",
       "5        0.922601     0.922481  0.922481  0.922485     61  100  \n",
       "6        0.892121     0.891051  0.891140  0.891100     61  100  \n",
       "7        0.912934     0.910506  0.910641  0.910603     61  100  \n",
       "8        0.901803     0.894942  0.894713  0.895325     61  100  \n",
       "9        0.916140     0.902724  0.902404  0.903409     61  100  "
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "176f6dcd-5e0b-45bd-a73b-225010c96ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best = 8\n",
    "\n",
    "dbfile = open('rte-tree-aeeem-{0}.pickle'.format(best), 'rb')    \n",
    "rte = pickle.load(dbfile)\n",
    "dbfile.close()\n",
    "\n",
    "dbfile = open('manifold-tree-aeeem-{0}.pickle'.format(best), 'rb')    \n",
    "manifold = pickle.load(dbfile)\n",
    "dbfile.close()\n",
    "\n",
    "dbfile = open('scaler-tree-aeeem-{0}.pickle'.format(best), 'rb')    \n",
    "scaler2 = pickle.load(dbfile)\n",
    "dbfile.close()\n",
    "\n",
    "dbfile = open('sdp-classifier-tree-aeeem-{0}.pickle'.format(best), 'rb')    \n",
    "sdp_classifier = pickle.load(dbfile)\n",
    "dbfile.close()\n",
    "sdp_classifier.load_weights('sdp-tree-aeeem-{0}.weights.best.keras'.format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "07c91b00-4914-4288-b111-f558d6c11e3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1497, 118018)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sparse_embedding = rte.transform(X_norm_scale)\n",
    "X_sparse_manifold = manifold.transform(X_sparse_embedding)\n",
    "X_sparse_manifold = scaler2.transform(X_sparse_manifold)\n",
    "X_sparse_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "0cf7a4f4-0d4c-48da-889b-3f301cd6f939",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1497, 61), (1497, 62))"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_norm_scale.shape, df.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "34557d77-c1cb-4dcb-a3da-5ed736dd2b7e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "tsne = TSNE(n_jobs=4, n_components=2, verbose = 1)\n",
    "Y  = tsne.fit_transform(X_sparse_manifold)\n",
    "\n",
    "#tsne = TSNE(n_jobs=4, n_components=2, verbose = 1)\n",
    "#Y  = tsne.fit_transform(encoded_train_tcga)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0af136be-9fe3-406f-a700-d50ef3135c23",
   "metadata": {
    "tags": []
   },
   "source": [
    "tsne_ori = pd.DataFrame(Y, columns = [\"tsne1\", \"tsne2\"])\n",
    "defect = pd.DataFrame(df, columns = [\"Defective\"])\n",
    "tsne_ori = pd.concat([tsne_ori,defect.reset_index(drop=True)], axis = 1, sort = False)\n",
    "tsne_ori = tsne_ori.sort_values(by = \"Defective\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "345f745b-aa3f-4cd0-a617-b3238504d734",
   "metadata": {
    "tags": []
   },
   "source": [
    "import plotly_express as px\n",
    "\n",
    "figx = px.scatter(\n",
    "    tsne_ori,\n",
    "    x=\"tsne1\",\n",
    "    y=\"tsne2\",\n",
    "    color=\"Defective\",\n",
    "    hover_name=\"Defective\",\n",
    "    width=970,\n",
    "    height=800,\n",
    "    template=\"ggplot2\",\n",
    "    color_discrete_sequence= px.colors.qualitative.Alphabet,\n",
    "    #facet_col=\"group_label\",\n",
    "    size_max=0.1,\n",
    ")\n",
    "\n",
    "figx.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "f2ad6c81-4e4b-4d4c-ac81-c65bae16db19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on training data\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.9820\n",
      "test loss, test acc: [0.07035829871892929, 0.9819639325141907]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on training data\")\n",
    "results = sdp_classifier.evaluate([X_sparse_manifold, X_norm_scale], y, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "2534dc17-636b-4a74-85ee-168e8584e4ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 937us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99      1288\n",
      "         1.0       0.90      0.98      0.94       209\n",
      "\n",
      "    accuracy                           0.98      1497\n",
      "   macro avg       0.95      0.98      0.96      1497\n",
      "weighted avg       0.98      0.98      0.98      1497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "results = sdp_classifier.predict([X_sparse_manifold,X_norm_scale])\n",
    "results=np.round(results)\n",
    "print(classification_report(y,results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "2c4d4e34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1497,) (1497, 1)\n",
      "0.9815020505809979\n"
     ]
    }
   ],
   "source": [
    "print(y.shape, results.shape)\n",
    "fpr, tpr, thresholds = roc_curve(y, results)\n",
    "print(auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "24d644bd-ad4c-4677-b0cd-9cc007d050b2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 1ms/step\n",
      "78/78 [==============================] - 0s 1ms/step\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "105/105 [==============================] - 0s 1ms/step\n",
      "94/94 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "list_result = []\n",
    "\n",
    "for label in my_dataset:\n",
    "    dt = adjustdataset(my_dataset[label], df)\n",
    "    pt, scaler, imputer, X_norm_scale_dt, y_dt = preprocessing(dt,imputer,pt, scaler, show=False)\n",
    "    x_sparse_embedding_dt = rte.transform(X_norm_scale_dt)\n",
    "    x_sparse_manifold_dt = manifold.transform(x_sparse_embedding_dt)\n",
    "    x_sparse_manifold_dt = scaler2.transform(x_sparse_manifold_dt)\n",
    "    results = sdp_classifier.predict([x_sparse_manifold_dt,X_norm_scale_dt])\n",
    "    result  = np.round(results)\n",
    "    fpr, tpr, thresholds = roc_curve(y_dt, result)\n",
    "    list_result.append({'label':label, 'accuracy' : accuracy_score(y_dt, result),'precision':precision_score(y_dt, result, average='weighted'),\n",
    "                  'recall': recall_score(y_dt, result, average='weighted'), 'auc':auc(fpr, tpr),\n",
    "                        'f1-score':f1_score(y_dt, result, average='weighted')})\n",
    "    #heat_map(y_dt,result,label)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "ffaf8265-fb9a-423b-9d7f-e5d794f2a1ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eq</td>\n",
       "      <td>0.884130</td>\n",
       "      <td>0.889300</td>\n",
       "      <td>0.884130</td>\n",
       "      <td>0.828352</td>\n",
       "      <td>0.886290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jdt</td>\n",
       "      <td>0.894146</td>\n",
       "      <td>0.897667</td>\n",
       "      <td>0.894146</td>\n",
       "      <td>0.824647</td>\n",
       "      <td>0.895700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lc</td>\n",
       "      <td>0.932358</td>\n",
       "      <td>0.937889</td>\n",
       "      <td>0.932358</td>\n",
       "      <td>0.879697</td>\n",
       "      <td>0.934487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ml</td>\n",
       "      <td>0.867818</td>\n",
       "      <td>0.878756</td>\n",
       "      <td>0.867818</td>\n",
       "      <td>0.757252</td>\n",
       "      <td>0.872543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pde</td>\n",
       "      <td>0.981964</td>\n",
       "      <td>0.983204</td>\n",
       "      <td>0.981964</td>\n",
       "      <td>0.981502</td>\n",
       "      <td>0.982289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  accuracy  precision    recall       auc  f1-score\n",
       "0    eq  0.884130   0.889300  0.884130  0.828352  0.886290\n",
       "1   jdt  0.894146   0.897667  0.894146  0.824647  0.895700\n",
       "2    lc  0.932358   0.937889  0.932358  0.879697  0.934487\n",
       "3    ml  0.867818   0.878756  0.867818  0.757252  0.872543\n",
       "4   pde  0.981964   0.983204  0.981964  0.981502  0.982289"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame(list_result)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "8b541f30-57c1-465b-9d4a-bfdbd6d516f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy     0.896234\n",
       "precision    0.923975\n",
       "recall       0.896234\n",
       "auc          0.874335\n",
       "f1-score     0.904801\n",
       "dtype: float64"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result[['accuracy','precision','recall','auc','f1-score']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "0cc25061-7a0c-4f90-9702-621f5b804f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_111\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " X_train1 (InputLayer)       [(None, 100)]                0         []                            \n",
      "                                                                                                  \n",
      " X_train2 (InputLayer)       [(None, 61)]                 0         []                            \n",
      "                                                                                                  \n",
      " X_train1_layer (Dense)      (None, 64)                   6464      ['X_train1[0][0]']            \n",
      "                                                                                                  \n",
      " X_train2_layer (Dense)      (None, 64)                   3968      ['X_train2[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_222 (B  (None, 64)                   256       ['X_train1_layer[0][0]']      \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_223 (B  (None, 64)                   256       ['X_train2_layer[0][0]']      \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dropout_222 (Dropout)       (None, 64)                   0         ['batch_normalization_222[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_223 (Dropout)       (None, 64)                   0         ['batch_normalization_223[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " concatenate_111 (Concatena  (None, 128)                  0         ['dropout_222[0][0]',         \n",
      " te)                                                                 'dropout_223[0][0]']         \n",
      "                                                                                                  \n",
      " classifier (Dense)          (None, 1)                    129       ['concatenate_111[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11073 (43.25 KB)\n",
      "Trainable params: 10817 (42.25 KB)\n",
      "Non-trainable params: 256 (1.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sdp_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "b3e07fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_result = []\n",
    "\n",
    "for label in my_dataset:\n",
    "    dt = my_dataset[label]\n",
    "    list_result.append({'Dataset':label, 'Instances':dt.shape[0], 'Features':dt.shape[1],\n",
    "                        'Defective Instances': dt[dt['Defective'] == 'Y'].shape[0],\n",
    "                        'Non-Defective Instances': dt[dt['Defective'] == 'N'].shape[0],})\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "b70de863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Instances</th>\n",
       "      <th>Features</th>\n",
       "      <th>Defective Instances</th>\n",
       "      <th>Non-Defective Instances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eq</td>\n",
       "      <td>324</td>\n",
       "      <td>62</td>\n",
       "      <td>129</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jdt</td>\n",
       "      <td>997</td>\n",
       "      <td>62</td>\n",
       "      <td>206</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lc</td>\n",
       "      <td>691</td>\n",
       "      <td>62</td>\n",
       "      <td>64</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ml</td>\n",
       "      <td>1862</td>\n",
       "      <td>62</td>\n",
       "      <td>245</td>\n",
       "      <td>1617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pde</td>\n",
       "      <td>1497</td>\n",
       "      <td>62</td>\n",
       "      <td>209</td>\n",
       "      <td>1288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset  Instances  Features  Defective Instances  Non-Defective Instances\n",
       "0      eq        324        62                  129                      195\n",
       "1     jdt        997        62                  206                      791\n",
       "2      lc        691        62                   64                      627\n",
       "3      ml       1862        62                  245                     1617\n",
       "4     pde       1497        62                  209                     1288"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame(list_result)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504fe02e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
